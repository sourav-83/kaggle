{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91c65588",
   "metadata": {
    "papermill": {
     "duration": 0.033653,
     "end_time": "2024-10-31T13:21:09.225612",
     "exception": false,
     "start_time": "2024-10-31T13:21:09.191959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43357c2d",
   "metadata": {
    "papermill": {
     "duration": 0.031732,
     "end_time": "2024-10-31T13:21:09.292010",
     "exception": false,
     "start_time": "2024-10-31T13:21:09.260278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Make both T4 GPUs visiable to CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "787c4a4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:21:09.358708Z",
     "iopub.status.busy": "2024-10-31T13:21:09.358374Z",
     "iopub.status.idle": "2024-10-31T13:21:09.367774Z",
     "shell.execute_reply": "2024-10-31T13:21:09.367037Z"
    },
    "papermill": {
     "duration": 0.044722,
     "end_time": "2024-10-31T13:21:09.369706",
     "exception": false,
     "start_time": "2024-10-31T13:21:09.324984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, math, numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4354548c",
   "metadata": {
    "papermill": {
     "duration": 0.031706,
     "end_time": "2024-10-31T13:21:09.433836",
     "exception": false,
     "start_time": "2024-10-31T13:21:09.402130",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install vLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb6bb227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:21:09.499507Z",
     "iopub.status.busy": "2024-10-31T13:21:09.498882Z",
     "iopub.status.idle": "2024-10-31T13:23:39.883890Z",
     "shell.execute_reply": "2024-10-31T13:23:39.882532Z"
    },
    "papermill": {
     "duration": 150.420373,
     "end_time": "2024-10-31T13:23:39.886144",
     "exception": false,
     "start_time": "2024-10-31T13:21:09.465771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.4.0\r\n",
      "Uninstalling torch-2.4.0:\r\n",
      "  Successfully uninstalled torch-2.4.0\r\n",
      "Looking in links: /kaggle/input/vllm-whl\r\n",
      "Processing /kaggle/input/vllm-whl/vllm-0.4.0.post1-cp310-cp310-manylinux1_x86_64.whl\r\n",
      "Processing /kaggle/input/vllm-whl/cmake-3.29.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\r\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from vllm) (1.11.1.1)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from vllm) (5.9.3)\r\n",
      "Requirement already satisfied: ray>=2.9 in /opt/conda/lib/python3.10/site-packages (from vllm) (2.24.0)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from vllm) (0.2.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from vllm) (1.26.4)\r\n",
      "Processing /kaggle/input/vllm-whl/torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (from vllm)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from vllm) (2.32.3)\r\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from vllm) (9.0.0)\r\n",
      "Requirement already satisfied: transformers>=4.39.1 in /opt/conda/lib/python3.10/site-packages (from vllm) (4.45.1)\r\n",
      "Processing /kaggle/input/vllm-whl/xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (from vllm)\r\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from vllm) (0.111.0)\r\n",
      "Requirement already satisfied: uvicorn[standard] in /opt/conda/lib/python3.10/site-packages (from vllm) (0.30.1)\r\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from vllm) (2.9.2)\r\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from vllm) (0.20.0)\r\n",
      "Processing /kaggle/input/vllm-whl/pynvml-11.5.0-py3-none-any.whl (from vllm)\r\n",
      "Processing /kaggle/input/vllm-whl/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from vllm)\r\n",
      "Processing /kaggle/input/vllm-whl/outlines-0.0.34-py3-none-any.whl (from vllm)\r\n",
      "Processing /kaggle/input/vllm-whl/tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\r\n",
      "Processing /kaggle/input/vllm-whl/interegular-0.3.3-py37-none-any.whl (from outlines==0.0.34->vllm)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (3.1.4)\r\n",
      "Processing /kaggle/input/vllm-whl/lark-1.1.9-py3-none-any.whl (from outlines==0.0.34->vllm)\r\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (1.6.0)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (3.0.0)\r\n",
      "Processing /kaggle/input/vllm-whl/diskcache-5.6.3-py3-none-any.whl (from outlines==0.0.34->vllm)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (1.14.1)\r\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (0.60.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (1.4.2)\r\n",
      "Requirement already satisfied: referencing in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (0.35.1)\r\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (4.22.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.6.0->vllm) (2024.5.15)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->vllm) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->vllm) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->vllm) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->vllm) (3.3)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->vllm) (2024.6.1)\r\n",
      "Processing /kaggle/input/vllm-whl/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\r\n",
      "Processing /kaggle/input/vllm-whl/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\r\n",
      "Processing /kaggle/input/vllm-whl/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\r\n",
      "Processing /kaggle/input/vllm-whl/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\r\n",
      "Processing /kaggle/input/vllm-whl/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\r\n",
      "Processing /kaggle/input/vllm-whl/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\r\n",
      "Processing /kaggle/input/vllm-whl/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\r\n",
      "Processing /kaggle/input/vllm-whl/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\r\n",
      "Processing /kaggle/input/vllm-whl/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\r\n",
      "Processing /kaggle/input/vllm-whl/nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\r\n",
      "Processing /kaggle/input/vllm-whl/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\r\n",
      "Processing /kaggle/input/vllm-whl/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->vllm)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->vllm) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->vllm) (2.23.4)\r\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (8.1.7)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (1.0.8)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (3.20.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (6.0.2)\r\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (1.3.1)\r\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (1.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (2024.8.30)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.1->vllm) (0.25.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.1->vllm) (0.4.5)\r\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.1->vllm) (0.20.0)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.1->vllm) (4.66.4)\r\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (0.37.2)\r\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (0.0.4)\r\n",
      "Requirement already satisfied: httpx>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (0.27.0)\r\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (0.0.9)\r\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (5.10.0)\r\n",
      "Requirement already satisfied: orjson>=3.2.1 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (3.10.4)\r\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (2.1.1)\r\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.14.0)\r\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.6.1)\r\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (1.0.1)\r\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.19.0)\r\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.22.0)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (12.0)\r\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi->vllm) (2.6.1)\r\n",
      "Requirement already satisfied: typer>=0.12.3 in /opt/conda/lib/python3.10/site-packages (from fastapi-cli>=0.0.2->fastapi->vllm) (0.12.3)\r\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi->vllm) (4.4.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi->vllm) (1.0.5)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi->vllm) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->outlines==0.0.34->vllm) (2.1.5)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ray>=2.9->vllm) (3.1.2)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->outlines==0.0.34->vllm) (23.2.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->outlines==0.0.34->vllm) (2023.12.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->outlines==0.0.34->vllm) (0.18.1)\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->outlines==0.0.34->vllm) (0.43.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.2->vllm) (1.3.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.23.0->fastapi->vllm) (1.2.0)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (13.7.1)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (2.18.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (0.1.2)\r\n",
      "Installing collected packages: triton, pynvml, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lark, interegular, diskcache, cmake, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, xformers, outlines, vllm\r\n",
      "  Attempting uninstall: pynvml\r\n",
      "    Found existing installation: pynvml 11.4.1\r\n",
      "    Uninstalling pynvml-11.4.1:\r\n",
      "      Successfully uninstalled pynvml-11.4.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "ucxx 0.39.1 requires libucx>=1.15.0, which is not installed.\r\n",
      "dask-cuda 24.8.2 requires pynvml<11.5,>=11.0.0, but you have pynvml 11.5.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed cmake-3.29.0.1 diskcache-5.6.3 interegular-0.3.3 lark-1.1.9 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 outlines-0.0.34 pynvml-11.5.0 tiktoken-0.6.0 torch-2.1.2 triton-2.1.0 vllm-0.4.0.post1 xformers-0.0.23.post1\r\n",
      "Processing /kaggle/input/vllm-t4-fix/grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "grpcio is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Processing /kaggle/input/vllm-t4-fix/ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl\r\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (8.1.7)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (3.15.1)\r\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (4.22.0)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (1.0.8)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (3.20.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (6.0.2)\r\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (1.3.1)\r\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (1.4.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (2.32.3)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.11.0) (23.2.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.11.0) (2023.12.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.11.0) (0.35.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.11.0) (0.18.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ray==2.11.0) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.11.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.11.0) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.11.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.11.0) (2024.8.30)\r\n",
      "Installing collected packages: ray\r\n",
      "  Attempting uninstall: ray\r\n",
      "    Found existing installation: ray 2.24.0\r\n",
      "    Uninstalling ray-2.24.0:\r\n",
      "      Successfully uninstalled ray-2.24.0\r\n",
      "Successfully installed ray-2.11.0\r\n",
      "CPU times: user 2.11 s, sys: 414 ms, total: 2.52 s\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!pip uninstall -y torch\n",
    "!pip install -U --no-index --find-links=/kaggle/input/vllm-whl -U vllm\n",
    "!pip install -U --upgrade /kaggle/input/vllm-t4-fix/grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install -U --upgrade /kaggle/input/vllm-t4-fix/ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78bcd0",
   "metadata": {
    "papermill": {
     "duration": 0.036069,
     "end_time": "2024-10-31T13:23:39.959053",
     "exception": false,
     "start_time": "2024-10-31T13:23:39.922984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Some Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48081034",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:23:40.034175Z",
     "iopub.status.busy": "2024-10-31T13:23:40.033760Z",
     "iopub.status.idle": "2024-10-31T13:23:40.038995Z",
     "shell.execute_reply": "2024-10-31T13:23:40.038181Z"
    },
    "papermill": {
     "duration": 0.04515,
     "end_time": "2024-10-31T13:23:40.040891",
     "exception": false,
     "start_time": "2024-10-31T13:23:39.995741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In DEBUG mode, infer only on 5 problems\n",
    "DEBUG = False\n",
    "# Number of candidate solutions to generate\n",
    "K = 4\n",
    "DEPTH = 4\n",
    "TEMPERATURE = 0.35\n",
    "TOP_P = 0.775\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d79b9b",
   "metadata": {
    "papermill": {
     "duration": 0.037734,
     "end_time": "2024-10-31T13:23:40.115435",
     "exception": false,
     "start_time": "2024-10-31T13:23:40.077701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb0c294",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:23:40.197820Z",
     "iopub.status.busy": "2024-10-31T13:23:40.197412Z",
     "iopub.status.idle": "2024-10-31T13:23:44.763355Z",
     "shell.execute_reply": "2024-10-31T13:23:44.762483Z"
    },
    "papermill": {
     "duration": 4.611565,
     "end_time": "2024-10-31T13:23:44.766008",
     "exception": false,
     "start_time": "2024-10-31T13:23:40.154443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 13:23:43,771\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import vllm\n",
    "import re\n",
    "import csv\n",
    "import torch\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from queue import Queue, Empty\n",
    "import os\n",
    "import re\n",
    "import signal\n",
    "import subprocess\n",
    "import tempfile\n",
    "from collections import Counter\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8694d28",
   "metadata": {
    "papermill": {
     "duration": 0.039922,
     "end_time": "2024-10-31T13:23:44.845627",
     "exception": false,
     "start_time": "2024-10-31T13:23:44.805705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Python Code Execution Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f11ab65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:23:44.924738Z",
     "iopub.status.busy": "2024-10-31T13:23:44.924123Z",
     "iopub.status.idle": "2024-10-31T13:23:44.931928Z",
     "shell.execute_reply": "2024-10-31T13:23:44.930951Z"
    },
    "papermill": {
     "duration": 0.050217,
     "end_time": "2024-10-31T13:23:44.934354",
     "exception": false,
     "start_time": "2024-10-31T13:23:44.884137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bac1d1",
   "metadata": {
    "papermill": {
     "duration": 0.036387,
     "end_time": "2024-10-31T13:23:45.007566",
     "exception": false,
     "start_time": "2024-10-31T13:23:44.971179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Find Python code blocks within text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f06adc63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:23:45.082693Z",
     "iopub.status.busy": "2024-10-31T13:23:45.081687Z",
     "iopub.status.idle": "2024-10-31T13:23:45.088817Z",
     "shell.execute_reply": "2024-10-31T13:23:45.087875Z"
    },
    "papermill": {
     "duration": 0.04693,
     "end_time": "2024-10-31T13:23:45.090870",
     "exception": false,
     "start_time": "2024-10-31T13:23:45.043940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_python_blocks(text):\n",
    "    blocks = re.findall(r\"(```python.*?```)\", text, re.DOTALL)\n",
    "    # filter blocks by trying to convert them to float or int\n",
    "    filtered_blocks = []\n",
    "    for block in blocks:\n",
    "        code = block[len(\"```python\"):-len(\"```\")].strip()\n",
    "        try:\n",
    "            x = int(code)\n",
    "        except:\n",
    "            filtered_blocks.append(code)\n",
    "            continue\n",
    "        try:\n",
    "            x = float(code)\n",
    "        except:\n",
    "            filtered_blocks.append(code)\n",
    "    return filtered_blocks        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2cc12",
   "metadata": {
    "papermill": {
     "duration": 0.03626,
     "end_time": "2024-10-31T13:23:45.163967",
     "exception": false,
     "start_time": "2024-10-31T13:23:45.127707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Class to Execute Python code (adopted from Numina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d3c8b8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:23:45.239815Z",
     "iopub.status.busy": "2024-10-31T13:23:45.239440Z",
     "iopub.status.idle": "2024-10-31T13:23:45.253506Z",
     "shell.execute_reply": "2024-10-31T13:23:45.252630Z"
    },
    "papermill": {
     "duration": 0.054391,
     "end_time": "2024-10-31T13:23:45.255379",
     "exception": false,
     "start_time": "2024-10-31T13:23:45.200988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PythonREPL:\n",
    "    def __init__(self, timeout=5):\n",
    "        self.timeout = timeout\n",
    "    # handles timeout\n",
    "    @contextmanager\n",
    "    def time_limit(self, seconds):\n",
    "        def signal_handler(*_):\n",
    "            raise TimeoutError(f\"Timed out after {seconds} seconds.\")\n",
    "\n",
    "        signal.signal(signal.SIGALRM, signal_handler)\n",
    "        signal.alarm(seconds)\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            signal.alarm(0)\n",
    "\n",
    "    def __call__(self, query):\n",
    "        query = \"import math\\nimport numpy as np\\nimport sympy as sp\\n\" + query\n",
    "        query = query.strip().split(\"\\n\")\n",
    "        if \"print(\" not in query[-1]:\n",
    "            if \"#\" in query[-1]:\n",
    "                query[-1] = query[-1].split(\"#\")[0]\n",
    "            query[-1] = \"print(\" + query[-1] + \")\"\n",
    "        query = \"\\n\".join(query)\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            temp_file_path = os.path.join(temp_dir, \"tmp.py\")\n",
    "            with open(temp_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(query)\n",
    "            with self.time_limit(self.timeout):\n",
    "                result = subprocess.run(\n",
    "                    [\"python3\", temp_file_path],\n",
    "                    capture_output=True,\n",
    "                    check=False,\n",
    "                    text=True,\n",
    "                    timeout=self.timeout,\n",
    "                )\n",
    "                if result.returncode == 0:\n",
    "                    output = result.stdout\n",
    "                    return True, output.strip()\n",
    "                error_msg = result.stderr.strip()\n",
    "                msgs = error_msg.split(\"\\n\")\n",
    "                new_msgs = []\n",
    "                want_next = False\n",
    "                for m in msgs:\n",
    "                    if \"Traceback\" in m:\n",
    "                        new_msgs.append(m)\n",
    "                    elif m == msgs[-1]:\n",
    "                        new_msgs.append(m)\n",
    "                    elif temp_file_path in m:\n",
    "                        st = m.index('\"/') + 1 if '\"/' in m else 0\n",
    "                        ed = m.index(temp_file_path) + 1 if temp_file_path in m else None\n",
    "                        clr = m[st:ed] if not ed else m[st:]\n",
    "                        m = m.replace(clr, \"\")\n",
    "                        new_msgs.append(m)\n",
    "                        want_next = True\n",
    "                    elif want_next:\n",
    "                        new_msgs.append(m)\n",
    "                        want_next = False\n",
    "                error_msg = \"\\n\".join(new_msgs)\n",
    "                return False, error_msg.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3446117",
   "metadata": {
    "papermill": {
     "duration": 0.03664,
     "end_time": "2024-10-31T13:23:45.328340",
     "exception": false,
     "start_time": "2024-10-31T13:23:45.291700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Execute a Python code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b31bd64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:23:45.402771Z",
     "iopub.status.busy": "2024-10-31T13:23:45.402411Z",
     "iopub.status.idle": "2024-10-31T13:23:45.408404Z",
     "shell.execute_reply": "2024-10-31T13:23:45.407570Z"
    },
    "papermill": {
     "duration": 0.04551,
     "end_time": "2024-10-31T13:23:45.410401",
     "exception": false,
     "start_time": "2024-10-31T13:23:45.364891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute(executor, code):\n",
    "    success = False\n",
    "    for lib in (\"subprocess\", \"venv\"):\n",
    "        if lib in code:\n",
    "            output = f\"{lib} is not allowed\"\n",
    "            outputs.append(output)\n",
    "            successes.append(success)\n",
    "            continue\n",
    "    try:\n",
    "        success, output = executor(code)\n",
    "    except TimeoutError as e:\n",
    "        output = str(e)\n",
    "\n",
    "    output = output.strip()\n",
    "    \n",
    "    return output, success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4511c6",
   "metadata": {
    "papermill": {
     "duration": 0.036401,
     "end_time": "2024-10-31T13:23:45.483152",
     "exception": false,
     "start_time": "2024-10-31T13:23:45.446751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test by running some python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c6b9481",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:23:45.557317Z",
     "iopub.status.busy": "2024-10-31T13:23:45.556949Z",
     "iopub.status.idle": "2024-10-31T13:23:45.561274Z",
     "shell.execute_reply": "2024-10-31T13:23:45.560401Z"
    },
    "papermill": {
     "duration": 0.043529,
     "end_time": "2024-10-31T13:23:45.563112",
     "exception": false,
     "start_time": "2024-10-31T13:23:45.519583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Block 1\n",
    "```python\n",
    "s = 0\n",
    "for i in range(100):\n",
    "    s += i\n",
    "print(s)\n",
    "```\n",
    "Block 2\n",
    "```python\n",
    "2**12\n",
    "```\n",
    "Block 3\n",
    "```python\n",
    "3\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bdbe850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:23:45.637279Z",
     "iopub.status.busy": "2024-10-31T13:23:45.636941Z",
     "iopub.status.idle": "2024-10-31T13:23:45.642771Z",
     "shell.execute_reply": "2024-10-31T13:23:45.641973Z"
    },
    "papermill": {
     "duration": 0.04531,
     "end_time": "2024-10-31T13:23:45.644740",
     "exception": false,
     "start_time": "2024-10-31T13:23:45.599430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s = 0\\nfor i in range(100):\\n    s += i\\nprint(s)', '2**12']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks = find_python_blocks(text)\n",
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7748ca27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:23:45.720479Z",
     "iopub.status.busy": "2024-10-31T13:23:45.719895Z",
     "iopub.status.idle": "2024-10-31T13:23:46.943680Z",
     "shell.execute_reply": "2024-10-31T13:23:46.942438Z"
    },
    "papermill": {
     "duration": 1.263498,
     "end_time": "2024-10-31T13:23:46.945806",
     "exception": false,
     "start_time": "2024-10-31T13:23:45.682308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4950', True), ('4096', True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor = PythonREPL()\n",
    "outputs = [execute(executor, block) for block in blocks]\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c75410a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:23:47.021537Z",
     "iopub.status.busy": "2024-10-31T13:23:47.021182Z",
     "iopub.status.idle": "2024-10-31T13:23:47.026161Z",
     "shell.execute_reply": "2024-10-31T13:23:47.025246Z"
    },
    "papermill": {
     "duration": 0.045053,
     "end_time": "2024-10-31T13:23:47.028443",
     "exception": false,
     "start_time": "2024-10-31T13:23:46.983390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "```python\n",
      "s = 0\n",
      "for i in range(100):\n",
      "    s += i\n",
      "print(s)\n",
      "```\n",
      "```output\n",
      "4950\n",
      "```\n",
      "\n",
      "```python\n",
      "2**12\n",
      "```\n",
      "```output\n",
      "4096\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "for block, output in zip(blocks, outputs):\n",
    "    print(f\"\"\"\n",
    "```python\n",
    "{block}\n",
    "```\n",
    "```output\n",
    "{output[0]}\n",
    "```\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158080dd",
   "metadata": {
    "papermill": {
     "duration": 0.036326,
     "end_time": "2024-10-31T13:23:47.101294",
     "exception": false,
     "start_time": "2024-10-31T13:23:47.064968",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Model on vLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81b2473",
   "metadata": {
    "papermill": {
     "duration": 0.036466,
     "end_time": "2024-10-31T13:23:47.174406",
     "exception": false,
     "start_time": "2024-10-31T13:23:47.137940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## We use the Qwen 2.5 7b Instruct Model here by Alibaba. You should explore other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21242128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:23:47.249739Z",
     "iopub.status.busy": "2024-10-31T13:23:47.249021Z",
     "iopub.status.idle": "2024-10-31T13:26:52.888789Z",
     "shell.execute_reply": "2024-10-31T13:26:52.886406Z"
    },
    "papermill": {
     "duration": 185.681895,
     "end_time": "2024-10-31T13:26:52.892821",
     "exception": false,
     "start_time": "2024-10-31T13:23:47.210926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ad658ac3e742eba6f75f9d5473b1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/841 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 10-31 13:23:47 config.py:211] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 13:23:50,265\tINFO worker.py:1749 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-31 13:23:51 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='Qwen/Qwen2.5-32B-Instruct-AWQ', tokenizer='Qwen/Qwen2.5-32B-Instruct-AWQ', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=10000, download_dir=None, load_format=auto, tensor_parallel_size=2, disable_custom_all_reduce=True, quantization=awq, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, seed=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b70ad5c5e114ac285c3e0c194e2b33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30b808b89ba47dd87737dcd26cdcb2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb7c34ba64f4892bb0b297197be3e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8da0655056439fa936bc58233ac831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-31 13:24:01 selector.py:40] Cannot use FlashAttention backend for Volta and Turing GPUs.\n",
      "INFO 10-31 13:24:01 selector.py:25] Using XFormers backend.\n",
      "\u001b[36m(RayWorkerVllm pid=372)\u001b[0m INFO 10-31 13:24:02 selector.py:40] Cannot use FlashAttention backend for Volta and Turing GPUs.\n",
      "\u001b[36m(RayWorkerVllm pid=372)\u001b[0m INFO 10-31 13:24:02 selector.py:25] Using XFormers backend.\n",
      "INFO 10-31 13:24:02 pynccl_utils.py:45] vLLM is using nccl==2.18.1\n",
      "\u001b[36m(RayWorkerVllm pid=372)\u001b[0m INFO 10-31 13:24:02 pynccl_utils.py:45] vLLM is using nccl==2.18.1\n",
      "INFO 10-31 13:24:03 weight_utils.py:177] Using model weights format ['*.safetensors']\n",
      "\u001b[36m(RayWorkerVllm pid=372)\u001b[0m INFO 10-31 13:24:03 weight_utils.py:177] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1be6d6c46c45bab684dd5543023730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/3.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35aef18c8304af8ba6c202398dd23be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/3.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280671b7c751442998e2f1827b7da4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34bd080227b4412a72f755eb67aba8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80872b646a4e4718b5bafd94c4075721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-31 13:26:31 model_runner.py:104] Loading model weights took 9.0933 GB\n",
      "\u001b[36m(RayWorkerVllm pid=372)\u001b[0m INFO 10-31 13:26:31 model_runner.py:104] Loading model weights took 9.0933 GB\n",
      "INFO 10-31 13:26:49 ray_gpu_executor.py:240] # GPU blocks: 1094, # CPU blocks: 2048\n"
     ]
    }
   ],
   "source": [
    "llm = vllm.LLM(\n",
    "    \"Qwen/Qwen2.5-32B-Instruct-AWQ\",\n",
    "    tensor_parallel_size=2, \n",
    "    quantization=\"AWQ\",\n",
    "    gpu_memory_utilization=0.95, \n",
    "    trust_remote_code=True,\n",
    "    dtype=\"half\", \n",
    "    enforce_eager=True,\n",
    "    max_model_len=10000,\n",
    ")\n",
    "tokenizer = llm.get_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44929f4",
   "metadata": {
    "papermill": {
     "duration": 0.05404,
     "end_time": "2024-10-31T13:26:52.998559",
     "exception": false,
     "start_time": "2024-10-31T13:26:52.944519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utilites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa77504",
   "metadata": {
    "papermill": {
     "duration": 0.05296,
     "end_time": "2024-10-31T13:26:53.106427",
     "exception": false,
     "start_time": "2024-10-31T13:26:53.053467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Extract boxed answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c7a8bfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:26:53.217652Z",
     "iopub.status.busy": "2024-10-31T13:26:53.214446Z",
     "iopub.status.idle": "2024-10-31T13:26:53.245274Z",
     "shell.execute_reply": "2024-10-31T13:26:53.242962Z"
    },
    "papermill": {
     "duration": 0.084356,
     "end_time": "2024-10-31T13:26:53.249009",
     "exception": false,
     "start_time": "2024-10-31T13:26:53.164653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_answer(text):\n",
    "    # find right most boxed answer\n",
    "    def last_boxed_only_string(text):\n",
    "        idx = text.rfind(\"\\\\boxed\")\n",
    "        if idx < 0:\n",
    "            idx = text.rfind(\"\\\\fbox\")\n",
    "            if idx < 0:\n",
    "                return None\n",
    "        i = idx\n",
    "        right_brace_idx = None\n",
    "        num_left_braces_open = 0\n",
    "        while i < len(text):\n",
    "            if text[i] == \"{\":\n",
    "                num_left_braces_open += 1\n",
    "            if text[i] == \"}\":\n",
    "                num_left_braces_open -= 1\n",
    "                if num_left_braces_open == 0:\n",
    "                    right_brace_idx = i\n",
    "                    break\n",
    "            i += 1\n",
    "        if right_brace_idx is None:\n",
    "            return None\n",
    "        return text[idx : right_brace_idx + 1]\n",
    "    # get content of boxed\n",
    "    def remove_boxed(boxed):\n",
    "        left = \"\\\\boxed{\"\n",
    "        try:\n",
    "            assert boxed[: len(left)] == left\n",
    "            assert boxed[-1] == \"}\"\n",
    "            length = len(left)\n",
    "            return boxed[length:-1]\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    boxed = last_boxed_only_string(text)\n",
    "    if boxed is None:\n",
    "        return None\n",
    "    answer = remove_boxed(boxed)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d392fe95",
   "metadata": {
    "papermill": {
     "duration": 0.042272,
     "end_time": "2024-10-31T13:26:53.364753",
     "exception": false,
     "start_time": "2024-10-31T13:26:53.322481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Majority vote (select the most occuring answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00b845a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:26:53.450872Z",
     "iopub.status.busy": "2024-10-31T13:26:53.450024Z",
     "iopub.status.idle": "2024-10-31T13:26:53.458596Z",
     "shell.execute_reply": "2024-10-31T13:26:53.457639Z"
    },
    "papermill": {
     "duration": 0.053239,
     "end_time": "2024-10-31T13:26:53.460692",
     "exception": false,
     "start_time": "2024-10-31T13:26:53.407453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the majority voting function to get the most common answer\n",
    "def majority_vote(answers):\n",
    "    answers = [answer for answer in answers if answer is not None]\n",
    "\n",
    "    if not answers:\n",
    "        return None\n",
    "    # count the occurence of each answer\n",
    "    counts = {}\n",
    "    for answer in answers:\n",
    "        if answer in counts:\n",
    "            counts[answer] += 1\n",
    "        else:\n",
    "            counts[answer] = 1\n",
    "\n",
    "    max_answer = None\n",
    "    max_count = 0\n",
    "    \n",
    "    for answer, count in counts.items():\n",
    "        if count > max_count:\n",
    "            max_answer = answer\n",
    "            max_count = count\n",
    "    \n",
    "    return max_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda98b04",
   "metadata": {
    "papermill": {
     "duration": 0.041265,
     "end_time": "2024-10-31T13:26:53.548365",
     "exception": false,
     "start_time": "2024-10-31T13:26:53.507100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TIR Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d075049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:26:53.639214Z",
     "iopub.status.busy": "2024-10-31T13:26:53.638413Z",
     "iopub.status.idle": "2024-10-31T13:26:53.667325Z",
     "shell.execute_reply": "2024-10-31T13:26:53.666199Z"
    },
    "papermill": {
     "duration": 0.078137,
     "end_time": "2024-10-31T13:26:53.670124",
     "exception": false,
     "start_time": "2024-10-31T13:26:53.591987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TIRAgent:\n",
    "    def __init__(self, problem_id, id, problem, tokenizer, max_depth, log):\n",
    "        # problem id\n",
    "        self.problem_id = problem_id\n",
    "        # id of the agent\n",
    "        self.id = id\n",
    "        # number of LLM turns\n",
    "        self.depth = 1\n",
    "        # maximum number of turns allowed\n",
    "        self.max_depth = max_depth\n",
    "        # LLM's tokenizer\n",
    "        self.tokenizer = tokenizer\n",
    "        # Problem statement\n",
    "        self.problem = problem\n",
    "        # Chat Messages\n",
    "        self.messages = [{\"role\": \"system\", \n",
    "                \"content\": f\"\"\"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
    "                Your job is to solve math problems which have non-negative integer answers by following the steps: \n",
    "                1. Break this problem into smaller subproblems and solve each subproblem step-by-step. \n",
    "                2. You will solve most of the problem yourself but you can use python to perform big calculations only like a calculator.And you will tell the user to run the script.\n",
    "                3. Then using the result from the user, solve rest of the problem and put final answer (only the integer) within \\\\boxed{{}} \n",
    "                \"\"\"},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"\n",
    "{self.problem}.\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        # Last response from the LLM\n",
    "        self.last_response = None\n",
    "        # Code blocks from the last response\n",
    "        self.blocks = []\n",
    "        # Answers that the LLM generated in \\boxed{}\n",
    "        self.answers = []\n",
    "        # No python code generated in last response or max_depth reached\n",
    "        self.is_complete = False\n",
    "        # File to log answers\n",
    "        self.log = log\n",
    "        # Next prompt to the LLM\n",
    "        self.next_prompt = None\n",
    "        \n",
    "    def complete(self):\n",
    "        # is the Agent done\n",
    "        return self.is_complete\n",
    "    \n",
    "    def add_response(self, response, executor):\n",
    "        self.depth += 1\n",
    "        # remember this response\n",
    "        self.last_response = response\n",
    "        # add this to the messages history\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        # extract python blocks\n",
    "        self.blocks = find_python_blocks(response)\n",
    "        # extract answer from the generated text, if present\n",
    "        answer = extract_answer(response)\n",
    "        if answer is not None:\n",
    "            self.answers.append(answer)\n",
    "        # is it done?\n",
    "        self.is_complete = not self._should_continue()\n",
    "        # if not, use the python executor to create next prompt\n",
    "        if not self.is_complete:\n",
    "            self.next_prompt = self._next_prompt(executor) \n",
    "            self.messages.append({\"role\": \"user\", \"content\": self.next_prompt})\n",
    "    \n",
    "    def _should_continue(self):        \n",
    "        # quit if max_depth number of turns reached\n",
    "        if self.depth >= self.max_depth:\n",
    "            return False\n",
    "        # if no python code generated, we can stop now\n",
    "        elif len(self.blocks) > 0:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def _next_prompt(self, executor):\n",
    "        assert not self.is_complete\n",
    "        assert len(self.blocks) > 0\n",
    "        # get code result from python execution\n",
    "        output, status = execute(executor, self.blocks[-1])\n",
    "        \n",
    "        prompt = ''\n",
    "        # if code succeeds give the output\n",
    "        if status:\n",
    "            prompt = f\"\"\"The python code you provided gives the following output:\n",
    "```python\n",
    "{self.blocks[-1]}\n",
    "```\n",
    "```output\n",
    "{output}\n",
    "```\"\"\"\n",
    "        # if code fails, give the error\n",
    "        else:\n",
    "            prompt = f\"\"\"The python code you provided gives the following error:\n",
    "```python\n",
    "{self.blocks[-1]}\n",
    "```\n",
    "```output\n",
    "{output}\n",
    "```\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    \n",
    "    def next_message(self):\n",
    "        assert not self.is_complete \n",
    "        # apply chat template to get the text\n",
    "        text = self.tokenizer.apply_chat_template(\n",
    "            self.messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        return text\n",
    "        \n",
    "    \n",
    "    def final_answer(self):\n",
    "        # if there no answers yet, we have to return None\n",
    "        ans = None\n",
    "        # otherwise return the latest answer\n",
    "        if len(self.answers) > 0:\n",
    "            ans = self.answers[-1]\n",
    "        # log to file\n",
    "        if self.log:\n",
    "            self.log.writerow([self.problem_id, self.id, ans])\n",
    "        # try to convert to integer\n",
    "        try:\n",
    "            ans = int(ans)\n",
    "        except:\n",
    "            ans = None\n",
    "        \n",
    "        return ans        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df70e75",
   "metadata": {
    "papermill": {
     "duration": 0.042734,
     "end_time": "2024-10-31T13:26:53.775802",
     "exception": false,
     "start_time": "2024-10-31T13:26:53.733068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sc-TIR Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d32d427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:26:53.860840Z",
     "iopub.status.busy": "2024-10-31T13:26:53.859904Z",
     "iopub.status.idle": "2024-10-31T13:26:53.876217Z",
     "shell.execute_reply": "2024-10-31T13:26:53.874628Z"
    },
    "papermill": {
     "duration": 0.062329,
     "end_time": "2024-10-31T13:26:53.878555",
     "exception": false,
     "start_time": "2024-10-31T13:26:53.816226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SCTIRAgent:\n",
    "    def __init__(self, problem_id, problem, tokenizer, samples, max_depth, log):\n",
    "        # problem id\n",
    "        self.problem_id = problem_id\n",
    "        # problem statement\n",
    "        self.problem = problem\n",
    "        # LLM's tokenizer\n",
    "        self.tokenizer = tokenizer\n",
    "        # number of TIRAgents to create\n",
    "        self.samples = samples\n",
    "        # maximum number of turns\n",
    "        self.max_depth = max_depth\n",
    "        # TIR Agents\n",
    "        self.agents = [TIRAgent(problem_id, i, problem, tokenizer, max_depth, log) for i in range(samples)]\n",
    "        # log file\n",
    "        self.log = log\n",
    "    \n",
    "    def complete(self):\n",
    "        # only complete when all agents are done\n",
    "        for agent in self.agents:\n",
    "            if not agent.complete():\n",
    "                return False\n",
    "        return True\n",
    "        \n",
    "    def get_ready_agents(self):\n",
    "        # return agents that are not complete yet\n",
    "        ready_agents = []\n",
    "        for agent in self.agents:\n",
    "            if not agent.complete():\n",
    "                ready_agents.append(agent)\n",
    "        return ready_agents\n",
    "    \n",
    "    def final_answer(self):\n",
    "        # majority vote agent answers\n",
    "        assert self.complete()\n",
    "        answers = [agent.final_answer() for agent in self.agents]\n",
    "        print(self.problem_id)\n",
    "        print(answers)\n",
    "        answer = majority_vote(answers)\n",
    "        print(answer)\n",
    "        if answer is None:\n",
    "            return 0\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f15c19",
   "metadata": {
    "papermill": {
     "duration": 0.040579,
     "end_time": "2024-10-31T13:26:53.960883",
     "exception": false,
     "start_time": "2024-10-31T13:26:53.920304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c21daf50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:26:54.048458Z",
     "iopub.status.busy": "2024-10-31T13:26:54.046671Z",
     "iopub.status.idle": "2024-10-31T13:26:54.101874Z",
     "shell.execute_reply": "2024-10-31T13:26:54.099847Z"
    },
    "papermill": {
     "duration": 0.102028,
     "end_time": "2024-10-31T13:26:54.105106",
     "exception": false,
     "start_time": "2024-10-31T13:26:54.003078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vllm import SamplingParams\n",
    "trans_df=pd.read_csv(\"/kaggle/input/dlsprint3/test.csv\")\n",
    "sampling_paramsT= SamplingParams(n=1, temperature=0.5, top_p=0.8, max_tokens=5120)\n",
    "\n",
    "def predict(problem):\n",
    "    prompt = f\" Problem: {problem}.English:\"\n",
    "    messages =[\n",
    "                {\"role\": \"system\", \"content\": '''You are Qwen, created by Alibaba Cloud. You are a helpful assistant.Your job is to translate a given mathemtaical problem in Bengali to English by following steps.\n",
    "                1.perform a translation of each sentence\n",
    "                2.then make a full translation and put it in \\\\boxed{{}}\n",
    "                 '''},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=True\n",
    "            )\n",
    "\n",
    "        # Generate translations\n",
    "    # Generate translations\n",
    "    outputs = llm.generate([text], sampling_paramsT)\n",
    "\n",
    "    # Collect and process generated outputs\n",
    "    all_generated_texts = [out.text for out in outputs[0].outputs]\n",
    "\n",
    "    # Return the first translation result (or process as needed)\n",
    "    return all_generated_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4729bb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:26:54.195896Z",
     "iopub.status.busy": "2024-10-31T13:26:54.194265Z",
     "iopub.status.idle": "2024-10-31T13:26:54.202506Z",
     "shell.execute_reply": "2024-10-31T13:26:54.200902Z"
    },
    "papermill": {
     "duration": 0.05595,
     "end_time": "2024-10-31T13:26:54.205025",
     "exception": false,
     "start_time": "2024-10-31T13:26:54.149075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ex=(predict(trans_df.Problem[1]))\n",
    "#pr=extract_answer(ex)\n",
    "#ex,pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59fe4696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T13:26:54.340282Z",
     "iopub.status.busy": "2024-10-31T13:26:54.337115Z",
     "iopub.status.idle": "2024-10-31T14:04:18.638439Z",
     "shell.execute_reply": "2024-10-31T14:04:18.637488Z"
    },
    "papermill": {
     "duration": 2244.450655,
     "end_time": "2024-10-31T14:04:18.712192",
     "exception": false,
     "start_time": "2024-10-31T13:26:54.261537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:12<00:00, 12.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  0\n",
      "Problem:  How many maximum parts can a cake be divided into by cutting it linearly 2 times?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:23<00:00, 23.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  1\n",
      "Problem:  A pond has 100 stones placed on it. First, a frog jumps over the pond using the 1st, 2nd, 3rd,..., 99th, 100th stones. The second frog jumps over the pond using the 2nd, 4th, 6th,..., 98th, 100th stones. The third frog jumps over the pond using the 3rd, 6th, 9th,..., 99th stones. 100 frogs jumped in this manner. How many stones did an odd number of frogs jump on?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:21<00:00, 21.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  2\n",
      "Problem:  Let $f(x) = x^{67-x^{67-x^{67-\\dots}}}$, where $x \\neq 0$, if $f(n) = 64$, then what remainder will be left when $n^n$ is divided by 11?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:46<00:00, 46.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  3\n",
      "Problem:  Samin \\ and \\ Swarga \\ use \\ only \\ 0 \\ and \\ 1 \\ for \\ calculations. \\ They \\ do \\ not \\ recognize \\ any \\ other \\ digits. \\ Samin \\ has \\ a \\ 2024-digit \\ number, \\ where \\ all \\ the \\ digits \\ are \\ 1. \\ Samin \\ squares \\ that \\ number \\ and \\ gives \\ it \\ to \\ Swarga, \\ and \\ Swarga \\ subtracts \\ 1 \\ from \\ it \\ and \\ gives \\ it \\ to \\ you. \\ How \\ many \\ 1s \\ are \\ there \\ in \\ the \\ number \\ you \\ have?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:31<00:00, 31.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  4\n",
      "Problem:  A, B, C are three stands. To move 2 disks from stand A to stand B takes 3 moves, for 3 disks it takes 7 moves, and for 4 disks it takes 15 moves. Then, how many moves are needed to move 10 disks from stand A to stand B?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:16<00:00, 16.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  5\n",
      "Problem:  For\\ what\\ value\\ of\\ a\\ is\\ x^2 + 4x + 8y + 4xy + 4y^2 + axyz\\ divisible\\ by\\ x + 2y?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:14<00:00, 14.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  6\n",
      "Problem:  A clock has become abnormally damaged. After the clock strikes eleven o'clock at night, every time the hour hand completes a full rotation, the speed of the clock becomes half. Exactly at the moment when the state of the clock will be such that it will take more than 2024 minutes for one minute to pass, what time will the clock show?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:19<00:00, 19.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  7\n",
      "Problem:  Three friends Shahriyar, Sakib, and Sadia. Shahriyar has all the whole numbers from 1 to 10. Sakib has all the whole numbers from 11 to 20. Sadia has all the whole numbers from 21 to 30. Mithila wants to take 1 number from each friend in such a way that the sum of the three numbers is divisible by 3. How many ways can Mithila take those three numbers?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:17<00:00, 17.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  8\n",
      "Problem:  A \\text{ is } 70\\% \\text{ of } B, B \\text{ is } 50\\% \\text{ of } C, C \\text{ is } 40\\% \\text{ of } D. \\text{ Then, what percent of } D \\text{ is } A?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:17<00:00, 17.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  9\n",
      "Problem:  A dragon burns 5 trees every 10th minute. Majed and Emon - two warriors are standing with guns. Majed can shoot every 6 minutes and Emon can shoot every 14 minutes. The problem is, the dragon does not get hit unless both shoot at the same time. If the dragon flies away after getting hit 3 times, then how many trees has the dragon burned in total?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:14<00:00, 14.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  10\n",
      "Problem:  If the product of two consecutive positive integers is 10712, how many factors does the smaller number have?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:12<00:00, 12.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  11\n",
      "Problem:  For what minimum value of $k$ is $\\sqrt{70 \\times k!}$ a whole number?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:17<00:00, 17.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  12\n",
      "Problem:  If Shahrazad did not tell one story every night and instead told $\\gcd(k, 101)$ stories on the $k$-th night, how many stories would there be in total over these 1001 nights? (Here, $\\gcd(k,101)$ is the greatest common divisor of $k$ and 101.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:18<00:00, 18.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  13\n",
      "Problem:  If Payel wants to set a 3-digit password on her mobile phone, then how many different ways can Payel set the password?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:40<00:00, 40.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  14\n",
      "Problem:  If\\ the\\ infinite\\ sum\\ of\\ the\\ series\\ 1 - \\left(\\frac{3!}{2! \\times 1! \\times 2^1}\\right) + \\left(\\frac{4!}{2! \\times 2! \\times 2^2}\\right) - \\left(\\frac{5!}{2! \\times 3! \\times 2^3}\\right) + \\dots\\ can\\ be\\ expressed\\ as\\ \\frac{m}{n},\\ find\\ the\\ value\\ of\\ m \\times n\\ (where\\ m\\ and\\ n\\ are\\ coprime).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:26<00:00, 26.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  15\n",
      "Problem:  In a $5 \\times 5$ chessboard, in how many ways can two Bishops be placed such that they do not attack each other in a single move? (Note, on the chessboard, a Bishop can move any number of spaces diagonally.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:21<00:00, 21.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  16\n",
      "Problem:  Let $f: N \\to R$ where $f(x) = \\log_{2024}{x}$. Then determine the minimum value of $k$ such that $ \\sum_{n = 1}^{k} f(n) \\geq 2 $.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:13<00:00, 13.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  17\n",
      "Problem:  How many ordered pairs $(a, b)$ are possible such that $gcd(a, b) + lcm(a, b) = 2023$?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:27<00:00, 27.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  18\n",
      "Problem:  Find the value of $n$ in the equation $\\frac{1+3+5+\\dots+(2n+1)}{\\frac{1}{2} + \\frac{1}{6} + \\frac{1}{12} + \\dots + \\frac{1}{342}} = 342$.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:14<00:00, 14.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  19\n",
      "Problem:  Using the digits 1,2,3,4 only once, how many 3-digit numbers can be formed?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:54<00:00, 54.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  20\n",
      "Problem:  \n",
      "A drop of coffee is located at point $A$ on the upper edge of a cylindrical coffee cup with a diameter of 4 cm and a height of 9 cm. Point $B$ is located directly opposite point $A$ on the bottom of the coffee cup such that the three-dimensional distance from $A$ to $B$ is maximized. Determine the value of $a + b$ if the drop of coffee travels the shortest distance of $\\sqrt{a\\pi^2 + b}$ cm from point $A$ to point $B$ along the surface of the cup.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:11<00:00, 11.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  21\n",
      "Problem:  If the cost of 4 bananas is 32 rupees, find the cost of 1 dozen bananas.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:39<00:00, 39.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  22\n",
      "Problem:  Niloy threw two dice, one red and one blue, each having 6 faces with numbers 1 to 6 written on them. After throwing the dice, if Niloy gets a prime number by adding the two numbers obtained from the two dice, he calls that pair a \"wonderful pair\". How many \"wonderful pairs\" can Niloy get?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:31<00:00, 31.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  23\n",
      "Problem:  x^2 + 45y - 2025 = 0 \\text{ and } y^2 - 45x - 2025 = 0 \\text{ are a pair of equations with four real solutions } (x_1, y_1), (x_2, y_2), (x_3, y_3) \\text{ and } (x_4, y_4), \\text{ where } x_1 > x_2 > x_3 > x_4 \\text{ and } y_2 > y_3 > y_4 > y_1. \\text{ If } x_1 + y_2 \\text{ can be expressed in the form } \\frac{a + b \\cdot \\sqrt{c}}{d}, \\text{ then determine the value of } a+b+c+d.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:17<00:00, 17.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  24\n",
      "Problem:  In a dormitory, how many people at least need to be there so that it can be said with certainty that at least 13 of them were born in the same month?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:42<00:00, 42.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  25\n",
      "Problem:  \\text{Consider a positive integer } n \\text{ such that } n! \\text{ is divisible by } 2^{3072}, 3^{2048}, \\text{ and } 5^{1024} \\text{ without remainder. Determine the value of } n. \\text{ [For any positive integer } k, k! = 1 \\times 2 \\times 3 \\times 4 \\times \\dots \\times (k - 1) \\times k \\text{]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:22<00:00, 22.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  26\n",
      "Problem:  $x$, $y$, and $z$ are real numbers such that $(4^x +1)(4^y + 8)(4^z + 32) = 2^{x + y + z + 7}$. Determine the value of $x + y + z$.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:22<00:00, 22.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  27\n",
      "Problem:  '6' is written in front of a three-digit number. If the double of the new four-digit number is 50 times the first number, find the three-digit number.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:19<00:00, 19.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  28\n",
      "Problem:  The difference in age between the two brothers is 5 years. If the elder brother's age is currently 24 years, what will be the younger brother's age 10 years later?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:13<00:00, 13.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  29\n",
      "Problem:  The difference between the $n$-th term and the $(n - 1)$-th term, when subtracted from the product of the two terms, gives the $(n + 1)$-th term. If the first two terms of the series are 1 and 2, find the 999th term.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:36<00:00, 36.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  30\n",
      "Problem:  \\lceil {\\frac{n+(n+1)}{n+2}} \\rceil + \\lceil {\\frac{(n + 1) + (n + 2)}{(n + 3)}} \\rceil + \\lceil {\\frac{(n + 2) + (n + 3)}{n + 4}} \\rceil + \\dots + \\lceil {\\frac{(n+m-2)+(n+m-1)}{n+m}} \\rceil =201, \\text{ where } 0 < n < 1. \\text{ Find the value of } m. \\lceil \\rceil \\text{ represents the ceiling function, which gives the next integer of any decimal number. For example, } \\left\\lceil {2.1} \\right\\rceil = 3, \\left\\lceil {3} \\right\\rceil = 3, \\left\\lceil {2.6} \\right\\rceil = 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:15<00:00, 15.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  31\n",
      "Problem:  If\\ x + y + z = 0\\ and\\ (x+y)(y+z)(z+x) = -20,\\ find\\ the\\ value\\ of\\ xyz.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:19<00:00, 19.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  32\n",
      "Problem:  The sum of the given series \\frac{2}{3} + \\frac{3}{3^2} + \\frac{2}{3^3} + \\frac{3}{3^4} + \\frac{2}{3^5} + \\frac{3}{3^6} + \\dots can be expressed as \\frac{a}{b}, where a and b are coprime numbers. Determine the value of a + b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:26<00:00, 26.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  33\n",
      "Problem:  A list of all subsets formed by taking 4 elements each from $S = \\{2, 6, 12, 24, 25, 30, 40\\}$ is made. What will be the sum of the highest numbers in each subset of the list?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:22<00:00, 22.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  34\n",
      "Problem:  f(0) = 0; f(1) = 1; f(n) = f(n - 1) - f(n - 2); \\text{Find the value of } f(0) + f(1) + f(2) +...+f(2024).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:16<00:00, 16.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  35\n",
      "Problem:  Payel decided to paint some part of the courtyard in front of her house. She went straight 12 meters from the door, then went 6 meters to the right. Then she came straight back to the door. The area formed by this will be completely painted. If 1 box of paint is needed to paint every 6 square meters of area, how many boxes of paint will be needed to paint the entire area?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:24<00:00, 24.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  36\n",
      "Problem:  A magic box is in front of Pratik where if some amount of money is kept, at the end of the day 2 more money is returned from the box. One day he kept 1 money in the box, at the end of the first day he got 3 money, at the end of the second day he got 5 money, in this way after 17 days his total money became $x$ amount. He keeps all the money in the box. The next day he gets back the amount equal to the LCM of $x$ and 500. How much money does he have in total now?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:12<00:00, 12.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  37\n",
      "Problem:  What is the sum of the first 100 terms of the series -1+2-3+4-5+6-7+8...?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:14<00:00, 14.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  38\n",
      "Problem:  If the average of two positive integers is 16 and their difference is 4, what will be the product of the two numbers?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:44<00:00, 44.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  39\n",
      "Problem:  Emon is trapped inside a glass sphere. Standing on the surface of the sphere, he holds a laser light in such a way that it bends at a certain angle before entering the sphere. If $a = 60^\\circ$, the light bends 2 times on the surface of the sphere and returns to Emon. How many times at minimum will the light bend and return to Emon if $a = 20^\\circ$?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:23<00:00, 23.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  40\n",
      "Problem:  Find such two-digit numbers, which are exactly divisible by the sum of their digits and the unit digit of the numbers is 1. What is the sum of these numbers?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:17<00:00, 17.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  41\n",
      "Problem:  A dragon burns 5 trees every 10th minute. Majed and Emon, two warriors, are standing with guns. Majed can shoot every 3 minutes and Emon can shoot every 13 minutes. The problem is, the dragon does not get hit unless both of them shoot at the same time. If the dragon flies away after receiving 2 hits, how many trees has the dragon burned in total?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:19<00:00, 19.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  42\n",
      "Problem:  How \\, many \\, different \\, three-digit \\, numbers \\, of \\, the \\, form \\, \\overline{A5B} \\, are \\, divisible \\, by \\, 4? \\, (A \\, and \\, B \\, can \\, be \\, the \\, same \\, digit).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:11<00:00, 11.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  43\n",
      "Problem:  A positive square number has $n$ digits. When the number is squared, the number of digits of the number becomes $n+8$. If the square root of the number has $n - k$ digits, find the value of $k$.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:29<00:00, 29.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  44\n",
      "Problem:  'a' is a six-digit number. By writing 6 at the end of 'a', a seven-digit number 'b' is obtained. By writing 2 at the beginning of 'a', a seven-digit number 'c' is obtained. If 3c = b, then what is the value of 'a'?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:56<00:00, 56.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  45\n",
      "Problem:  A \\text{ drop of coffee is at point } A \\text{ on the upper edge of a cylindrical coffee cup with a diameter of 4 cm and a height of 7 cm. Point } B \\text{ is located directly opposite point } A \\text{ on the bottom of the coffee cup such that the three-dimensional distance from } A \\text{ to } B \\text{ is maximized. Determine the value of } a + b \\text{ if the drop of coffee travels the minimum distance of } \\sqrt{a\\pi^2 + b} \\text{ cm from point } A \\text{ to point } B \\text{ along the surface of the cup.}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:18<00:00, 18.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  46\n",
      "Problem:  In a football match, the final score is 3-2. How many different ways can the scores be at halftime such that the difference in goals is always 1?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:21<00:00, 21.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  47\n",
      "Problem:  How many ordered tuples $(a, b, c, d)$ are possible such that $5 | (ad - bc + 2024)$, where $a, b, c, d \\in \\{0, 1, 2, 3... 24\\}$?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:19<00:00, 19.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  48\n",
      "Problem:  Tahmid \\ has \\ the \\ numbers \\ $1, 2, 3, 5, 7, 9$. \\ He \\ uses \\ these \\ numbers \\ exactly \\ once \\ to \\ form \\ as \\ many \\ 6-digit \\ numbers \\ as \\ possible. \\ The \\ probability \\ that \\ a \\ number \\ formed \\ is \\ divisible \\ by \\ $12$ \\ is \\ $\\frac{M}{N}$, \\ where \\ $M$ \\ and \\ $N$ \\ are \\ relatively \\ prime \\ numbers. \\ Then, \\ determine \\ the \\ value \\ of \\ $M + N$.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:23<00:00, 23.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  49\n",
      "Problem:  Saif loves to discover new things in mathematics. He discovered a new operator like addition, subtraction, multiplication, and division. He named this operator the Diamond Operator ($\\diamond$). The job of the Diamond Operator is that if you put the Diamond Operator between two numbers, you will get the product of the sum and the difference of the two numbers. For example, $5 \\diamond 3 = (5 + 3)(5 - 3)$. Then, if Saif calculates the value of $(12 \\diamond 11) \\diamond 2$, what will he get?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:12<00:00, 12.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  50\n",
      "Problem:  Determine\\ the\\ next\\ term\\ of\\ the\\ sequence\\ 34,\\ 35,\\ 37,\\ 40\\ \\dots.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:25<00:00, 25.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  51\n",
      "Problem:  $x$ and $y$ are two positive integers. $xy = 196$ and the least common multiple (LCM) of $x$ and $y$ is not equal to either of the numbers. Determine the maximum value of $x + y$.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:09<00:00,  9.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  52\n",
      "Problem:  A family cooks 6 kg of rice for 9 days for 8 members. If 4 guests stay in that house for 15 days, how much total rice in kg will be needed for 15 days?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:19<00:00, 19.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  53\n",
      "Problem:  Chingku has built a machine where if an English word (it's not necessary to be meaningful) is input, it sequentially writes the numbers that represent the order of each letter and shows it as output. For example, if the input is \"abc\", the output is 123, if the input is \"dydx\", the output is 425424. How many words in total can be input by Chingku so that the output is 212121?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:17<00:00, 17.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  54\n",
      "Problem:  How many positive integers are there whose digits sum to 12, the average of the digits is 2, and all digits are non-zero?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:26<00:00, 26.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  55\n",
      "Problem:  You have an infinite number of 2, 3, and 4 dollar notes. You need to buy a pen that costs 12 dollars. In how many ways can you buy that pen by giving exactly 12 dollars using those notes?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:25<00:00, 25.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  56\n",
      "Problem:  2 candidates are standing for the class captain election. The total number of students in the classroom is 40. How many votes must one candidate receive to be certain that they have won the election?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:20<00:00, 20.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  57\n",
      "Problem:  Anupam has a magic box where any number placed in it turns into the square of that number the next day. Anupam loves to play with that box. On the first day, he puts 23 in the box and the next day, after getting the number, he discards the rest of the digits except the last two and keeps the remaining number back in the box. If he continues this process every day, what number will he put in the box on the 2024th day?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:29<00:00, 29.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  58\n",
      "Problem:  n! \\text{ (n factorial) is the product of all whole numbers from 1 to n. Arif added 3 to the factorial of a number and found that it is a perfect cube. What is the highest number that Arif could have chosen?}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:29<00:00, 29.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  59\n",
      "Problem:  Tahmid wrote a positive integer on the board, each digit of which is 2 and the number is divisible by 6666. If the number written by Tahmid is the smallest among all such possible numbers, how many 2's are there in the number?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:09<00:00,  9.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  60\n",
      "Problem:  What will be the sum when thirty is added to seven hundred eighty-one?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:12<00:00, 12.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  61\n",
      "Problem:  The\\ sum\\ of\\ two\\ prime\\ numbers\\ is\\ 7.\\ What\\ is\\ the\\ product\\ of\\ the\\ two\\ numbers?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:26<00:00, 26.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  62\n",
      "Problem:  The digits of a whole number are 2, 3, 5, and 7, and each of these appears at least twice. The number is not divisible by any of its own digits. What is the minimum value of the number?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:13<00:00, 13.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  63\n",
      "Problem:  A regular cube's face midpoints are connected to form a quadrilateral bipyramid shape. The ratio of the volume of this bipyramid to the volume of the cube is $m/n$, where $m$ and $n$ are relatively prime. Now find the value of $m + n$.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:16<00:00, 16.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  64\n",
      "Problem:  f(x) + 2f(-x) = 2x; 2f(x) + f(-x) = x^2; \\text{From 1 to 2024, how many values of } x \\text{ are there for which both } x \\text{ and } f(x) \\text{ are integers?}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:10<00:00, 10.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  65\n",
      "Problem:  What is the least square number divisible by 35, 48, and 63?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:22<00:00, 22.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  66\n",
      "Problem:  Majed loves to discover new things in mathematics. He discovered a new operator like addition, subtraction, multiplication, and division. He named this operator the Diamond Operator ($\\diamond$). The function of the Diamond Operator is that when you place the Diamond Operator between two numbers, you get the product of the sum and the difference of those two numbers. For example, $5 \\diamond 3 = (5+3) \\times (5-3)$. Then, in the same way, if Majed calculates the value of $(9 \\diamond 7) \\diamond 5$, what will he get?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:29<00:00, 29.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  67\n",
      "Problem:  In a chess tournament with 16 players, in each round, each one plays with every other three times. If in each round, half of the competitors are eliminated, then how many matches will be played in total to choose the winner in the tournament?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:36<00:00, 36.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  68\n",
      "Problem:  What is the least positive integer that can be added to 350 to make it a perfect square number? (A perfect square number is a positive integer that can be expressed as the product of an integer and the same integer. For example: 25 = 55, 36 = 66, etc.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:26<00:00, 26.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  69\n",
      "Problem:  If a year is a leap year, then that year's February month has twenty-nine days. The probability of having 53 Fridays in such a leap year can be written in the form $\\frac{a}{b}$. Determine the minimum value of a + b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:19<00:00, 19.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  70\n",
      "Problem:  The lengths of the sides of two squares are 5 and 9 respectively. What is the difference in the perimeters of the largest and the smallest square?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:20<00:00, 20.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  71\n",
      "Problem:  In the equation \\sqrt{a + b} + \\sqrt{c + d} = \\sqrt{6250}, where a, b, c, and d are integers, find the minimum value of a + b + c + d.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:15<00:00, 15.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  72\n",
      "Problem:  If $f(x) = 256^{2^{-(x+1)}}$, then find the value of $\\prod_{i=1}^{\\infty} f(i)$.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:19<00:00, 19.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  73\n",
      "Problem:  For what lowest odd value of $n$ is $2025^n - 2024n - 1$ divisible by $2024^3$ (where, $n > 1$)?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:15<00:00, 15.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  74\n",
      "Problem:  How many pairs of prime numbers less than 100 can be found such that their difference is a prime number?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:22<00:00, 22.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  75\n",
      "Problem:  If \\ a = 3 \\ and \\ r = \\frac{1}{3}, \\ then \\ \\prod_{i=0}^{6}(a \\times r^i) = c^d, \\ where \\ c \\ is \\ a \\ prime \\ number, \\ find \\ the \\ value \\ of \\ c - d. \\ Just \\ as \\ \\Sigma \\ denotes \\ a \\ sum, \\ \\prod \\ denotes \\ a \\ product. \\ For \\ example: \\ \\prod_{i=1}^{4}(2 \\times i) = 2 \\times 4 \\times 6 \\times 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:10<00:00, 10.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  76\n",
      "Problem:  A cyclic trapezium is drawn, whose circumcircle has a radius of 10. If the perpendicular distance between the two parallel sides of the trapezium is 12, what is the maximum possible area of the trapezium?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:14<00:00, 14.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  77\n",
      "Problem:  Using the digits 1, 2, 7 only once, how many two-digit numbers can be created?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:18<00:00, 18.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  78\n",
      "Problem:  The price of a book is 76 taka. You buy the book at a 25% discount. After the discount, how much money did you pay for the book?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:47<00:00, 47.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  79\n",
      "Problem:  \\text{Joytir's exam has 6 questions and she has the answers to all 6 questions but she doesn't know which answer corresponds to which question. If she writes the correct answer out of the 6 answers she has for each question, she will get 1 mark. The probability of her getting 0 in that exam can be expressed as } \\frac{a}{b} \\text{, where a and b are coprime. Find the value of a + b.}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:24<00:00, 24.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  80\n",
      "Problem:  There are so many whole numbers k between 1 and 100 (including 1 and 100) whose product of all factors can be written in the form of \"$k^{\\frac{9}{2}}$. Find the sum of those numbers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:11<00:00, 11.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  81\n",
      "Problem:  A number will be called a magic number if it can be expressed in the form $2^n + n^2$ for any integer $n$, and the number can only be divided by two numbers. Find the sum of all magic numbers less than 2024.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:11<00:00, 11.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  82\n",
      "Problem:  What is the digit in the fourth decimal place when 6789 is divided by 43?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:51<00:00, 51.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  83\n",
      "Problem:  Manisha bought a notebook with 256 pages. On the first day, Tunna marks every page with a pencil, and Manisha erases the mark from every second page. The next day, Tunna marks every third page again, and Manisha erases the mark from every fourth page. This continues for 128 days. After 128 days, how many pages in the notebook still have marks?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:26<00:00, 26.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  84\n",
      "Problem:  In an exam, the average of the scores of 12 students is 90. Due to the correction of one student's score, the average increased by 2 points. By how much did that student's score increase?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:13<00:00, 13.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  85\n",
      "Problem:  What will be the remainder when the number 20232024+20242025 is divided by 6?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:14<00:00, 14.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  86\n",
      "Problem:  If the largest angle of a triangle is 80, determine the minimum possible value of the smallest angle.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:30<00:00, 30.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  87\n",
      "Problem:  B \\text{ is a point on the semicircle with diameter } AC \\text{ such that } AB < AC. D \\text{ is the midpoint of } AC \\text{ and } E \\text{ is a point on } BC \\text{ such that } ED \\text{ is perpendicular to } AC. \\text{ If } AC = 20, \\text{ what is the maximum area of triangle } BDE?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:33<00:00, 33.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  88\n",
      "Problem:  At the beginning of a tree's life, there is one leaf. At any time, any leaf is destroyed and two unique branches are formed there, each having one leaf. In this way, at one point, the number of leaves becomes 7. How many ways can the tree reach that stage?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:20<00:00, 20.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  89\n",
      "Problem:  $w$, $x$, $y$, $z$ are four odd numbers such that $w! \\times x! \\times y! \\times z! = 10!$. Determine the value of $w \\times x \\times y \\times z$.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:09<00:00,  9.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  90\n",
      "Problem:  A triangle's three angles are respectively $4x - 8$, $3x - 7$ and $2x + 6$ degrees. Determine the difference between the largest and the smallest angle.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:24<00:00, 24.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  91\n",
      "Problem:  f(n) \\text{ is the square of the sum of the digits of the number } n. \\ f_2(n) = f(f(n)), f_3(n) = f(f(f(n))), f_4(n) = f(f(f(f(n)))), ... \\ What \\ is \\ the \\ value \\ of \\ f_{2024}(2)?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:45<00:00, 45.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  92\n",
      "Problem:  Emon has a large solid cylinder with a radius of 6561 units. He wants to cut the cylinder from the outside in such a way that only one solid cylinder remains at the end, and the outer radius of the pipes obtained after cutting decreases by a factor of three in sequence. If the radius of the pipes and the cylinder are whole numbers, then what is the maximum number of pipes that can be obtained?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:21<00:00, 21.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  93\n",
      "Problem:  The average of 30 positive integers is 40 and the average of another 40 positive integers is 12. Then find the average of the total 70 integers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:21<00:00, 21.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  94\n",
      "Problem:  If the sum of n consecutive whole numbers is divisible by n, then n is called a magic number. How many such magic numbers are there between 1 and 2024?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:14<00:00, 14.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  95\n",
      "Problem:  A box has some red and blue balls. If one more red ball is added, then the probability of getting a red ball becomes equal to the probability of getting a blue ball. If three more blue balls are added, then the probability of getting a blue ball becomes twice the probability of getting a red ball. How many balls are there in the box?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:28<00:00, 28.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  96\n",
      "Problem:  A four-digit whole number is divisible by 11 without any remainder. If the last two digits of the number are removed and placed at the front, it becomes divisible by 4. For example, if the number is $abcd$, then $cdab$ will be divisible by 4. Find the sum of such possible numbers where the difference between the first and last digits is 6. For example, one such number is 7271, which is divisible by 11. When the last two digits are removed and placed at the front, the number becomes 7172, which is divisible by 4, and the difference between the first and last digits of 7271 is 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:18<00:00, 18.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  97\n",
      "Problem:  How many positive integers are there that are factors of at least one of the numbers $12^{12}, 14^{12}$, and $18^9$?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:11<00:00, 11.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  98\n",
      "Problem:  The sum of 3 consecutive whole numbers is 216, what is the smallest number?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 1/1 [00:12<00:00, 12.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  99\n",
      "Problem:  A magician gave you a certain number of pencils on the first day. After that, the magician gives you twice the number of pencils given the previous day every day. You noticed on the fourth day that you have 60 pencils, so how many pencils did the magician give you on the first day?\n",
      "Submission saved to /kaggle/working/trans.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Iterate through each row in the test data\n",
    "for idx, row in trans_df.iterrows():\n",
    "         \n",
    "         problem = row['Problem']  # Extract the problem text\n",
    "         trans = predict(problem)  # Get the prediction using the model\n",
    "         trans=extract_answer(trans)\n",
    "         print(\"Problem: \",idx)\n",
    "         print(\"Problem: \",trans)\n",
    "         results.append({\"ID\": idx,  \n",
    "                        \"problem\": trans\n",
    "                                })\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "sub_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "submission_file_path = '/kaggle/working/trans.csv'  # Define where to save the submission file\n",
    "sub_df.to_csv(submission_file_path, index=False)\n",
    "\n",
    "print(f\"Submission saved to {submission_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a0b0cf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T14:04:18.871950Z",
     "iopub.status.busy": "2024-10-31T14:04:18.871570Z",
     "iopub.status.idle": "2024-10-31T14:04:18.878478Z",
     "shell.execute_reply": "2024-10-31T14:04:18.877584Z"
    },
    "papermill": {
     "duration": 0.089653,
     "end_time": "2024-10-31T14:04:18.880483",
     "exception": false,
     "start_time": "2024-10-31T14:04:18.790830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_csv('/kaggle/working/trans.csv')\n",
    "#test_df['ID'] = range(len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa11dd64",
   "metadata": {
    "papermill": {
     "duration": 0.080642,
     "end_time": "2024-10-31T14:04:19.040913",
     "exception": false,
     "start_time": "2024-10-31T14:04:18.960271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load 5 problems since we are short on time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b67434f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T14:04:19.212849Z",
     "iopub.status.busy": "2024-10-31T14:04:19.211925Z",
     "iopub.status.idle": "2024-10-31T14:04:19.231589Z",
     "shell.execute_reply": "2024-10-31T14:04:19.230658Z"
    },
    "papermill": {
     "duration": 0.107262,
     "end_time": "2024-10-31T14:04:19.233628",
     "exception": false,
     "start_time": "2024-10-31T14:04:19.126366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How many maximum parts can a cake be divided i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A pond has 100 stones placed on it. First, a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Let $f(x) = x^{67-x^{67-x^{67-\\dots}}}$, where...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Samin \\ and \\ Swarga \\ use \\ only \\ 0 \\ and \\ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A, B, C are three stands. To move 2 disks from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>A box has some red and blue balls. If one more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>A four-digit whole number is divisible by 11 w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>How many positive integers are there that are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>The sum of 3 consecutive whole numbers is 216,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>A magician gave you a certain number of pencil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                            problem\n",
       "0    0  How many maximum parts can a cake be divided i...\n",
       "1    1  A pond has 100 stones placed on it. First, a f...\n",
       "2    2  Let $f(x) = x^{67-x^{67-x^{67-\\dots}}}$, where...\n",
       "3    3  Samin \\ and \\ Swarga \\ use \\ only \\ 0 \\ and \\ ...\n",
       "4    4  A, B, C are three stands. To move 2 disks from...\n",
       "..  ..                                                ...\n",
       "95  95  A box has some red and blue balls. If one more...\n",
       "96  96  A four-digit whole number is divisible by 11 w...\n",
       "97  97  How many positive integers are there that are ...\n",
       "98  98  The sum of 3 consecutive whole numbers is 216,...\n",
       "99  99  A magician gave you a certain number of pencil...\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0c81c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T14:04:19.396230Z",
     "iopub.status.busy": "2024-10-31T14:04:19.395839Z",
     "iopub.status.idle": "2024-10-31T14:04:19.400645Z",
     "shell.execute_reply": "2024-10-31T14:04:19.399626Z"
    },
    "papermill": {
     "duration": 0.088483,
     "end_time": "2024-10-31T14:04:19.402621",
     "exception": false,
     "start_time": "2024-10-31T14:04:19.314138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    test_df = test_df[:5]\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac2a114",
   "metadata": {
    "papermill": {
     "duration": 0.080617,
     "end_time": "2024-10-31T14:04:19.563249",
     "exception": false,
     "start_time": "2024-10-31T14:04:19.482632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configure LLM and Python REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a56adf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T14:04:19.724988Z",
     "iopub.status.busy": "2024-10-31T14:04:19.724125Z",
     "iopub.status.idle": "2024-10-31T14:04:19.728990Z",
     "shell.execute_reply": "2024-10-31T14:04:19.728033Z"
    },
    "papermill": {
     "duration": 0.087916,
     "end_time": "2024-10-31T14:04:19.730919",
     "exception": false,
     "start_time": "2024-10-31T14:04:19.643003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampling_params = vllm.SamplingParams(max_tokens=10500, temperature=.35, top_p=.775)\n",
    "executor = PythonREPL()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06d7a81",
   "metadata": {
    "papermill": {
     "duration": 0.079617,
     "end_time": "2024-10-31T14:04:19.891045",
     "exception": false,
     "start_time": "2024-10-31T14:04:19.811428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run the Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0c9d63",
   "metadata": {
    "papermill": {
     "duration": 0.079074,
     "end_time": "2024-10-31T14:04:20.051050",
     "exception": false,
     "start_time": "2024-10-31T14:04:19.971976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TIR Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f53bf406",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-10-31T14:04:20.213663Z",
     "iopub.status.busy": "2024-10-31T14:04:20.213278Z",
     "iopub.status.idle": "2024-10-31T14:04:20.219881Z",
     "shell.execute_reply": "2024-10-31T14:04:20.219070Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.089904,
     "end_time": "2024-10-31T14:04:20.221772",
     "exception": false,
     "start_time": "2024-10-31T14:04:20.131868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for row in test_df.values[:2]:\\n    problem_id = row[0]\\n    problem = row[1]\\n    \\n    agent = TIRAgent(problem_id, 0, problem, tokenizer, max_depth=4, log=None)\\n    \\n    while not agent.complete():\\n        text = agent.next_message()\\n        # get response from LLM\\n        response = llm.generate([text], sampling_params)\\n        # pass in python executor, since response might contain python code\\n        agent.add_response(response[0].outputs[0].text, executor)\\n    \\n    for message in agent.messages:\\n        print(f\"Role: {message[\\'role\\']}\\n\")\\n        print(f\"Content:\\n {message[\\'content\\']}\\n\")\\n    \\n    answer = agent.final_answer()\\n    print(f\"Final answer: {answer}\")'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for row in test_df.values[:2]:\n",
    "    problem_id = row[0]\n",
    "    problem = row[1]\n",
    "    \n",
    "    agent = TIRAgent(problem_id, 0, problem, tokenizer, max_depth=4, log=None)\n",
    "    \n",
    "    while not agent.complete():\n",
    "        text = agent.next_message()\n",
    "        # get response from LLM\n",
    "        response = llm.generate([text], sampling_params)\n",
    "        # pass in python executor, since response might contain python code\n",
    "        agent.add_response(response[0].outputs[0].text, executor)\n",
    "    \n",
    "    for message in agent.messages:\n",
    "        print(f\"Role: {message['role']}\\n\")\n",
    "        print(f\"Content:\\n {message['content']}\\n\")\n",
    "    \n",
    "    answer = agent.final_answer()\n",
    "    print(f\"Final answer: {answer}\")'''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656d8b22",
   "metadata": {
    "papermill": {
     "duration": 0.08062,
     "end_time": "2024-10-31T14:04:20.382891",
     "exception": false,
     "start_time": "2024-10-31T14:04:20.302271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SC-TIR Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e1af02c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T14:04:20.546083Z",
     "iopub.status.busy": "2024-10-31T14:04:20.545724Z",
     "iopub.status.idle": "2024-10-31T14:04:20.552963Z",
     "shell.execute_reply": "2024-10-31T14:04:20.552013Z"
    },
    "papermill": {
     "duration": 0.090885,
     "end_time": "2024-10-31T14:04:20.554918",
     "exception": false,
     "start_time": "2024-10-31T14:04:20.464033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for row in trans_df.values[85:86]:\\n    problem_id = row[0]\\n    problem = \"A pond has 100 stones placed on it. First, a frog jumps over the pond using the 1st, 2nd, 3rd,..., 99th, 100th stones. The second frog jumps over the pond using the 2nd, 4th, 6th,..., 98th, 100th stones. The third frog jumps over the pond using the 3rd, 6th, 9th,..., 99th stones. 100 frogs jumped in this manner. How many stones did an odd number of frogs jump on?\"\\n    \\n    agent = SCTIRAgent(problem_id, problem, tokenizer, samples=4, max_depth=4, log=None)\\n    \\n    while not agent.complete():\\n        ready_agents = agent.get_ready_agents()\\n        texts = [a.next_message() for a in ready_agents]\\n        # get response from LLM\\n        responses = llm.generate(texts, sampling_params)\\n        # pass response to the agents\\n        for i, ready_agent in enumerate(ready_agents):\\n            print(responses[i].outputs[0].text)\\n            ready_agent.add_response(responses[i].outputs[0].text, executor)\\n    \\n    answer = agent.final_answer()\\n    print(f\"Problem: {problem}\")\\n    print(f\"Final answer: {answer}\")'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for row in trans_df.values[85:86]:\n",
    "    problem_id = row[0]\n",
    "    problem = \"A pond has 100 stones placed on it. First, a frog jumps over the pond using the 1st, 2nd, 3rd,..., 99th, 100th stones. The second frog jumps over the pond using the 2nd, 4th, 6th,..., 98th, 100th stones. The third frog jumps over the pond using the 3rd, 6th, 9th,..., 99th stones. 100 frogs jumped in this manner. How many stones did an odd number of frogs jump on?\"\n",
    "    \n",
    "    agent = SCTIRAgent(problem_id, problem, tokenizer, samples=4, max_depth=4, log=None)\n",
    "    \n",
    "    while not agent.complete():\n",
    "        ready_agents = agent.get_ready_agents()\n",
    "        texts = [a.next_message() for a in ready_agents]\n",
    "        # get response from LLM\n",
    "        responses = llm.generate(texts, sampling_params)\n",
    "        # pass response to the agents\n",
    "        for i, ready_agent in enumerate(ready_agents):\n",
    "            print(responses[i].outputs[0].text)\n",
    "            ready_agent.add_response(responses[i].outputs[0].text, executor)\n",
    "    \n",
    "    answer = agent.final_answer()\n",
    "    print(f\"Problem: {problem}\")\n",
    "    print(f\"Final answer: {answer}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8447131",
   "metadata": {
    "papermill": {
     "duration": 0.080263,
     "end_time": "2024-10-31T14:04:20.715266",
     "exception": false,
     "start_time": "2024-10-31T14:04:20.635003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c3d1a",
   "metadata": {
    "papermill": {
     "duration": 0.081359,
     "end_time": "2024-10-31T14:04:20.876782",
     "exception": false,
     "start_time": "2024-10-31T14:04:20.795423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f396b0",
   "metadata": {
    "papermill": {
     "duration": 0.080619,
     "end_time": "2024-10-31T14:04:21.041922",
     "exception": false,
     "start_time": "2024-10-31T14:04:20.961303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Also log agent answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f764830f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T14:04:21.206618Z",
     "iopub.status.busy": "2024-10-31T14:04:21.206218Z",
     "iopub.status.idle": "2024-10-31T14:04:21.214568Z",
     "shell.execute_reply": "2024-10-31T14:04:21.213672Z"
    },
    "papermill": {
     "duration": 0.092395,
     "end_time": "2024-10-31T14:04:21.216490",
     "exception": false,
     "start_time": "2024-10-31T14:04:21.124095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('submission1.csv', 'w', encoding='utf-8')\n",
    "log_file = open('log.csv', 'w', encoding='utf-8')\n",
    "\n",
    "submission = csv.writer(file)\n",
    "log = csv.writer(log_file)\n",
    "\n",
    "submission.writerow(['ID', 'Answer'])\n",
    "log.writerow(['ID', \"Agent ID\", 'Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f760b",
   "metadata": {
    "papermill": {
     "duration": 0.08031,
     "end_time": "2024-10-31T14:04:21.378075",
     "exception": false,
     "start_time": "2024-10-31T14:04:21.297765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configure LLM sampling parameters and Python REPL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ffd570",
   "metadata": {
    "papermill": {
     "duration": 0.078915,
     "end_time": "2024-10-31T14:04:21.537438",
     "exception": false,
     "start_time": "2024-10-31T14:04:21.458523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Use a queue to Batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af21eebb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T14:04:21.699514Z",
     "iopub.status.busy": "2024-10-31T14:04:21.699100Z",
     "iopub.status.idle": "2024-10-31T15:31:33.817920Z",
     "shell.execute_reply": "2024-10-31T15:31:33.816852Z"
    },
    "papermill": {
     "duration": 5232.202772,
     "end_time": "2024-10-31T15:31:33.820135",
     "exception": false,
     "start_time": "2024-10-31T14:04:21.617363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts:   2%|         | 1/64 [02:00<2:06:38, 120.61s/it]\u001b[A\n",
      "Processed prompts:   3%|         | 2/64 [02:07<55:24, 53.62s/it]   \u001b[A\n",
      "Processed prompts:   5%|         | 3/64 [02:14<32:51, 32.32s/it]\u001b[A\n",
      "Processed prompts:   6%|         | 4/64 [02:14<19:40, 19.68s/it]\u001b[A\n",
      "Processed prompts:   8%|         | 5/64 [02:17<13:18, 13.53s/it]\u001b[A\n",
      "Processed prompts:   9%|         | 6/64 [02:20<09:44, 10.08s/it]\u001b[A\n",
      "Processed prompts:  11%|         | 7/64 [02:25<07:56,  8.37s/it]\u001b[A\n",
      "Processed prompts:  12%|        | 8/64 [02:30<06:51,  7.34s/it]\u001b[A\n",
      "Processed prompts:  14%|        | 9/64 [02:34<05:48,  6.35s/it]\u001b[A\n",
      "Processed prompts:  16%|        | 10/64 [02:39<05:09,  5.74s/it]\u001b[A\n",
      "Processed prompts:  17%|        | 11/64 [02:44<05:05,  5.77s/it]\u001b[A\n",
      "Processed prompts:  19%|        | 12/64 [02:48<04:21,  5.03s/it]\u001b[A\n",
      "Processed prompts:  22%|       | 14/64 [02:52<03:01,  3.63s/it]\u001b[A\n",
      "Processed prompts:  23%|       | 15/64 [02:53<02:32,  3.11s/it]\u001b[A\n",
      "Processed prompts:  25%|       | 16/64 [02:57<02:38,  3.31s/it]\u001b[A\n",
      "Processed prompts:  27%|       | 17/64 [03:00<02:34,  3.28s/it]\u001b[A\n",
      "Processed prompts:  28%|       | 18/64 [03:03<02:20,  3.04s/it]\u001b[A\n",
      "Processed prompts:  30%|       | 19/64 [03:08<02:45,  3.68s/it]\u001b[A\n",
      "Processed prompts:  31%|      | 20/64 [03:12<02:48,  3.82s/it]\u001b[A\n",
      "Processed prompts:  33%|      | 21/64 [03:18<03:04,  4.30s/it]\u001b[A\n",
      "Processed prompts:  34%|      | 22/64 [03:24<03:27,  4.95s/it]\u001b[A\n",
      "Processed prompts:  36%|      | 23/64 [03:30<03:31,  5.15s/it]\u001b[A\n",
      "Processed prompts:  38%|      | 24/64 [03:33<02:56,  4.41s/it]\u001b[A\n",
      "Processed prompts:  39%|      | 25/64 [03:38<02:57,  4.56s/it]\u001b[A\n",
      "Processed prompts:  41%|      | 26/64 [03:46<03:34,  5.65s/it]\u001b[A\n",
      "Processed prompts:  42%|     | 27/64 [03:50<03:11,  5.17s/it]\u001b[A\n",
      "Processed prompts:  44%|     | 28/64 [03:54<02:57,  4.94s/it]\u001b[A\n",
      "Processed prompts:  45%|     | 29/64 [03:57<02:29,  4.26s/it]\u001b[A\n",
      "Processed prompts:  47%|     | 30/64 [04:02<02:38,  4.66s/it]\u001b[A\n",
      "Processed prompts:  48%|     | 31/64 [04:06<02:21,  4.30s/it]\u001b[A\n",
      "Processed prompts:  50%|     | 32/64 [04:09<02:01,  3.80s/it]\u001b[A\n",
      "Processed prompts:  52%|    | 33/64 [04:10<01:36,  3.12s/it]\u001b[A\n",
      "Processed prompts:  53%|    | 34/64 [04:23<03:00,  6.02s/it]\u001b[A\n",
      "Processed prompts:  55%|    | 35/64 [04:25<02:17,  4.74s/it]\u001b[A\n",
      "Processed prompts:  56%|    | 36/64 [04:30<02:21,  5.04s/it]\u001b[A\n",
      "Processed prompts:  58%|    | 37/64 [04:32<01:47,  3.99s/it]\u001b[A\n",
      "Processed prompts:  59%|    | 38/64 [04:36<01:45,  4.06s/it]\u001b[A\n",
      "Processed prompts:  61%|    | 39/64 [04:36<01:12,  2.91s/it]\u001b[A\n",
      "Processed prompts:  62%|   | 40/64 [04:41<01:23,  3.50s/it]\u001b[A\n",
      "Processed prompts:  64%|   | 41/64 [04:46<01:28,  3.84s/it]\u001b[A\n",
      "Processed prompts:  66%|   | 42/64 [04:49<01:16,  3.49s/it]\u001b[A\n",
      "Processed prompts:  67%|   | 43/64 [05:01<02:10,  6.19s/it]\u001b[A\n",
      "Processed prompts:  69%|   | 44/64 [05:03<01:39,  4.95s/it]\u001b[A\n",
      "Processed prompts:  70%|   | 45/64 [05:05<01:14,  3.94s/it]\u001b[A\n",
      "Processed prompts:  72%|  | 46/64 [05:10<01:16,  4.25s/it]\u001b[A\n",
      "Processed prompts:  73%|  | 47/64 [05:12<01:02,  3.68s/it]\u001b[A\n",
      "Processed prompts:  75%|  | 48/64 [05:19<01:16,  4.77s/it]\u001b[A\n",
      "Processed prompts:  77%|  | 49/64 [05:23<01:06,  4.41s/it]\u001b[A\n",
      "Processed prompts:  78%|  | 50/64 [05:24<00:47,  3.41s/it]\u001b[A\n",
      "Processed prompts:  80%|  | 51/64 [05:25<00:33,  2.59s/it]\u001b[A\n",
      "Processed prompts:  81%| | 52/64 [05:30<00:41,  3.45s/it]\u001b[A\n",
      "Processed prompts:  83%| | 53/64 [05:32<00:34,  3.10s/it]\u001b[A\n",
      "Processed prompts:  84%| | 54/64 [05:41<00:47,  4.73s/it]\u001b[A\n",
      "Processed prompts:  86%| | 55/64 [05:47<00:46,  5.18s/it]\u001b[A\n",
      "Processed prompts:  88%| | 56/64 [05:49<00:32,  4.09s/it]\u001b[A\n",
      "Processed prompts:  89%| | 57/64 [05:50<00:22,  3.23s/it]\u001b[A\n",
      "Processed prompts:  91%| | 58/64 [05:52<00:16,  2.83s/it]\u001b[A\n",
      "Processed prompts:  92%|| 59/64 [05:55<00:14,  2.93s/it]\u001b[A\n",
      "Processed prompts:  95%|| 61/64 [05:58<00:06,  2.22s/it]\u001b[A\n",
      "Processed prompts:  97%|| 62/64 [06:01<00:05,  2.52s/it]\u001b[A\n",
      "Processed prompts:  98%|| 63/64 [06:03<00:02,  2.29s/it]\u001b[A\n",
      "Processed prompts: 100%|| 64/64 [06:17<00:00,  5.90s/it]\n",
      " 16%|        | 16/100 [06:33<34:27, 24.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[10, 10, 10, 10]\n",
      "10\n",
      "2\n",
      "[4, 4, 4, 4]\n",
      "4\n",
      "5\n",
      "[0, 0, 0, 0]\n",
      "0\n",
      "15\n",
      "[240, 240, 260, 240]\n",
      "240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts:   2%|         | 1/64 [00:40<42:03, 40.05s/it]\u001b[A\n",
      "Processed prompts:   5%|         | 3/64 [00:42<11:25, 11.23s/it]\u001b[A\n",
      "Processed prompts:   6%|         | 4/64 [00:46<08:44,  8.74s/it]\u001b[A\n",
      "Processed prompts:   8%|         | 5/64 [00:47<06:00,  6.11s/it]\u001b[A\n",
      "Processed prompts:  11%|         | 7/64 [00:52<04:13,  4.44s/it]\u001b[A\n",
      "Processed prompts:  12%|        | 8/64 [00:52<03:07,  3.35s/it]\u001b[A\n",
      "Processed prompts:  14%|        | 9/64 [00:53<02:20,  2.55s/it]\u001b[A\n",
      "Processed prompts:  16%|        | 10/64 [01:00<03:26,  3.83s/it]\u001b[A\n",
      "Processed prompts:  17%|        | 11/64 [01:03<03:16,  3.71s/it]\u001b[A\n",
      "Processed prompts:  19%|        | 12/64 [01:07<03:21,  3.88s/it]\u001b[A\n",
      "Processed prompts:  20%|        | 13/64 [01:13<03:43,  4.38s/it]\u001b[A\n",
      "Processed prompts:  22%|       | 14/64 [01:15<03:01,  3.63s/it]\u001b[A\n",
      "Processed prompts:  23%|       | 15/64 [01:27<04:57,  6.08s/it]\u001b[A\n",
      "Processed prompts:  25%|       | 16/64 [01:41<06:47,  8.49s/it]\u001b[A\n",
      "Processed prompts:  27%|       | 17/64 [01:49<06:30,  8.31s/it]\u001b[A\n",
      "Processed prompts:  28%|       | 18/64 [01:51<05:00,  6.54s/it]\u001b[A\n",
      "Processed prompts:  30%|       | 19/64 [02:00<05:22,  7.17s/it]\u001b[A\n",
      "Processed prompts:  31%|      | 20/64 [02:06<05:02,  6.87s/it]\u001b[A\n",
      "Processed prompts:  33%|      | 21/64 [02:32<08:56, 12.48s/it]\u001b[A\n",
      "Processed prompts:  34%|      | 22/64 [02:34<06:39,  9.51s/it]\u001b[A\n",
      "Processed prompts:  36%|      | 23/64 [02:37<05:07,  7.50s/it]\u001b[A\n",
      "Processed prompts:  38%|      | 24/64 [02:41<04:17,  6.44s/it]\u001b[A\n",
      "Processed prompts:  39%|      | 25/64 [02:46<03:57,  6.09s/it]\u001b[A\n",
      "Processed prompts:  41%|      | 26/64 [02:52<03:46,  5.97s/it]\u001b[A\n",
      "Processed prompts:  42%|     | 27/64 [03:10<05:56,  9.63s/it]\u001b[A\n",
      "Processed prompts:  44%|     | 28/64 [03:15<04:55,  8.20s/it]\u001b[A\n",
      "Processed prompts:  45%|     | 29/64 [03:22<04:35,  7.87s/it]\u001b[A\n",
      "Processed prompts:  47%|     | 30/64 [03:27<03:58,  7.02s/it]\u001b[A\n",
      "Processed prompts:  48%|     | 31/64 [03:32<03:31,  6.42s/it]\u001b[A\n",
      "Processed prompts:  50%|     | 32/64 [03:39<03:31,  6.61s/it]\u001b[A\n",
      "Processed prompts:  52%|    | 33/64 [03:50<04:06,  7.94s/it]\u001b[A\n",
      "Processed prompts:  53%|    | 34/64 [03:53<03:07,  6.26s/it]\u001b[A\n",
      "Processed prompts:  55%|    | 35/64 [04:06<04:04,  8.45s/it]\u001b[A\n",
      "Processed prompts:  56%|    | 36/64 [04:11<03:23,  7.27s/it]\u001b[A\n",
      "Processed prompts:  59%|    | 38/64 [04:14<02:03,  4.75s/it]\u001b[A\n",
      "Processed prompts:  61%|    | 39/64 [04:17<01:44,  4.17s/it]\u001b[A\n",
      "Processed prompts:  62%|   | 40/64 [04:18<01:20,  3.36s/it]\u001b[A\n",
      "Processed prompts:  64%|   | 41/64 [04:22<01:21,  3.53s/it]\u001b[A\n",
      "Processed prompts:  66%|   | 42/64 [04:27<01:30,  4.12s/it]\u001b[A\n",
      "Processed prompts:  67%|   | 43/64 [04:29<01:11,  3.41s/it]\u001b[A\n",
      "Processed prompts:  69%|   | 44/64 [04:31<01:02,  3.13s/it]\u001b[A\n",
      "Processed prompts:  72%|  | 46/64 [04:53<01:57,  6.52s/it]\u001b[A\n",
      "Processed prompts:  73%|  | 47/64 [04:54<01:29,  5.26s/it]\u001b[A\n",
      "Processed prompts:  75%|  | 48/64 [05:07<01:56,  7.28s/it]\u001b[A\n",
      "Processed prompts:  77%|  | 49/64 [05:07<01:20,  5.38s/it]\u001b[A\n",
      "Processed prompts:  78%|  | 50/64 [05:10<01:05,  4.68s/it]\u001b[A\n",
      "Processed prompts:  80%|  | 51/64 [05:12<00:49,  3.77s/it]\u001b[A\n",
      "Processed prompts:  81%| | 52/64 [05:12<00:32,  2.72s/it]\u001b[A\n",
      "Processed prompts:  83%| | 53/64 [05:20<00:47,  4.31s/it]\u001b[A\n",
      "Processed prompts:  84%| | 54/64 [05:35<01:13,  7.38s/it]\u001b[A\n",
      "Processed prompts:  86%| | 55/64 [05:51<01:29,  9.91s/it]\u001b[A\n",
      "Processed prompts:  88%| | 56/64 [05:58<01:13,  9.25s/it]\u001b[A\n",
      "Processed prompts:  89%| | 57/64 [06:01<00:49,  7.14s/it]\u001b[A\n",
      "Processed prompts:  91%| | 58/64 [06:06<00:39,  6.58s/it]\u001b[A\n",
      "Processed prompts:  94%|| 60/64 [06:23<00:30,  7.58s/it]\u001b[A\n",
      "Processed prompts:  95%|| 61/64 [06:24<00:17,  5.77s/it]\u001b[A\n",
      "Processed prompts:  97%|| 62/64 [06:25<00:09,  4.68s/it]\u001b[A\n",
      "Processed prompts:  98%|| 63/64 [06:40<00:07,  7.42s/it]\u001b[A\n",
      "Processed prompts: 100%|| 64/64 [07:48<00:00,  7.32s/it]\n",
      " 26%|       | 26/100 [14:35<44:04, 35.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[4, 4, 4, 4]\n",
      "4\n",
      "4\n",
      "[1023, 1023, 1023, 1023]\n",
      "1023\n",
      "6\n",
      "[11, 11, 11, 2]\n",
      "11\n",
      "7\n",
      "[207, 327, 321, 200]\n",
      "207\n",
      "8\n",
      "[14, 14, 14, 14]\n",
      "14\n",
      "9\n",
      "[63, 60, 60, 63]\n",
      "63\n",
      "10\n",
      "[2, 2, 2, 2]\n",
      "2\n",
      "12\n",
      "[1901, 2001, 1901, 1901]\n",
      "1901\n",
      "13\n",
      "[1000, 1000, 1000, 1000]\n",
      "1000\n",
      "20\n",
      "[97, 97, 85, 97]\n",
      "97\n",
      "22\n",
      "[15, 15, 15, 15]\n",
      "15\n",
      "24\n",
      "[145, 145, 145, 145]\n",
      "145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts:   2%|         | 1/64 [00:37<39:37, 37.73s/it]\u001b[A\n",
      "Processed prompts:   3%|         | 2/64 [00:38<16:16, 15.75s/it]\u001b[A\n",
      "Processed prompts:   5%|         | 3/64 [00:43<11:16, 11.10s/it]\u001b[A\n",
      "Processed prompts:   6%|         | 4/64 [00:44<06:57,  6.95s/it]\u001b[A\n",
      "Processed prompts:   8%|         | 5/64 [00:49<06:22,  6.49s/it]\u001b[A\n",
      "Processed prompts:   9%|         | 6/64 [00:52<05:03,  5.24s/it]\u001b[A\n",
      "Processed prompts:  11%|         | 7/64 [00:59<05:31,  5.82s/it]\u001b[A\n",
      "Processed prompts:  12%|        | 8/64 [01:04<05:05,  5.45s/it]\u001b[A\n",
      "Processed prompts:  14%|        | 9/64 [01:09<04:58,  5.43s/it]\u001b[A\n",
      "Processed prompts:  16%|        | 10/64 [01:21<06:36,  7.35s/it]\u001b[A\n",
      "Processed prompts:  17%|        | 11/64 [01:25<05:35,  6.34s/it]\u001b[A\n",
      "Processed prompts:  19%|        | 12/64 [01:29<04:56,  5.70s/it]\u001b[A\n",
      "Processed prompts:  20%|        | 13/64 [01:41<06:19,  7.44s/it]\u001b[A\n",
      "Processed prompts:  22%|       | 14/64 [01:44<05:04,  6.09s/it]\u001b[A\n",
      "Processed prompts:  23%|       | 15/64 [02:00<07:25,  9.10s/it]\u001b[A\n",
      "Processed prompts:  25%|       | 16/64 [02:20<09:54, 12.38s/it]\u001b[A\n",
      "Processed prompts:  27%|       | 17/64 [02:40<11:40, 14.90s/it]\u001b[A\n",
      "Processed prompts:  28%|       | 18/64 [02:46<09:17, 12.12s/it]\u001b[A\n",
      "Processed prompts:  30%|       | 19/64 [02:53<07:50, 10.45s/it]\u001b[A\n",
      "Processed prompts:  31%|      | 20/64 [02:58<06:36,  9.01s/it]\u001b[A\n",
      "Processed prompts:  33%|      | 21/64 [03:03<05:31,  7.72s/it]\u001b[A\n",
      "Processed prompts:  34%|      | 22/64 [03:09<04:58,  7.11s/it]\u001b[A\n",
      "Processed prompts:  36%|      | 23/64 [03:16<04:53,  7.15s/it]\u001b[A\n",
      "Processed prompts:  39%|      | 25/64 [03:25<03:52,  5.97s/it]\u001b[A\n",
      "Processed prompts:  41%|      | 26/64 [03:37<04:43,  7.47s/it]\u001b[A\n",
      "Processed prompts:  42%|     | 27/64 [03:54<06:09, 10.00s/it]\u001b[A\n",
      "Processed prompts:  44%|     | 28/64 [04:13<07:23, 12.31s/it]\u001b[A\n",
      "Processed prompts:  45%|     | 29/64 [04:18<06:00, 10.31s/it]\u001b[A\n",
      "Processed prompts:  47%|     | 30/64 [04:39<07:35, 13.41s/it]\u001b[A\n",
      "Processed prompts:  48%|     | 31/64 [04:49<06:49, 12.40s/it]\u001b[A\n",
      "Processed prompts:  50%|     | 32/64 [04:55<05:33, 10.43s/it]\u001b[A\n",
      "Processed prompts:  52%|    | 33/64 [05:11<06:16, 12.16s/it]\u001b[A\n",
      "Processed prompts:  53%|    | 34/64 [05:15<04:56,  9.87s/it]\u001b[A\n",
      "Processed prompts:  55%|    | 35/64 [05:36<06:14, 12.92s/it]\u001b[A\n",
      "Processed prompts:  56%|    | 36/64 [05:41<05:01, 10.78s/it]\u001b[A\n",
      "Processed prompts:  58%|    | 37/64 [05:50<04:36, 10.25s/it]\u001b[A\n",
      "Processed prompts:  59%|    | 38/64 [06:12<05:52, 13.57s/it]\u001b[A\n",
      "Processed prompts:  61%|    | 39/64 [06:21<05:07, 12.32s/it]\u001b[A\n",
      "Processed prompts:  62%|   | 40/64 [06:35<05:06, 12.78s/it]\u001b[A\n",
      "Processed prompts:  64%|   | 41/64 [06:41<04:10, 10.91s/it]\u001b[A\n",
      "Processed prompts:  66%|   | 42/64 [07:14<06:24, 17.47s/it]\u001b[A\n",
      "Processed prompts:  67%|   | 43/64 [07:31<06:01, 17.22s/it]\u001b[A\n",
      "Processed prompts:  69%|   | 44/64 [07:38<04:45, 14.27s/it]\u001b[A\n",
      "Processed prompts:  70%|   | 45/64 [07:40<03:20, 10.55s/it]\u001b[A\n",
      "Processed prompts:  72%|  | 46/64 [07:44<02:35,  8.61s/it]\u001b[A\n",
      "Processed prompts:  73%|  | 47/64 [08:00<03:01, 10.66s/it]\u001b[A\n",
      "Processed prompts:  75%|  | 48/64 [08:06<02:27,  9.23s/it]\u001b[A\n",
      "Processed prompts:  77%|  | 49/64 [08:12<02:07,  8.53s/it]\u001b[A\n",
      "Processed prompts:  78%|  | 50/64 [08:19<01:48,  7.78s/it]\u001b[A\n",
      "Processed prompts:  81%| | 52/64 [08:21<00:56,  4.67s/it]\u001b[A\n",
      "Processed prompts:  83%| | 53/64 [08:21<00:40,  3.72s/it]\u001b[A\n",
      "Processed prompts:  84%| | 54/64 [08:22<00:30,  3.01s/it]\u001b[A\n",
      "Processed prompts:  86%| | 55/64 [08:24<00:22,  2.52s/it]\u001b[A\n",
      "Processed prompts:  88%| | 56/64 [08:24<00:15,  1.96s/it]\u001b[A\n",
      "Processed prompts:  89%| | 57/64 [08:34<00:29,  4.15s/it]\u001b[A\n",
      "Processed prompts:  91%| | 58/64 [08:38<00:25,  4.17s/it]\u001b[A\n",
      "Processed prompts:  92%|| 59/64 [08:42<00:20,  4.07s/it]\u001b[A\n",
      "Processed prompts:  94%|| 60/64 [08:49<00:20,  5.08s/it]\u001b[A\n",
      "Processed prompts:  95%|| 61/64 [09:04<00:24,  8.04s/it]\u001b[A\n",
      "Processed prompts:  97%|| 62/64 [09:14<00:16,  8.40s/it]\u001b[A\n",
      "Processed prompts:  98%|| 63/64 [20:45<03:31, 212.00s/it]\u001b[A\n",
      "Processed prompts: 100%|| 64/64 [23:00<00:00, 21.57s/it] \n",
      " 37%|      | 37/100 [37:49<1:18:11, 74.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[2024, 2023, 4047, 4045]\n",
      "2024\n",
      "11\n",
      "[8, 8, 7, 8]\n",
      "8\n",
      "14\n",
      "[216, 176, 216, 216]\n",
      "216\n",
      "17\n",
      "[22, 11, 11, 8]\n",
      "11\n",
      "18\n",
      "[17, 17, 17, 17]\n",
      "17\n",
      "19\n",
      "[24, 24, 24, 24]\n",
      "24\n",
      "23\n",
      "[51, 7291152950, 51, 3331]\n",
      "51\n",
      "25\n",
      "[4105, 4105, 4105, 4105]\n",
      "4105\n",
      "26\n",
      "[3, None, None, 3]\n",
      "3\n",
      "31\n",
      "[20, 20, 20, 20]\n",
      "20\n",
      "32\n",
      "[17, 17, 17, 17]\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts:   2%|         | 1/64 [00:40<42:45, 40.72s/it]\u001b[A\n",
      "Processed prompts:   5%|         | 3/64 [00:45<12:22, 12.16s/it]\u001b[A\n",
      "Processed prompts:   9%|         | 6/64 [00:49<05:25,  5.61s/it]\u001b[A\n",
      "Processed prompts:  11%|         | 7/64 [00:51<04:33,  4.79s/it]\u001b[A\n",
      "Processed prompts:  12%|        | 8/64 [00:53<03:48,  4.08s/it]\u001b[A\n",
      "Processed prompts:  14%|        | 9/64 [00:57<03:43,  4.07s/it]\u001b[A\n",
      "Processed prompts:  16%|        | 10/64 [00:59<03:14,  3.60s/it]\u001b[A\n",
      "Processed prompts:  19%|        | 12/64 [01:03<02:29,  2.87s/it]\u001b[A\n",
      "Processed prompts:  20%|        | 13/64 [01:06<02:22,  2.79s/it]\u001b[A\n",
      "Processed prompts:  22%|       | 14/64 [01:10<02:38,  3.17s/it]\u001b[A\n",
      "Processed prompts:  23%|       | 15/64 [01:15<03:01,  3.70s/it]\u001b[A\n",
      "Processed prompts:  25%|       | 16/64 [01:27<04:45,  5.94s/it]\u001b[A\n",
      "Processed prompts:  27%|       | 17/64 [01:28<03:29,  4.45s/it]\u001b[A\n",
      "Processed prompts:  28%|       | 18/64 [01:32<03:29,  4.56s/it]\u001b[A\n",
      "Processed prompts:  30%|       | 19/64 [01:36<03:15,  4.35s/it]\u001b[A\n",
      "Processed prompts:  31%|      | 20/64 [01:52<05:32,  7.56s/it]\u001b[A\n",
      "Processed prompts:  33%|      | 21/64 [02:17<09:17, 12.96s/it]\u001b[A\n",
      "Processed prompts:  34%|      | 22/64 [02:45<12:07, 17.31s/it]\u001b[A\n",
      "Processed prompts:  36%|      | 23/64 [02:54<10:11, 14.92s/it]\u001b[A\n",
      "Processed prompts:  38%|      | 24/64 [02:57<07:28, 11.22s/it]\u001b[A\n",
      "Processed prompts:  39%|      | 25/64 [03:01<05:59,  9.22s/it]\u001b[A\n",
      "Processed prompts:  41%|      | 26/64 [03:07<05:09,  8.13s/it]\u001b[A\n",
      "Processed prompts:  42%|     | 27/64 [03:12<04:31,  7.35s/it]\u001b[A\n",
      "Processed prompts:  44%|     | 28/64 [03:14<03:17,  5.48s/it]\u001b[A\n",
      "Processed prompts:  45%|     | 29/64 [03:17<02:49,  4.85s/it]\u001b[A\n",
      "Processed prompts:  47%|     | 30/64 [03:19<02:14,  3.94s/it]\u001b[A\n",
      "Processed prompts:  48%|     | 31/64 [03:29<03:14,  5.88s/it]\u001b[A\n",
      "Processed prompts:  50%|     | 32/64 [03:32<02:39,  5.00s/it]\u001b[A\n",
      "Processed prompts:  52%|    | 33/64 [03:35<02:13,  4.30s/it]\u001b[A\n",
      "Processed prompts:  53%|    | 34/64 [03:41<02:27,  4.91s/it]\u001b[A\n",
      "Processed prompts:  55%|    | 35/64 [03:44<02:01,  4.19s/it]\u001b[A\n",
      "Processed prompts:  56%|    | 36/64 [03:46<01:40,  3.58s/it]\u001b[A\n",
      "Processed prompts:  58%|    | 37/64 [03:48<01:25,  3.16s/it]\u001b[A\n",
      "Processed prompts:  59%|    | 38/64 [03:54<01:47,  4.15s/it]\u001b[A\n",
      "Processed prompts:  61%|    | 39/64 [03:56<01:26,  3.46s/it]\u001b[A\n",
      "Processed prompts:  62%|   | 40/64 [04:00<01:24,  3.50s/it]\u001b[A\n",
      "Processed prompts:  64%|   | 41/64 [04:04<01:22,  3.58s/it]\u001b[A\n",
      "Processed prompts:  66%|   | 42/64 [04:08<01:22,  3.74s/it]\u001b[A\n",
      "Processed prompts:  67%|   | 43/64 [04:11<01:16,  3.66s/it]\u001b[A\n",
      "Processed prompts:  69%|   | 44/64 [04:13<01:04,  3.24s/it]\u001b[A\n",
      "Processed prompts:  70%|   | 45/64 [04:19<01:17,  4.06s/it]\u001b[A\n",
      "Processed prompts:  72%|  | 46/64 [04:21<01:00,  3.38s/it]\u001b[A\n",
      "Processed prompts:  73%|  | 47/64 [04:22<00:43,  2.54s/it]\u001b[A\n",
      "Processed prompts:  75%|  | 48/64 [04:25<00:42,  2.64s/it]\u001b[A\n",
      "Processed prompts:  77%|  | 49/64 [04:28<00:44,  2.96s/it]\u001b[A\n",
      "Processed prompts:  78%|  | 50/64 [04:29<00:30,  2.14s/it]\u001b[A\n",
      "Processed prompts:  80%|  | 51/64 [04:29<00:20,  1.57s/it]\u001b[A\n",
      "Processed prompts:  81%| | 52/64 [04:31<00:21,  1.80s/it]\u001b[A\n",
      "Processed prompts:  83%| | 53/64 [04:32<00:15,  1.42s/it]\u001b[A\n",
      "Processed prompts:  84%| | 54/64 [04:35<00:19,  1.95s/it]\u001b[A\n",
      "Processed prompts:  86%| | 55/64 [04:38<00:19,  2.15s/it]\u001b[A\n",
      "Processed prompts:  88%| | 56/64 [04:38<00:13,  1.66s/it]\u001b[A\n",
      "Processed prompts:  89%| | 57/64 [04:45<00:22,  3.23s/it]\u001b[A\n",
      "Processed prompts:  91%| | 58/64 [04:48<00:19,  3.23s/it]\u001b[A\n",
      "Processed prompts:  94%|| 60/64 [04:54<00:12,  3.13s/it]\u001b[A\n",
      "Processed prompts:  95%|| 61/64 [04:54<00:07,  2.42s/it]\u001b[A\n",
      "Processed prompts:  97%|| 62/64 [04:55<00:03,  1.83s/it]\u001b[A\n",
      "Processed prompts:  98%|| 63/64 [04:56<00:01,  1.84s/it]\u001b[A\n",
      "Processed prompts: 100%|| 64/64 [04:57<00:00,  4.64s/it]\n",
      " 48%|     | 48/100 [42:55<49:15, 56.84s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "[11, 11, 11, 11]\n",
      "11\n",
      "21\n",
      "[96, None, 96, 96]\n",
      "96\n",
      "27\n",
      "[250, 250, 250, 250]\n",
      "250\n",
      "28\n",
      "[29, 29, 29, 29]\n",
      "29\n",
      "29\n",
      "[1, 1, 1, 1]\n",
      "1\n",
      "30\n",
      "[101, 102, 101, 101]\n",
      "101\n",
      "33\n",
      "[1224, 1224, 1224, 1224]\n",
      "1224\n",
      "34\n",
      "[2, 2, 2, 2]\n",
      "2\n",
      "35\n",
      "[6, 6, 6, 6]\n",
      "6\n",
      "37\n",
      "[50, 50, 50, 50]\n",
      "50\n",
      "39\n",
      "[18, 18, 6, 18]\n",
      "18\n",
      "40\n",
      "[102, 102, 102, 102]\n",
      "102\n",
      "43\n",
      "[4, 4, 1, 5]\n",
      "4\n",
      "45\n",
      "[65, 53, 53, 65]\n",
      "65\n",
      "46\n",
      "[2, 2, 2, 5]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts:   2%|         | 1/64 [00:40<42:14, 40.24s/it]\u001b[A\n",
      "Processed prompts:   5%|         | 3/64 [00:43<11:43, 11.53s/it]\u001b[A\n",
      "Processed prompts:   6%|         | 4/64 [00:45<08:13,  8.22s/it]\u001b[A\n",
      "Processed prompts:   8%|         | 5/64 [00:47<06:11,  6.30s/it]\u001b[A\n",
      "Processed prompts:  11%|         | 7/64 [00:54<04:41,  4.94s/it]\u001b[A\n",
      "Processed prompts:  12%|        | 8/64 [00:58<04:27,  4.78s/it]\u001b[A\n",
      "Processed prompts:  14%|        | 9/64 [01:01<03:57,  4.32s/it]\u001b[A\n",
      "Processed prompts:  16%|        | 10/64 [01:04<03:20,  3.71s/it]\u001b[A\n",
      "Processed prompts:  17%|        | 11/64 [01:24<07:33,  8.57s/it]\u001b[A\n",
      "Processed prompts:  19%|        | 12/64 [01:32<07:08,  8.24s/it]\u001b[A\n",
      "Processed prompts:  20%|        | 13/64 [01:45<08:07,  9.57s/it]\u001b[A\n",
      "Processed prompts:  22%|       | 14/64 [01:52<07:24,  8.88s/it]\u001b[A\n",
      "Processed prompts:  23%|       | 15/64 [01:58<06:31,  7.99s/it]\u001b[A\n",
      "Processed prompts:  25%|       | 16/64 [02:13<08:00, 10.01s/it]\u001b[A\n",
      "Processed prompts:  27%|       | 17/64 [02:16<06:25,  8.20s/it]\u001b[A\n",
      "Processed prompts:  28%|       | 18/64 [02:18<04:46,  6.23s/it]\u001b[A\n",
      "Processed prompts:  30%|       | 19/64 [02:28<05:30,  7.34s/it]\u001b[A\n",
      "Processed prompts:  31%|      | 20/64 [02:30<04:07,  5.63s/it]\u001b[A\n",
      "Processed prompts:  33%|      | 21/64 [02:30<02:53,  4.03s/it]\u001b[A\n",
      "Processed prompts:  34%|      | 22/64 [02:32<02:25,  3.46s/it]\u001b[A\n",
      "Processed prompts:  36%|      | 23/64 [02:37<02:37,  3.84s/it]\u001b[A\n",
      "Processed prompts:  38%|      | 24/64 [02:46<03:37,  5.44s/it]\u001b[A\n",
      "Processed prompts:  39%|      | 25/64 [02:57<04:38,  7.14s/it]\u001b[A\n",
      "Processed prompts:  41%|      | 26/64 [03:01<03:51,  6.08s/it]\u001b[A\n",
      "Processed prompts:  42%|     | 27/64 [03:06<03:30,  5.70s/it]\u001b[A\n",
      "Processed prompts:  44%|     | 28/64 [03:10<03:08,  5.23s/it]\u001b[A\n",
      "Processed prompts:  45%|     | 29/64 [03:12<02:38,  4.52s/it]\u001b[A\n",
      "Processed prompts:  47%|     | 30/64 [03:15<02:16,  4.01s/it]\u001b[A\n",
      "Processed prompts:  48%|     | 31/64 [03:36<04:55,  8.94s/it]\u001b[A\n",
      "Processed prompts:  50%|     | 32/64 [03:47<05:05,  9.55s/it]\u001b[A\n",
      "Processed prompts:  52%|    | 33/64 [03:49<03:45,  7.27s/it]\u001b[A\n",
      "Processed prompts:  53%|    | 34/64 [03:55<03:27,  6.90s/it]\u001b[A\n",
      "Processed prompts:  55%|    | 35/64 [04:02<03:21,  6.95s/it]\u001b[A\n",
      "Processed prompts:  56%|    | 36/64 [04:06<02:47,  5.99s/it]\u001b[A\n",
      "Processed prompts:  58%|    | 37/64 [04:08<02:12,  4.89s/it]\u001b[A\n",
      "Processed prompts:  59%|    | 38/64 [04:15<02:27,  5.66s/it]\u001b[A\n",
      "Processed prompts:  61%|    | 39/64 [04:18<02:00,  4.80s/it]\u001b[A\n",
      "Processed prompts:  62%|   | 40/64 [04:27<02:27,  6.16s/it]\u001b[A\n",
      "Processed prompts:  64%|   | 41/64 [04:33<02:16,  5.95s/it]\u001b[A\n",
      "Processed prompts:  66%|   | 42/64 [04:38<02:03,  5.60s/it]\u001b[A\n",
      "Processed prompts:  67%|   | 43/64 [04:41<01:41,  4.84s/it]\u001b[A\n",
      "Processed prompts:  69%|   | 44/64 [04:46<01:37,  4.86s/it]\u001b[A\n",
      "Processed prompts:  70%|   | 45/64 [04:47<01:14,  3.95s/it]\u001b[A\n",
      "Processed prompts:  72%|  | 46/64 [04:48<00:53,  3.00s/it]\u001b[A\n",
      "Processed prompts:  73%|  | 47/64 [04:50<00:43,  2.57s/it]\u001b[A\n",
      "Processed prompts:  75%|  | 48/64 [05:01<01:21,  5.10s/it]\u001b[A\n",
      "Processed prompts:  77%|  | 49/64 [05:02<00:56,  3.79s/it]\u001b[A\n",
      "Processed prompts:  78%|  | 50/64 [05:04<00:46,  3.32s/it]\u001b[A\n",
      "Processed prompts:  80%|  | 51/64 [05:04<00:31,  2.43s/it]\u001b[A\n",
      "Processed prompts:  81%| | 52/64 [05:11<00:44,  3.74s/it]\u001b[A\n",
      "Processed prompts:  83%| | 53/64 [05:14<00:37,  3.44s/it]\u001b[A\n",
      "Processed prompts:  84%| | 54/64 [05:14<00:24,  2.44s/it]\u001b[A\n",
      "Processed prompts:  86%| | 55/64 [05:20<00:30,  3.44s/it]\u001b[A\n",
      "Processed prompts:  88%| | 56/64 [05:23<00:27,  3.40s/it]\u001b[A\n",
      "Processed prompts:  89%| | 57/64 [05:26<00:23,  3.41s/it]\u001b[A\n",
      "Processed prompts:  91%| | 58/64 [05:29<00:18,  3.13s/it]\u001b[A\n",
      "Processed prompts:  92%|| 59/64 [05:39<00:26,  5.38s/it]\u001b[A\n",
      "Processed prompts:  94%|| 60/64 [05:43<00:19,  4.93s/it]\u001b[A\n",
      "Processed prompts:  97%|| 62/64 [05:46<00:06,  3.24s/it]\u001b[A\n",
      "Processed prompts:  98%|| 63/64 [05:47<00:02,  2.78s/it]\u001b[A\n",
      "Processed prompts: 100%|| 64/64 [05:48<00:00,  5.44s/it]\n",
      " 60%|    | 60/100 [48:56<31:15, 46.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "[161500, 161500, 161823, 161823]\n",
      "161500\n",
      "38\n",
      "[252, 252, 252, 252]\n",
      "252\n",
      "41\n",
      "[39, 39, 35, 39]\n",
      "39\n",
      "42\n",
      "[18, 18, 18, 18]\n",
      "18\n",
      "44\n",
      "[857142, 857142, 857142, 857142]\n",
      "857142\n",
      "48\n",
      "[7, 7, 17, 17]\n",
      "7\n",
      "50\n",
      "[44, 44, 44, 44]\n",
      "44\n",
      "51\n",
      "[105, 35, 100, 105]\n",
      "105\n",
      "53\n",
      "[1, 1, 1, 20]\n",
      "1\n",
      "55\n",
      "[7, 7, 7, 7]\n",
      "7\n",
      "56\n",
      "[21, 21, 20, 21]\n",
      "21\n",
      "57\n",
      "[81, 21, 81, 81]\n",
      "81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts:   2%|         | 1/64 [00:44<47:03, 44.82s/it]\u001b[A\n",
      "Processed prompts:   3%|         | 2/64 [00:46<20:10, 19.52s/it]\u001b[A\n",
      "Processed prompts:   6%|         | 4/64 [00:50<08:25,  8.43s/it]\u001b[A\n",
      "Processed prompts:   8%|         | 5/64 [00:53<06:42,  6.82s/it]\u001b[A\n",
      "Processed prompts:   9%|         | 6/64 [00:57<05:37,  5.83s/it]\u001b[A\n",
      "Processed prompts:  11%|         | 7/64 [00:59<04:39,  4.90s/it]\u001b[A\n",
      "Processed prompts:  12%|        | 8/64 [01:03<04:07,  4.43s/it]\u001b[A\n",
      "Processed prompts:  16%|        | 10/64 [01:08<03:16,  3.64s/it]\u001b[A\n",
      "Processed prompts:  19%|        | 12/64 [01:12<02:34,  2.98s/it]\u001b[A\n",
      "Processed prompts:  20%|        | 13/64 [01:18<03:04,  3.63s/it]\u001b[A\n",
      "Processed prompts:  22%|       | 14/64 [01:26<03:49,  4.59s/it]\u001b[A\n",
      "Processed prompts:  23%|       | 15/64 [01:32<04:06,  5.03s/it]\u001b[A\n",
      "Processed prompts:  25%|       | 16/64 [01:39<04:26,  5.56s/it]\u001b[A\n",
      "Processed prompts:  27%|       | 17/64 [01:43<03:55,  5.02s/it]\u001b[A\n",
      "Processed prompts:  28%|       | 18/64 [01:52<04:53,  6.38s/it]\u001b[A\n",
      "Processed prompts:  30%|       | 19/64 [02:02<05:33,  7.42s/it]\u001b[A\n",
      "Processed prompts:  31%|      | 20/64 [02:13<06:11,  8.44s/it]\u001b[A\n",
      "Processed prompts:  33%|      | 21/64 [02:14<04:28,  6.24s/it]\u001b[A\n",
      "Processed prompts:  34%|      | 22/64 [02:25<05:15,  7.51s/it]\u001b[A\n",
      "Processed prompts:  36%|      | 23/64 [02:27<04:04,  5.97s/it]\u001b[A\n",
      "Processed prompts:  38%|      | 24/64 [02:37<04:50,  7.26s/it]\u001b[A\n",
      "Processed prompts:  39%|      | 25/64 [02:42<04:16,  6.57s/it]\u001b[A\n",
      "Processed prompts:  41%|      | 26/64 [02:44<03:12,  5.05s/it]\u001b[A\n",
      "Processed prompts:  42%|     | 27/64 [02:46<02:29,  4.05s/it]\u001b[A\n",
      "Processed prompts:  44%|     | 28/64 [02:47<01:59,  3.31s/it]\u001b[A\n",
      "Processed prompts:  45%|     | 29/64 [03:01<03:46,  6.48s/it]\u001b[A\n",
      "Processed prompts:  47%|     | 30/64 [03:09<03:58,  7.03s/it]\u001b[A\n",
      "Processed prompts:  48%|     | 31/64 [03:16<03:49,  6.95s/it]\u001b[A\n",
      "Processed prompts:  50%|     | 32/64 [03:19<03:02,  5.72s/it]\u001b[A\n",
      "Processed prompts:  52%|    | 33/64 [03:25<02:57,  5.74s/it]\u001b[A\n",
      "Processed prompts:  53%|    | 34/64 [03:32<03:02,  6.08s/it]\u001b[A\n",
      "Processed prompts:  55%|    | 35/64 [03:35<02:35,  5.37s/it]\u001b[A\n",
      "Processed prompts:  56%|    | 36/64 [03:39<02:19,  4.99s/it]\u001b[A\n",
      "Processed prompts:  58%|    | 37/64 [03:45<02:15,  5.04s/it]\u001b[A\n",
      "Processed prompts:  59%|    | 38/64 [03:46<01:41,  3.92s/it]\u001b[A\n",
      "Processed prompts:  62%|   | 40/64 [03:47<00:54,  2.26s/it]\u001b[A\n",
      "Processed prompts:  64%|   | 41/64 [03:47<00:40,  1.75s/it]\u001b[A\n",
      "Processed prompts:  66%|   | 42/64 [03:47<00:30,  1.40s/it]\u001b[A\n",
      "Processed prompts:  67%|   | 43/64 [03:59<01:30,  4.29s/it]\u001b[A\n",
      "Processed prompts:  69%|   | 44/64 [04:09<01:58,  5.91s/it]\u001b[A\n",
      "Processed prompts:  70%|   | 45/64 [04:10<01:22,  4.34s/it]\u001b[A\n",
      "Processed prompts:  72%|  | 46/64 [04:16<01:27,  4.86s/it]\u001b[A\n",
      "Processed prompts:  73%|  | 47/64 [04:17<01:04,  3.78s/it]\u001b[A\n",
      "Processed prompts:  75%|  | 48/64 [04:23<01:10,  4.44s/it]\u001b[A\n",
      "Processed prompts:  77%|  | 49/64 [04:24<00:53,  3.55s/it]\u001b[A\n",
      "Processed prompts:  78%|  | 50/64 [04:26<00:39,  2.81s/it]\u001b[A\n",
      "Processed prompts:  80%|  | 51/64 [04:26<00:27,  2.14s/it]\u001b[A\n",
      "Processed prompts:  81%| | 52/64 [04:27<00:20,  1.74s/it]\u001b[A\n",
      "Processed prompts:  83%| | 53/64 [04:28<00:15,  1.45s/it]\u001b[A\n",
      "Processed prompts:  84%| | 54/64 [04:29<00:15,  1.53s/it]\u001b[A\n",
      "Processed prompts:  86%| | 55/64 [04:35<00:25,  2.83s/it]\u001b[A\n",
      "Processed prompts:  88%| | 56/64 [04:39<00:25,  3.17s/it]\u001b[A\n",
      "Processed prompts:  89%| | 57/64 [04:41<00:20,  2.88s/it]\u001b[A\n",
      "Processed prompts:  91%| | 58/64 [04:42<00:13,  2.26s/it]\u001b[A\n",
      "Processed prompts:  92%|| 59/64 [04:49<00:18,  3.61s/it]\u001b[A\n",
      "Processed prompts:  94%|| 60/64 [04:51<00:12,  3.20s/it]\u001b[A\n",
      "Processed prompts:  95%|| 61/64 [04:57<00:12,  4.09s/it]\u001b[A\n",
      "Processed prompts:  97%|| 62/64 [05:00<00:07,  3.57s/it]\u001b[A\n",
      "Processed prompts:  98%|| 63/64 [05:02<00:03,  3.14s/it]\u001b[A\n",
      "Processed prompts: 100%|| 64/64 [05:15<00:00,  4.92s/it]\n",
      " 72%|  | 72/100 [54:27<18:46, 40.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "[75000, 75000, 75000, 75000]\n",
      "75000\n",
      "49\n",
      "[525, 525, 525, 525]\n",
      "525\n",
      "52\n",
      "[15, 15, 15, 15]\n",
      "15\n",
      "54\n",
      "[11, 11, 462, 90]\n",
      "11\n",
      "59\n",
      "[12, 12, 12, 4]\n",
      "12\n",
      "60\n",
      "[811, 811, 811, 811]\n",
      "811\n",
      "63\n",
      "[7, 7, 7, 7]\n",
      "7\n",
      "64\n",
      "[1349, 1350, 1348, 1349]\n",
      "1349\n",
      "68\n",
      "[11, 11, 11, 11]\n",
      "11\n",
      "69\n",
      "[9, 9, 9, 9]\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts:   2%|         | 1/64 [00:39<41:35, 39.61s/it]\u001b[A\n",
      "Processed prompts:   3%|         | 2/64 [00:42<18:19, 17.73s/it]\u001b[A\n",
      "Processed prompts:   6%|         | 4/64 [00:45<07:36,  7.61s/it]\u001b[A\n",
      "Processed prompts:   8%|         | 5/64 [00:47<05:53,  6.00s/it]\u001b[A\n",
      "Processed prompts:   9%|         | 6/64 [00:51<05:08,  5.32s/it]\u001b[A\n",
      "Processed prompts:  11%|         | 7/64 [00:53<04:10,  4.39s/it]\u001b[A\n",
      "Processed prompts:  12%|        | 8/64 [00:55<03:30,  3.76s/it]\u001b[A\n",
      "Processed prompts:  14%|        | 9/64 [00:58<03:11,  3.48s/it]\u001b[A\n",
      "Processed prompts:  16%|        | 10/64 [01:01<02:48,  3.13s/it]\u001b[A\n",
      "Processed prompts:  17%|        | 11/64 [01:04<02:42,  3.07s/it]\u001b[A\n",
      "Processed prompts:  19%|        | 12/64 [01:07<02:45,  3.18s/it]\u001b[A\n",
      "Processed prompts:  20%|        | 13/64 [01:15<03:50,  4.52s/it]\u001b[A\n",
      "Processed prompts:  22%|       | 14/64 [01:19<03:39,  4.38s/it]\u001b[A\n",
      "Processed prompts:  23%|       | 15/64 [01:24<03:50,  4.71s/it]\u001b[A\n",
      "Processed prompts:  25%|       | 16/64 [01:32<04:24,  5.51s/it]\u001b[A\n",
      "Processed prompts:  27%|       | 17/64 [01:35<03:54,  4.98s/it]\u001b[A\n",
      "Processed prompts:  28%|       | 18/64 [02:26<14:21, 18.74s/it]\u001b[A\n",
      "Processed prompts:  30%|       | 19/64 [02:29<10:34, 14.09s/it]\u001b[A\n",
      "Processed prompts:  31%|      | 20/64 [02:36<08:40, 11.83s/it]\u001b[A\n",
      "Processed prompts:  33%|      | 21/64 [02:38<06:22,  8.90s/it]\u001b[A\n",
      "Processed prompts:  34%|      | 22/64 [02:42<05:18,  7.58s/it]\u001b[A\n",
      "Processed prompts:  36%|      | 23/64 [02:44<04:02,  5.91s/it]\u001b[A\n",
      "Processed prompts:  38%|      | 24/64 [02:59<05:38,  8.46s/it]\u001b[A\n",
      "Processed prompts:  39%|      | 25/64 [03:16<07:05, 10.92s/it]\u001b[A\n",
      "Processed prompts:  41%|      | 26/64 [03:43<10:00, 15.82s/it]\u001b[A\n",
      "Processed prompts:  42%|     | 27/64 [03:47<07:38, 12.38s/it]\u001b[A\n",
      "Processed prompts:  44%|     | 28/64 [03:51<05:54,  9.86s/it]\u001b[A\n",
      "Processed prompts:  45%|     | 29/64 [03:53<04:23,  7.53s/it]\u001b[A\n",
      "Processed prompts:  47%|     | 30/64 [03:56<03:29,  6.16s/it]\u001b[A\n",
      "Processed prompts:  48%|     | 31/64 [03:59<02:45,  5.03s/it]\u001b[A\n",
      "Processed prompts:  50%|     | 32/64 [04:05<02:50,  5.34s/it]\u001b[A\n",
      "Processed prompts:  52%|    | 33/64 [04:08<02:29,  4.81s/it]\u001b[A\n",
      "Processed prompts:  53%|    | 34/64 [04:14<02:29,  4.97s/it]\u001b[A\n",
      "Processed prompts:  55%|    | 35/64 [04:18<02:22,  4.90s/it]\u001b[A\n",
      "Processed prompts:  58%|    | 37/64 [04:23<01:39,  3.68s/it]\u001b[A\n",
      "Processed prompts:  59%|    | 38/64 [04:33<02:18,  5.34s/it]\u001b[A\n",
      "Processed prompts:  61%|    | 39/64 [04:40<02:21,  5.66s/it]\u001b[A\n",
      "Processed prompts:  62%|   | 40/64 [04:45<02:15,  5.66s/it]\u001b[A\n",
      "Processed prompts:  64%|   | 41/64 [04:48<01:47,  4.67s/it]\u001b[A\n",
      "Processed prompts:  66%|   | 42/64 [04:48<01:17,  3.52s/it]\u001b[A\n",
      "Processed prompts:  67%|   | 43/64 [05:05<02:32,  7.27s/it]\u001b[A\n",
      "Processed prompts:  69%|   | 44/64 [05:07<01:58,  5.92s/it]\u001b[A\n",
      "Processed prompts:  70%|   | 45/64 [05:12<01:47,  5.67s/it]\u001b[A\n",
      "Processed prompts:  72%|  | 46/64 [05:15<01:27,  4.88s/it]\u001b[A\n",
      "Processed prompts:  73%|  | 47/64 [05:29<02:05,  7.39s/it]\u001b[A\n",
      "Processed prompts:  75%|  | 48/64 [05:30<01:30,  5.65s/it]\u001b[A\n",
      "Processed prompts:  77%|  | 49/64 [05:32<01:05,  4.40s/it]\u001b[A\n",
      "Processed prompts:  78%|  | 50/64 [05:37<01:05,  4.65s/it]\u001b[A\n",
      "Processed prompts:  80%|  | 51/64 [05:42<01:02,  4.80s/it]\u001b[A\n",
      "Processed prompts:  81%| | 52/64 [05:44<00:45,  3.77s/it]\u001b[A\n",
      "Processed prompts:  83%| | 53/64 [05:51<00:52,  4.75s/it]\u001b[A\n",
      "Processed prompts:  84%| | 54/64 [05:51<00:34,  3.42s/it]\u001b[A\n",
      "Processed prompts:  86%| | 55/64 [05:54<00:29,  3.29s/it]\u001b[A\n",
      "Processed prompts:  88%| | 56/64 [05:54<00:19,  2.40s/it]\u001b[A\n",
      "Processed prompts:  89%| | 57/64 [05:56<00:16,  2.35s/it]\u001b[A\n",
      "Processed prompts:  91%| | 58/64 [05:59<00:14,  2.40s/it]\u001b[A\n",
      "Processed prompts:  92%|| 59/64 [06:00<00:10,  2.14s/it]\u001b[A\n",
      "Processed prompts:  94%|| 60/64 [06:02<00:07,  1.86s/it]\u001b[A\n",
      "Processed prompts:  95%|| 61/64 [06:06<00:08,  2.67s/it]\u001b[A\n",
      "Processed prompts:  97%|| 62/64 [06:20<00:12,  6.09s/it]\u001b[A\n",
      "Processed prompts:  98%|| 63/64 [06:44<00:11, 11.50s/it]\u001b[A\n",
      "Processed prompts: 100%|| 64/64 [07:24<00:00,  6.95s/it]\n",
      " 83%| | 83/100 [1:02:03<11:30, 40.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "[4, 4, 4, 4]\n",
      "4\n",
      "61\n",
      "[10, 10, 10, 10]\n",
      "10\n",
      "62\n",
      "[22335577, 22335577, 22335577, 22335577]\n",
      "22335577\n",
      "65\n",
      "[176400, 176400, 176400, 176400]\n",
      "176400\n",
      "66\n",
      "[999, 999, 999, 999]\n",
      "999\n",
      "67\n",
      "[465, 465, 465, 45]\n",
      "465\n",
      "70\n",
      "[16, 16, 16, 16]\n",
      "16\n",
      "71\n",
      "[3130, 3130, 3130, 3130]\n",
      "3130\n",
      "72\n",
      "[16, 16, 16, 16]\n",
      "16\n",
      "73\n",
      "[2025, 253, 5, 57]\n",
      "2025\n",
      "75\n",
      "[23, 17, 17, 17]\n",
      "17\n",
      "77\n",
      "[6, 6, 6, 6]\n",
      "6\n",
      "80\n",
      "[136, 136, 233, 136]\n",
      "136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts:   2%|         | 1/64 [00:42<44:56, 42.80s/it]\u001b[A\n",
      "Processed prompts:   5%|         | 3/64 [00:48<13:17, 13.07s/it]\u001b[A\n",
      "Processed prompts:   6%|         | 4/64 [00:49<09:09,  9.16s/it]\u001b[A\n",
      "Processed prompts:   8%|         | 5/64 [00:52<06:58,  7.10s/it]\u001b[A\n",
      "Processed prompts:   9%|         | 6/64 [00:54<05:08,  5.31s/it]\u001b[A\n",
      "Processed prompts:  11%|         | 7/64 [00:58<04:33,  4.79s/it]\u001b[A\n",
      "Processed prompts:  12%|        | 8/64 [01:16<08:29,  9.10s/it]\u001b[A\n",
      "Processed prompts:  14%|        | 9/64 [01:19<06:33,  7.16s/it]\u001b[A\n",
      "Processed prompts:  16%|        | 10/64 [01:22<05:10,  5.75s/it]\u001b[A\n",
      "Processed prompts:  17%|        | 11/64 [01:24<04:18,  4.88s/it]\u001b[A\n",
      "Processed prompts:  19%|        | 12/64 [01:27<03:37,  4.18s/it]\u001b[A\n",
      "Processed prompts:  20%|        | 13/64 [01:30<03:08,  3.70s/it]\u001b[A\n",
      "Processed prompts:  22%|       | 14/64 [02:15<13:26, 16.14s/it]\u001b[A\n",
      "Processed prompts:  23%|       | 15/64 [02:28<12:24, 15.20s/it]\u001b[A\n",
      "Processed prompts:  25%|       | 16/64 [02:43<12:10, 15.22s/it]\u001b[A\n",
      "Processed prompts:  27%|       | 17/64 [02:48<09:27, 12.07s/it]\u001b[A\n",
      "Processed prompts:  28%|       | 18/64 [02:50<07:05,  9.25s/it]\u001b[A\n",
      "Processed prompts:  30%|       | 19/64 [02:54<05:45,  7.68s/it]\u001b[A\n",
      "Processed prompts:  31%|      | 20/64 [03:00<05:06,  6.96s/it]\u001b[A\n",
      "Processed prompts:  33%|      | 21/64 [03:03<04:10,  5.82s/it]\u001b[A\n",
      "Processed prompts:  34%|      | 22/64 [03:15<05:20,  7.62s/it]\u001b[A\n",
      "Processed prompts:  36%|      | 23/64 [03:17<04:09,  6.09s/it]\u001b[A\n",
      "Processed prompts:  38%|      | 24/64 [03:21<03:36,  5.41s/it]\u001b[A\n",
      "Processed prompts:  39%|      | 25/64 [03:24<03:00,  4.64s/it]\u001b[A\n",
      "Processed prompts:  41%|      | 26/64 [03:26<02:31,  3.99s/it]\u001b[A\n",
      "Processed prompts:  42%|     | 27/64 [03:30<02:27,  3.99s/it]\u001b[A\n",
      "Processed prompts:  44%|     | 28/64 [03:33<02:09,  3.60s/it]\u001b[A\n",
      "Processed prompts:  45%|     | 29/64 [03:37<02:15,  3.88s/it]\u001b[A\n",
      "Processed prompts:  47%|     | 30/64 [03:49<03:26,  6.07s/it]\u001b[A\n",
      "Processed prompts:  50%|     | 32/64 [03:56<02:36,  4.90s/it]\u001b[A\n",
      "Processed prompts:  52%|    | 33/64 [03:58<02:08,  4.16s/it]\u001b[A\n",
      "Processed prompts:  53%|    | 34/64 [04:00<01:53,  3.77s/it]\u001b[A\n",
      "Processed prompts:  55%|    | 35/64 [04:00<01:21,  2.81s/it]\u001b[A\n",
      "Processed prompts:  56%|    | 36/64 [04:04<01:23,  2.98s/it]\u001b[A\n",
      "Processed prompts:  58%|    | 37/64 [04:12<02:02,  4.54s/it]\u001b[A\n",
      "Processed prompts:  59%|    | 38/64 [04:18<02:09,  5.00s/it]\u001b[A\n",
      "Processed prompts:  61%|    | 39/64 [04:29<02:48,  6.73s/it]\u001b[A\n",
      "Processed prompts:  62%|   | 40/64 [04:32<02:14,  5.61s/it]\u001b[A\n",
      "Processed prompts:  64%|   | 41/64 [04:36<01:58,  5.17s/it]\u001b[A\n",
      "Processed prompts:  66%|   | 42/64 [04:45<02:15,  6.14s/it]\u001b[A\n",
      "Processed prompts:  67%|   | 43/64 [04:46<01:35,  4.56s/it]\u001b[A\n",
      "Processed prompts:  69%|   | 44/64 [04:49<01:24,  4.22s/it]\u001b[A\n",
      "Processed prompts:  70%|   | 45/64 [04:50<01:01,  3.26s/it]\u001b[A\n",
      "Processed prompts:  72%|  | 46/64 [04:54<01:00,  3.35s/it]\u001b[A\n",
      "Processed prompts:  73%|  | 47/64 [04:59<01:08,  4.05s/it]\u001b[A\n",
      "Processed prompts:  75%|  | 48/64 [05:00<00:48,  3.00s/it]\u001b[A\n",
      "Processed prompts:  77%|  | 49/64 [05:01<00:35,  2.39s/it]\u001b[A\n",
      "Processed prompts:  78%|  | 50/64 [05:04<00:37,  2.68s/it]\u001b[A\n",
      "Processed prompts:  80%|  | 51/64 [05:06<00:31,  2.46s/it]\u001b[A\n",
      "Processed prompts:  81%| | 52/64 [05:06<00:21,  1.79s/it]\u001b[A\n",
      "Processed prompts:  83%| | 53/64 [05:07<00:15,  1.38s/it]\u001b[A\n",
      "Processed prompts:  84%| | 54/64 [05:08<00:13,  1.35s/it]\u001b[A\n",
      "Processed prompts:  86%| | 55/64 [05:18<00:34,  3.78s/it]\u001b[A\n",
      "Processed prompts:  88%| | 56/64 [05:19<00:23,  2.98s/it]\u001b[A\n",
      "Processed prompts:  89%| | 57/64 [05:19<00:15,  2.27s/it]\u001b[A\n",
      "Processed prompts:  91%| | 58/64 [05:25<00:20,  3.40s/it]\u001b[A\n",
      "Processed prompts:  92%|| 59/64 [05:33<00:22,  4.53s/it]\u001b[A\n",
      "Processed prompts:  94%|| 60/64 [05:33<00:13,  3.28s/it]\u001b[A\n",
      "Processed prompts:  95%|| 61/64 [05:45<00:17,  5.82s/it]\u001b[A\n",
      "Processed prompts:  97%|| 62/64 [05:49<00:10,  5.26s/it]\u001b[A\n",
      "Processed prompts:  98%|| 63/64 [05:50<00:04,  4.07s/it]\u001b[A\n",
      "Processed prompts: 100%|| 64/64 [18:24<00:00, 17.26s/it] \n",
      "100%|| 100/100 [1:20:45<00:00, 48.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "[57, 57, 57, 57]\n",
      "57\n",
      "81\n",
      "[613, 613, 613, 613]\n",
      "613\n",
      "86\n",
      "[21, 50, 20, 21]\n",
      "21\n",
      "90\n",
      "[28, 28, 28, 28]\n",
      "28\n",
      "91\n",
      "[169, 169, 169, 169]\n",
      "169\n",
      "92\n",
      "[8, 8, 9, 8]\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:  10%|         | 5/49 [00:47<03:45,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 10-31 15:25:54 scheduler.py:245] Input prompt (10073 tokens) is too long and exceeds limit of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 49/49 [04:41<00:00,  5.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "[16, 16, 16, 16]\n",
      "16\n",
      "76\n",
      "[120, 120, 288, 192]\n",
      "120\n",
      "79\n",
      "[197, 197, 1197, 197]\n",
      "197\n",
      "82\n",
      "[7, 7, 7, 7]\n",
      "7\n",
      "83\n",
      "[255, 16, 255, 16]\n",
      "255\n",
      "84\n",
      "[24, 24, 24, 24]\n",
      "24\n",
      "88\n",
      "[720, 720, 720, 720]\n",
      "720\n",
      "94\n",
      "[1012, 1012, 1012, 1012]\n",
      "1012\n",
      "95\n",
      "[9, 9, 9, 9]\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|| 16/16 [01:35<00:00,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "[3, 3, 1, 3]\n",
      "3\n",
      "87\n",
      "[25, 25, 50, 25]\n",
      "25\n",
      "89\n",
      "[None, 45, 135, 135]\n",
      "135\n",
      "93\n",
      "[24, 24, 24, 24]\n",
      "24\n",
      "96\n",
      "[94094, 18000, 78474, 78474]\n",
      "78474\n",
      "97\n",
      "[674, 6175, 561, 531]\n",
      "674\n",
      "98\n",
      "[71, 71, 71, 71]\n",
      "71\n",
      "99\n",
      "[4, 4, 4, 7]\n",
      "4\n",
      "CPU times: user 1h 25min 10s, sys: 41.2 s, total: 1h 25min 52s\n",
      "Wall time: 1h 27min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "boxed_answers = {}\n",
    "agents = []\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "iterator = iter(tqdm(test_df.values))\n",
    "\n",
    "while True:\n",
    "    for agent in agents:\n",
    "        if agent.complete():\n",
    "            boxed_answers[agent.problem_id] = agent.final_answer()\n",
    "\n",
    "    agents[:] = list(filter(lambda a: not a.complete(), agents))\n",
    "\n",
    "    while q.qsize() < BATCH_SIZE:\n",
    "        try:\n",
    "            row = next(iterator)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "        id = row[0]\n",
    "        problem = row[1]\n",
    "\n",
    "        agent = SCTIRAgent(id, problem, tokenizer, K, DEPTH, log)\n",
    "        \n",
    "        agents.append(agent)\n",
    "\n",
    "        for tir_agent in agent.get_ready_agents():\n",
    "            q.put_nowait(tir_agent)\n",
    "            \n",
    "    if q.empty():\n",
    "        break\n",
    "        \n",
    "    \n",
    "    ready_agents = []\n",
    "    texts = []\n",
    "    for _ in range(BATCH_SIZE):\n",
    "        try:\n",
    "            agent = q.get_nowait()\n",
    "            ready_agents.append(agent)\n",
    "            texts.append(agent.next_message())\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    \n",
    "    responses = llm.generate(texts, sampling_params)\n",
    "    responses = [response.outputs[0].text for response in responses]\n",
    "    \n",
    "    for i in range(len(ready_agents)):\n",
    "        agent = ready_agents[i]\n",
    "        response = responses[i]\n",
    "        agent.add_response(response, executor)\n",
    "        if not agent.complete():\n",
    "            q.put_nowait(agent)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360254d4",
   "metadata": {
    "papermill": {
     "duration": 0.211683,
     "end_time": "2024-10-31T15:31:34.239470",
     "exception": false,
     "start_time": "2024-10-31T15:31:34.027787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Write to submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f7a8bc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T15:31:34.673470Z",
     "iopub.status.busy": "2024-10-31T15:31:34.672629Z",
     "iopub.status.idle": "2024-10-31T15:31:34.677557Z",
     "shell.execute_reply": "2024-10-31T15:31:34.676671Z"
    },
    "papermill": {
     "duration": 0.210941,
     "end_time": "2024-10-31T15:31:34.679556",
     "exception": false,
     "start_time": "2024-10-31T15:31:34.468615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for id, answer in boxed_answers.items():\n",
    "    submission.writerow([id, answer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46de996",
   "metadata": {
    "papermill": {
     "duration": 0.204428,
     "end_time": "2024-10-31T15:31:35.084995",
     "exception": false,
     "start_time": "2024-10-31T15:31:34.880567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Close files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec2fb5bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T15:31:35.538540Z",
     "iopub.status.busy": "2024-10-31T15:31:35.537787Z",
     "iopub.status.idle": "2024-10-31T15:31:35.557143Z",
     "shell.execute_reply": "2024-10-31T15:31:35.556333Z"
    },
    "papermill": {
     "duration": 0.270458,
     "end_time": "2024-10-31T15:31:35.559448",
     "exception": false,
     "start_time": "2024-10-31T15:31:35.288990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "file.close()\n",
    "log_file.close()\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"/kaggle/working/submission1.csv\")\n",
    "df.set_index('ID',inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9773555,
     "sourceId": 86200,
     "sourceType": "competition"
    },
    {
     "datasetId": 4871830,
     "sourceId": 8218776,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4746046,
     "sourceId": 8300737,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5870546,
     "sourceId": 9659138,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5902669,
     "sourceId": 9661283,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5935746,
     "sourceId": 9705459,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7835.152756,
   "end_time": "2024-10-31T15:31:41.798504",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-31T13:21:06.645748",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00990a131c294883bbc77ac864d3aade": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "032c32fc09ea4172ad30513938e87070": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_75a32cb1559241fdb5049b55d933238f",
       "placeholder": "",
       "style": "IPY_MODEL_c87035b4bbd54093890ebd9321c0acc1",
       "value": "3.94G/3.94G[01:33&lt;00:00,41.5MB/s]"
      }
     },
     "07c6af36033a4097adc996e1803b284e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_93a9fe529eed4624b98cf8ee4bb0c809",
       "placeholder": "",
       "style": "IPY_MODEL_9dd9d1e130964fd583a46969ee07e4aa",
       "value": "1.67M/1.67M[00:00&lt;00:00,15.5MB/s]"
      }
     },
     "0bbb48df9bf845caa98f647329d954d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0cee72ed50434acd99e3f58496a95ee0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_10c7ad81ee954b2c8720cc20a24bb1a4",
       "placeholder": "",
       "style": "IPY_MODEL_b4753f77f89e40d98f253df301e0fab7",
       "value": "model-00003-of-00005.safetensors:100%"
      }
     },
     "0d244073a5d440678e17bfacd16e527c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a633080fc5ef4d549204df0b90a1d1e8",
       "max": 1671839.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7566e85c6c6642e88ce94b6aee168d4d",
       "value": 1671839.0
      }
     },
     "0ef3939a70ad41e09c0190fb7af4c5bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_219f2f01bcdf4775ab631efe759fc375",
       "placeholder": "",
       "style": "IPY_MODEL_53f3fa4df3de4578a7063bcb055b985f",
       "value": "3.98G/3.98G[01:33&lt;00:00,42.6MB/s]"
      }
     },
     "0ff107aa12684c3782524c1eaf622f65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_14009f949c1d4186952254e45c5ce15d",
       "placeholder": "",
       "style": "IPY_MODEL_de0b4251446f410ab95b5ce6bc3203e1",
       "value": "7.30k/7.30k[00:00&lt;00:00,534kB/s]"
      }
     },
     "0ff2607df2b14283aed83de8b62b144e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f2f5c19c50454e398636f3e3931b88aa",
       "placeholder": "",
       "style": "IPY_MODEL_cce9582a826d4b8b9f01c335650e7269",
       "value": "model-00004-of-00005.safetensors:100%"
      }
     },
     "10623318a07e458587ca3bcbb9a83e95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "10c7ad81ee954b2c8720cc20a24bb1a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1103a0ca59f5477899d56af33b988592": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d0f2573bcb6f42e7a6a0cec41fa0082c",
       "placeholder": "",
       "style": "IPY_MODEL_8537651f041c41689ed82a6489f7fad1",
       "value": "config.json:100%"
      }
     },
     "14009f949c1d4186952254e45c5ce15d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "153439973f5d4d8485160ec6ec78fce3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15b092917ba049ea833b858542575179": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_64ea69e543e04614b734c4945d96c27b",
       "max": 7031645.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_00990a131c294883bbc77ac864d3aade",
       "value": 7031645.0
      }
     },
     "18cd8dc13ef64d019f117e26c366906a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1e01be6c7f8b49429f754401c09ccfe4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_91a659a4e74743b5a7c0612c05bffed6",
       "placeholder": "",
       "style": "IPY_MODEL_2f089966401a4354a971b713b4e9ec86",
       "value": "merges.txt:100%"
      }
     },
     "21980785527041e0a8841d57d0908b52": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "219f2f01bcdf4775ab631efe759fc375": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "255cc960d1354b34b0ef87b5a41ee808": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "265db94b5b5843b0b3ca0e945010c893": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "280671b7c751442998e2f1827b7da4c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4add9f65ed2d4747a87aa2a9ff0cfd51",
        "IPY_MODEL_a44377719e3a4e26b9423d8e568dcde8",
        "IPY_MODEL_db603e30319b473ea87ccaede7cb6b8f"
       ],
       "layout": "IPY_MODEL_f0e495d7d7ae4d30b2e2551fcd20d885"
      }
     },
     "2914d210fcc146909b8b1bc11e618cf6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b70ad5c5e114ac285c3e0c194e2b33c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b2ccef4c1e234db99e674d6e67d22443",
        "IPY_MODEL_c7152a5b98134566af17a911c758a4f1",
        "IPY_MODEL_0ff107aa12684c3782524c1eaf622f65"
       ],
       "layout": "IPY_MODEL_7470ed9ea5554a5a8f4d8cc82223e085"
      }
     },
     "2b96f4252fef4072a04d1ac31b9d21b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c0b9dcd587b4890bcf129d833d07b92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ab57c54223bf4c81b6ea809db22e8ccc",
       "placeholder": "",
       "style": "IPY_MODEL_a23f03535110406b9b3dd0ce518f6b66",
       "value": "3.95G/3.95G[01:33&lt;00:00,42.1MB/s]"
      }
     },
     "2f089966401a4354a971b713b4e9ec86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3a09c91066b1492ca9b3aa597ca14783": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3b6abee91f784143af19076fe04d5710": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "408b40b32ad841c58b6f82b970249f7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4add9f65ed2d4747a87aa2a9ff0cfd51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_153439973f5d4d8485160ec6ec78fce3",
       "placeholder": "",
       "style": "IPY_MODEL_e77256f427eb494c801628610b9ffdfd",
       "value": "model-00002-of-00005.safetensors:100%"
      }
     },
     "4efa625b240d4ef5a933f8113ecfd5b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "53f3fa4df3de4578a7063bcb055b985f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "54ad2b9a7bff4f12b69e62520414e7e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_10623318a07e458587ca3bcbb9a83e95",
       "max": 3980134240.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_694321590b55444e93aa378c68b8a70b",
       "value": 3980134240.0
      }
     },
     "579c5022d0494fd6ba0b4f70db1c1eea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "58f177bde14541009c606559edd200d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_65edf1a07bc4485281dd8f2a0a2dcaef",
       "placeholder": "",
       "style": "IPY_MODEL_7966e71b37014eb590a47f40ce6852b1",
       "value": "tokenizer.json:100%"
      }
     },
     "64ea69e543e04614b734c4945d96c27b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65dad625ef2647fbaa05da6e910c5673": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_db5fecb451c64eb198de030e1f56d8aa",
       "placeholder": "",
       "style": "IPY_MODEL_ca67973cd45a444aad880bb1c9b738f6",
       "value": "7.03M/7.03M[00:00&lt;00:00,36.7MB/s]"
      }
     },
     "65edf1a07bc4485281dd8f2a0a2dcaef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "694321590b55444e93aa378c68b8a70b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6fb0ed775f764f4db5063a49444b526e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_88c175578e874c85b745561aca128ddf",
       "max": 841.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c94b9d8d80e44a8f9e69d3781de06d9c",
       "value": 841.0
      }
     },
     "73952f5c043e4f82b2f4b3e7e11f7f45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e3e9f0d6b60945bea864ad37493a01bb",
       "max": 3947411392.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8e850c9d2e4f40f29fe480f0020c3b98",
       "value": 3947411392.0
      }
     },
     "7470ed9ea5554a5a8f4d8cc82223e085": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7566e85c6c6642e88ce94b6aee168d4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "75a32cb1559241fdb5049b55d933238f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7673725f823448bfb508f48b6537a904": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7966e71b37014eb590a47f40ce6852b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7a96855596a74f9598e2f12000d1b3fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7cc7410f9ebe4f48a017f07d23dd7386": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_579c5022d0494fd6ba0b4f70db1c1eea",
       "max": 2776833.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3a09c91066b1492ca9b3aa597ca14783",
       "value": 2776833.0
      }
     },
     "7fec5db08443469e99dea110d376089f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "801ac54c10cf4e2084d721d3a3ce4fb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9bb902d5208b45deac4b6fcddc81fc63",
       "max": 3943575336.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_408b40b32ad841c58b6f82b970249f7d",
       "value": 3943575336.0
      }
     },
     "80872b646a4e4718b5bafd94c4075721": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0ff2607df2b14283aed83de8b62b144e",
        "IPY_MODEL_54ad2b9a7bff4f12b69e62520414e7e1",
        "IPY_MODEL_0ef3939a70ad41e09c0190fb7af4c5bd"
       ],
       "layout": "IPY_MODEL_9b766d224f8d4421941753d425c73e7e"
      }
     },
     "8537651f041c41689ed82a6489f7fad1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "88c175578e874c85b745561aca128ddf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a366721c65c427283dad4c09d2faa7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8f9daac7d32942209eb30ff78ebef374",
       "placeholder": "",
       "style": "IPY_MODEL_7673725f823448bfb508f48b6537a904",
       "value": "model-00005-of-00005.safetensors:100%"
      }
     },
     "8e850c9d2e4f40f29fe480f0020c3b98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8f9daac7d32942209eb30ff78ebef374": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "91a659a4e74743b5a7c0612c05bffed6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "93a9fe529eed4624b98cf8ee4bb0c809": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9537254db69848e0b69a7ddda918e3c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b766d224f8d4421941753d425c73e7e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9bb902d5208b45deac4b6fcddc81fc63": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9dd9d1e130964fd583a46969ee07e4aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a23f03535110406b9b3dd0ce518f6b66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a44377719e3a4e26b9423d8e568dcde8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d8873286b61f4af49e396bdec9737d01",
       "max": 3980134208.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_18cd8dc13ef64d019f117e26c366906a",
       "value": 3980134208.0
      }
     },
     "a495ec6e7d55497da77b6f743ea22a0d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a633080fc5ef4d549204df0b90a1d1e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a6f499f5bf2c47c0a31b6a184ddbb0bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_255cc960d1354b34b0ef87b5a41ee808",
       "placeholder": "",
       "style": "IPY_MODEL_cef9969744c443c6ac6fe7f12fab9562",
       "value": "3.48G/3.48G[01:22&lt;00:00,43.0MB/s]"
      }
     },
     "ab0074f905c9453c88bbe290e9f79ad0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ea1acb6fc6b447f8b6643057848a20e8",
       "placeholder": "",
       "style": "IPY_MODEL_dab201348ee84b678276e01429678f88",
       "value": "model-00001-of-00005.safetensors:100%"
      }
     },
     "ab57c54223bf4c81b6ea809db22e8ccc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b093475d66f54b7d9ce24cde5baf27da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b2ccef4c1e234db99e674d6e67d22443": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bd73e594fd9c402987ce299397a629a2",
       "placeholder": "",
       "style": "IPY_MODEL_f1103ba8e3d14a8d8614322e2111f12f",
       "value": "tokenizer_config.json:100%"
      }
     },
     "b4753f77f89e40d98f253df301e0fab7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bbb7c34ba64f4892bb0b297197be3e51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1e01be6c7f8b49429f754401c09ccfe4",
        "IPY_MODEL_0d244073a5d440678e17bfacd16e527c",
        "IPY_MODEL_07c6af36033a4097adc996e1803b284e"
       ],
       "layout": "IPY_MODEL_d1154e062a7d4195a611196cac1de200"
      }
     },
     "bd73e594fd9c402987ce299397a629a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c34bd080227b4412a72f755eb67aba8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0cee72ed50434acd99e3f58496a95ee0",
        "IPY_MODEL_73952f5c043e4f82b2f4b3e7e11f7f45",
        "IPY_MODEL_2c0b9dcd587b4890bcf129d833d07b92"
       ],
       "layout": "IPY_MODEL_c3d20a7e2a694d598279438237f7f89f"
      }
     },
     "c3ad658ac3e742eba6f75f9d5473b1fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1103a0ca59f5477899d56af33b988592",
        "IPY_MODEL_6fb0ed775f764f4db5063a49444b526e",
        "IPY_MODEL_f26d193af0e14c73b391ac29873e0a82"
       ],
       "layout": "IPY_MODEL_f5048fa0a057400abbd829485fa8d190"
      }
     },
     "c3d20a7e2a694d598279438237f7f89f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c41a81014fa14000b166878f71c9daba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c7152a5b98134566af17a911c758a4f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_21980785527041e0a8841d57d0908b52",
       "max": 7305.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f7f5313f3c4c4dd5b155b103569625b6",
       "value": 7305.0
      }
     },
     "c78fadac8ee74021989f7e4350db59c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f51fa3823e0744ee94336bf873bdd225",
       "max": 3477738728.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7fec5db08443469e99dea110d376089f",
       "value": 3477738728.0
      }
     },
     "c87035b4bbd54093890ebd9321c0acc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c94b9d8d80e44a8f9e69d3781de06d9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ca67973cd45a444aad880bb1c9b738f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cb8da0655056439fa936bc58233ac831": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_58f177bde14541009c606559edd200d9",
        "IPY_MODEL_15b092917ba049ea833b858542575179",
        "IPY_MODEL_65dad625ef2647fbaa05da6e910c5673"
       ],
       "layout": "IPY_MODEL_265db94b5b5843b0b3ca0e945010c893"
      }
     },
     "cce9582a826d4b8b9f01c335650e7269": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cef9969744c443c6ac6fe7f12fab9562": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cf1be6d6c46c45bab684dd5543023730": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ab0074f905c9453c88bbe290e9f79ad0",
        "IPY_MODEL_801ac54c10cf4e2084d721d3a3ce4fb3",
        "IPY_MODEL_032c32fc09ea4172ad30513938e87070"
       ],
       "layout": "IPY_MODEL_0bbb48df9bf845caa98f647329d954d2"
      }
     },
     "d0f2573bcb6f42e7a6a0cec41fa0082c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d1154e062a7d4195a611196cac1de200": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8873286b61f4af49e396bdec9737d01": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dab201348ee84b678276e01429678f88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "db5fecb451c64eb198de030e1f56d8aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "db603e30319b473ea87ccaede7cb6b8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9537254db69848e0b69a7ddda918e3c6",
       "placeholder": "",
       "style": "IPY_MODEL_7a96855596a74f9598e2f12000d1b3fe",
       "value": "3.98G/3.98G[01:33&lt;00:00,42.8MB/s]"
      }
     },
     "de0b4251446f410ab95b5ce6bc3203e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e30b808b89ba47dd87737dcd26cdcb2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f60486bc11c548e88b0dadc1841c34ab",
        "IPY_MODEL_7cc7410f9ebe4f48a017f07d23dd7386",
        "IPY_MODEL_ec60bb25a4654311814e0ecb7dd49af5"
       ],
       "layout": "IPY_MODEL_f4d07fba18ce446997ae35f5f47a09fd"
      }
     },
     "e3e9f0d6b60945bea864ad37493a01bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e77256f427eb494c801628610b9ffdfd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ea1acb6fc6b447f8b6643057848a20e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec60bb25a4654311814e0ecb7dd49af5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2914d210fcc146909b8b1bc11e618cf6",
       "placeholder": "",
       "style": "IPY_MODEL_c41a81014fa14000b166878f71c9daba",
       "value": "2.78M/2.78M[00:00&lt;00:00,22.7MB/s]"
      }
     },
     "f0e495d7d7ae4d30b2e2551fcd20d885": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f1103ba8e3d14a8d8614322e2111f12f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f26d193af0e14c73b391ac29873e0a82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2b96f4252fef4072a04d1ac31b9d21b7",
       "placeholder": "",
       "style": "IPY_MODEL_b093475d66f54b7d9ce24cde5baf27da",
       "value": "841/841[00:00&lt;00:00,65.9kB/s]"
      }
     },
     "f2f5c19c50454e398636f3e3931b88aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f35aef18c8304af8ba6c202398dd23be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8a366721c65c427283dad4c09d2faa7b",
        "IPY_MODEL_c78fadac8ee74021989f7e4350db59c1",
        "IPY_MODEL_a6f499f5bf2c47c0a31b6a184ddbb0bc"
       ],
       "layout": "IPY_MODEL_3b6abee91f784143af19076fe04d5710"
      }
     },
     "f4d07fba18ce446997ae35f5f47a09fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f5048fa0a057400abbd829485fa8d190": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f51fa3823e0744ee94336bf873bdd225": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f60486bc11c548e88b0dadc1841c34ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a495ec6e7d55497da77b6f743ea22a0d",
       "placeholder": "",
       "style": "IPY_MODEL_4efa625b240d4ef5a933f8113ecfd5b2",
       "value": "vocab.json:100%"
      }
     },
     "f7f5313f3c4c4dd5b155b103569625b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
