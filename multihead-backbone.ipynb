{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ffde9c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T10:28:52.100539Z",
     "iopub.status.busy": "2025-01-14T10:28:52.100290Z",
     "iopub.status.idle": "2025-01-14T10:28:58.504903Z",
     "shell.execute_reply": "2025-01-14T10:28:58.503820Z"
    },
    "papermill": {
     "duration": 6.409971,
     "end_time": "2025-01-14T10:28:58.506763",
     "exception": false,
     "start_time": "2025-01-14T10:28:52.096792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80983176",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-14T10:28:58.513355Z",
     "iopub.status.busy": "2025-01-14T10:28:58.513110Z",
     "iopub.status.idle": "2025-01-14T10:29:11.777607Z",
     "shell.execute_reply": "2025-01-14T10:29:11.776250Z"
    },
    "papermill": {
     "duration": 13.269536,
     "end_time": "2025-01-14T10:29:11.779350",
     "exception": false,
     "start_time": "2025-01-14T10:28:58.509814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pathmnist...\n",
      "Loading dermamnist...\n",
      "Loading octmnist...\n",
      "Loading pneumoniamnist...\n",
      "Loading retinamnist...\n",
      "Loading breastmnist...\n",
      "Loading bloodmnist...\n",
      "Loading tissuemnist...\n",
      "Loading organamnist...\n",
      "Loading organcmnist...\n",
      "Loading organsmnist...\n",
      "\n",
      "pathmnist:\n",
      "Task: multi-class\n",
      "Classes: 9\n",
      "Train size: 89996 \n",
      "Val size: 10004\n",
      "Test size: 7180\n",
      "\n",
      "dermamnist:\n",
      "Task: multi-class\n",
      "Classes: 7\n",
      "Train size: 7007 \n",
      "Val size: 1003\n",
      "Test size: 2005\n",
      "\n",
      "octmnist:\n",
      "Task: multi-class\n",
      "Classes: 4\n",
      "Train size: 97477 \n",
      "Val size: 10832\n",
      "Test size: 1000\n",
      "\n",
      "pneumoniamnist:\n",
      "Task: binary-class\n",
      "Classes: 2\n",
      "Train size: 4708 \n",
      "Val size: 524\n",
      "Test size: 624\n",
      "\n",
      "retinamnist:\n",
      "Task: ordinal-regression\n",
      "Classes: 5\n",
      "Train size: 1080 \n",
      "Val size: 120\n",
      "Test size: 400\n",
      "\n",
      "breastmnist:\n",
      "Task: binary-class\n",
      "Classes: 2\n",
      "Train size: 546 \n",
      "Val size: 78\n",
      "Test size: 156\n",
      "\n",
      "bloodmnist:\n",
      "Task: multi-class\n",
      "Classes: 8\n",
      "Train size: 11959 \n",
      "Val size: 1712\n",
      "Test size: 3421\n",
      "\n",
      "tissuemnist:\n",
      "Task: multi-class\n",
      "Classes: 8\n",
      "Train size: 165466 \n",
      "Val size: 23640\n",
      "Test size: 47280\n",
      "\n",
      "organamnist:\n",
      "Task: multi-class\n",
      "Classes: 11\n",
      "Train size: 34581 \n",
      "Val size: 6491\n",
      "Test size: 17778\n",
      "\n",
      "organcmnist:\n",
      "Task: multi-class\n",
      "Classes: 11\n",
      "Train size: 13000 \n",
      "Val size: 2392\n",
      "Test size: 8268\n",
      "\n",
      "organsmnist:\n",
      "Task: multi-class\n",
      "Classes: 11\n",
      "Train size: 13940 \n",
      "Val size: 2452\n",
      "Test size: 8829\n",
      "\n",
      "Total test samples: 96941\n"
     ]
    }
   ],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def load_medmnist_from_npz(data_flag):\n",
    "    \n",
    "    data_path = Path('/kaggle/input/tensor-reloaded-multi-task-med-mnist/data') / f'{data_flag}.npz'\n",
    "    data = np.load(data_path)\n",
    "\n",
    "    info = INFO[data_flag]\n",
    "    task = info['task']\n",
    "    n_channels = info['n_channels']\n",
    "    n_classes = len(info['label'])\n",
    "\n",
    "    class NPZDataset(Dataset):\n",
    "        def __init__(self, images, labels=None):\n",
    "            self.images = images\n",
    "            self.labels = labels\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.images)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image = self.images[idx]\n",
    "            if self.labels is not None:\n",
    "                return torch.tensor(image), torch.tensor(self.labels[idx])\n",
    "            return torch.tensor(image)\n",
    "\n",
    "    \n",
    "        \n",
    "    train_dataset = NPZDataset(data['train_images'], data.get('train_labels'))\n",
    "    val_dataset = NPZDataset(data['val_images'], data.get('val_labels'))\n",
    "    test_dataset = NPZDataset(data['test_images'])\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, info\n",
    "\n",
    "\n",
    "DATASETS = [\n",
    "    'pathmnist',\n",
    "    'dermamnist',\n",
    "    'octmnist',\n",
    "    'pneumoniamnist',\n",
    "    'retinamnist',\n",
    "    'breastmnist',\n",
    "    'bloodmnist',\n",
    "    'tissuemnist',\n",
    "    'organamnist',\n",
    "    'organcmnist',\n",
    "    'organsmnist'\n",
    "]\n",
    "\n",
    "def load_all_datasets():\n",
    "    datasets = {}\n",
    "    for data_flag in DATASETS:\n",
    "        print(f\"Loading {data_flag}...\")\n",
    "        train, val, test, info = load_medmnist_from_npz(data_flag)\n",
    "        datasets[data_flag] = {\n",
    "            'train': train,\n",
    "            'val': val,\n",
    "            'test': test,\n",
    "            'info': info\n",
    "        }\n",
    "    return datasets\n",
    "\n",
    "def print_dataset_info(datasets):\n",
    "    \n",
    "    total_test = 0\n",
    "    for data_flag, data in datasets.items():\n",
    "        info = data['info']\n",
    "        print(f\"\\n{data_flag}:\")\n",
    "        print(f\"Task: {info['task']}\")\n",
    "        print(f\"Classes: {len(info['label'])}\")\n",
    "        print(f\"Train size: {len(data['train'])} {''}\")\n",
    "        print(f\"Val size: {len(data['val'])}\")\n",
    "        print(f\"Test size: {len(data['test'])}\")\n",
    "        total_test += len(data['test'])\n",
    "    print(f\"\\nTotal test samples: {total_test}\")\n",
    "    \n",
    "\n",
    "def calculate_class_weights(datasets):\n",
    "    weights = {}\n",
    "\n",
    "    for data_flag in DATASETS:\n",
    "        \n",
    "        labels = datasets[data_flag]['train'].labels\n",
    "        if isinstance(labels, torch.Tensor):\n",
    "            labels = labels.numpy()\n",
    "\n",
    "        \n",
    "        num_classes = len(datasets[data_flag]['info']['label'])\n",
    "\n",
    "        \n",
    "        class_counts = np.bincount(labels.flatten(), minlength=num_classes)\n",
    "\n",
    "        \n",
    "        total = class_counts.sum()\n",
    "        raw_weights = total / (class_counts + 1e-6)\n",
    "\n",
    "        \n",
    "        normalized_weights = raw_weights / raw_weights.mean()\n",
    "\n",
    "        \n",
    "        weights[data_flag] = torch.FloatTensor(normalized_weights)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "datasets = load_all_datasets()\n",
    "print_dataset_info(datasets)\n",
    "class_weights = calculate_class_weights(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6a1b42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T10:29:11.787137Z",
     "iopub.status.busy": "2025-01-14T10:29:11.786677Z",
     "iopub.status.idle": "2025-01-14T10:29:15.810925Z",
     "shell.execute_reply": "2025-01-14T10:29:15.809985Z"
    },
    "papermill": {
     "duration": 4.029575,
     "end_time": "2025-01-14T10:29:15.812510",
     "exception": false,
     "start_time": "2025-01-14T10:29:11.782935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "        self.act = nn.GELU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.act(x + self.block(x))\n",
    "\n",
    "class MedMNISTMultiTaskModel(nn.Module):\n",
    "    def __init__(self, backbone_name='convnext_tiny', pretrained=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.task_outputs = {\n",
    "            'pathmnist': 9,\n",
    "            'dermamnist': 7,\n",
    "            'octmnist': 4,\n",
    "            'pneumoniamnist': 2,\n",
    "            'retinamnist': 5,\n",
    "            'breastmnist': 2,\n",
    "            'bloodmnist': 8,\n",
    "            'tissuemnist': 8,\n",
    "            'organamnist': 11,\n",
    "            'organcmnist': 11,\n",
    "            'organsmnist': 11\n",
    "        }\n",
    "\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            backbone_name,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,\n",
    "            drop_path_rate=0.1  \n",
    "        )\n",
    "\n",
    "        \n",
    "        self.backbone.stem[0] = nn.Conv2d(\n",
    "            3, 96, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        \n",
    "        \n",
    "        feat_dim = self.backbone.num_features  \n",
    "\n",
    "       \n",
    "        self.heads = nn.ModuleDict()\n",
    "        for task, num_classes in self.task_outputs.items():\n",
    "            self.heads[task] = nn.Sequential(\n",
    "                \n",
    "                nn.LayerNorm(feat_dim),\n",
    "                \n",
    "               \n",
    "                nn.Sequential(\n",
    "                    nn.Linear(feat_dim, feat_dim),\n",
    "                    nn.GELU(),\n",
    "                    nn.Dropout(0.2),\n",
    "                    \n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(feat_dim, feat_dim // 4),\n",
    "                        nn.GELU(),\n",
    "                        nn.Linear(feat_dim // 4, feat_dim),\n",
    "                        nn.Sigmoid()\n",
    "                    )\n",
    "                ),\n",
    "                \n",
    "                \n",
    "                nn.Sequential(\n",
    "                    nn.LayerNorm(feat_dim),\n",
    "                    nn.Linear(feat_dim, feat_dim * 4),\n",
    "                    nn.GELU(),\n",
    "                    nn.Dropout(0.2),\n",
    "                    nn.Linear(feat_dim * 4, feat_dim),\n",
    "                ),\n",
    "                \n",
    "                \n",
    "                nn.Sequential(\n",
    "                    nn.LayerNorm(feat_dim),\n",
    "                    nn.Linear(feat_dim, num_classes)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x, task_ids=None):\n",
    "        \n",
    "        features = self.backbone(x)\n",
    "\n",
    "        if task_ids is not None:\n",
    "            \n",
    "            task_groups = {}\n",
    "            for i, task_id in enumerate(task_ids):\n",
    "                task_name = DATASETS[task_id]\n",
    "                if task_name not in task_groups:\n",
    "                    task_groups[task_name] = {'indices': [], 'features': []}\n",
    "                task_groups[task_name]['indices'].append(i)\n",
    "                task_groups[task_name]['features'].append(features[i:i+1])\n",
    "\n",
    "           \n",
    "            outputs = torch.zeros(len(task_ids), max(self.task_outputs.values())).to(features.device)\n",
    "            for task_name, group in task_groups.items():\n",
    "                task_features = torch.cat(group['features'], dim=0)\n",
    "                task_outputs = self.heads[task_name](task_features)\n",
    "                for idx, output in zip(group['indices'], task_outputs):\n",
    "                    outputs[idx, :self.task_outputs[task_name]] = output\n",
    "\n",
    "            return outputs\n",
    "        else:\n",
    "            return {task: head(features) for task, head in self.heads.items()}\n",
    "\n",
    "\n",
    "def train_step(model, batch, optimizer, criterion):\n",
    "    images, labels, task_ids = batch\n",
    "\n",
    "    \n",
    "    outputs = model(images, task_ids)\n",
    "\n",
    "    \n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    task_metrics = {task: [] for task in DATASETS}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, task_ids in val_loader:\n",
    "            outputs = model(images, task_ids)\n",
    "\n",
    "           \n",
    "            for task_id, label, output in zip(task_ids, labels, outputs):\n",
    "                task_name = DATASETS[task_id]\n",
    "                pred = output.argmax(dim=1)\n",
    "                task_metrics[task_name].append(\n",
    "                    (pred == label).float().mean().item()\n",
    "                )\n",
    "\n",
    "    \n",
    "    metrics = {\n",
    "        task: np.mean(scores)\n",
    "        for task, scores in task_metrics.items()\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "class MedMNISTMultiDataset(Dataset):\n",
    "    def __init__(self, datasets, split='train', transform=None):\n",
    "        self.datasets = datasets\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "       \n",
    "        self.dataset_indices = []\n",
    "        for dataset_idx, (name, dataset_dict) in enumerate(datasets.items()):\n",
    "            dataset = dataset_dict[split]\n",
    "            n_samples = len(dataset)\n",
    "            self.dataset_indices.extend([(dataset_idx, i) for i in range(n_samples)])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset_indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dataset_idx, sample_idx = self.dataset_indices[idx]\n",
    "        dataset_name = DATASETS[dataset_idx]\n",
    "        dataset = self.datasets[dataset_name][self.split]\n",
    "        \n",
    "       \n",
    "        data = dataset[sample_idx]\n",
    "        if isinstance(data, tuple):\n",
    "            image, label = data\n",
    "        else:\n",
    "            image = data\n",
    "            label = torch.tensor(-1)  \n",
    "        \n",
    "        \n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = torch.from_numpy(image)\n",
    "        image = image.float()\n",
    "        \n",
    "       \n",
    "        if image.ndim == 2:\n",
    "            image = image.unsqueeze(0)\n",
    "        elif image.ndim == 3 and image.shape[-1] in [1, 3]:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        \n",
    "        if image.size(0) == 1:\n",
    "            image = image.repeat(3, 1, 1)\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label, torch.tensor(dataset_idx, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2777ad53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T10:29:15.820405Z",
     "iopub.status.busy": "2025-01-14T10:29:15.820152Z",
     "iopub.status.idle": "2025-01-14T17:32:10.590576Z",
     "shell.execute_reply": "2025-01-14T17:32:10.589232Z"
    },
    "papermill": {
     "duration": 25374.776562,
     "end_time": "2025-01-14T17:32:10.592431",
     "exception": false,
     "start_time": "2025-01-14T10:29:15.815869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154682a2c3b94195a8459c25b398b834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e9a448fb9c86>:32: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:40<00:00,  1.23it/s, loss=1.24]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2389, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.8936, Val F1 (Harmonic): 0.4548\n",
      "\n",
      "Epoch 2/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:41<00:00,  1.22it/s, loss=0.912]\n",
      "Validating: 100%|██████████| 116/116 [01:03<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9124, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.7479, Val F1 (Harmonic): 0.5250\n",
      "\n",
      "Epoch 3/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:41<00:00,  1.22it/s, loss=0.76]\n",
      "Validating: 100%|██████████| 116/116 [01:03<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7605, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.6256, Val F1 (Harmonic): 0.6082\n",
      "\n",
      "Epoch 4/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:41<00:00,  1.22it/s, loss=0.664]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6643, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.5682, Val F1 (Harmonic): 0.5948\n",
      "\n",
      "Epoch 5/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:42<00:00,  1.22it/s, loss=0.606]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6055, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.5740, Val F1 (Harmonic): 0.5504\n",
      "\n",
      "Epoch 6/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:41<00:00,  1.22it/s, loss=0.564]\n",
      "Validating: 100%|██████████| 116/116 [01:03<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5636, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.5227, Val F1 (Harmonic): 0.6484\n",
      "\n",
      "Epoch 7/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:39<00:00,  1.23it/s, loss=0.531]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5305, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.5010, Val F1 (Harmonic): 0.6293\n",
      "\n",
      "Epoch 8/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:41<00:00,  1.22it/s, loss=0.506]\n",
      "Validating: 100%|██████████| 116/116 [01:03<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5064, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.4829, Val F1 (Harmonic): 0.6362\n",
      "\n",
      "Epoch 9/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:40<00:00,  1.23it/s, loss=0.484]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4842, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.4634, Val F1 (Harmonic): 0.6186\n",
      "\n",
      "Epoch 10/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:42<00:00,  1.22it/s, loss=0.465]\n",
      "Validating: 100%|██████████| 116/116 [01:03<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4647, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.4562, Val F1 (Harmonic): 0.6287\n",
      "\n",
      "Epoch 11/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:42<00:00,  1.22it/s, loss=0.442]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4425, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.4639, Val F1 (Harmonic): 0.6844\n",
      "\n",
      "Epoch 12/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:43<00:00,  1.22it/s, loss=0.424]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4243, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.4372, Val F1 (Harmonic): 0.5391\n",
      "\n",
      "Epoch 13/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:43<00:00,  1.22it/s, loss=0.407]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4075, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.4305, Val F1 (Harmonic): 0.7307\n",
      "\n",
      "Epoch 14/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:44<00:00,  1.22it/s, loss=0.388]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3883, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.4346, Val F1 (Harmonic): 0.7079\n",
      "\n",
      "Epoch 15/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:44<00:00,  1.22it/s, loss=0.372]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3717, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.4178, Val F1 (Harmonic): 0.7390\n",
      "\n",
      "Epoch 16/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:44<00:00,  1.22it/s, loss=0.352]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3523, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.4243, Val F1 (Harmonic): 0.7371\n",
      "\n",
      "Epoch 17/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:45<00:00,  1.22it/s, loss=0.331]\n",
      "Validating: 100%|██████████| 116/116 [01:03<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3315, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.4224, Val F1 (Harmonic): 0.7202\n",
      "\n",
      "Epoch 18/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:44<00:00,  1.22it/s, loss=0.31]\n",
      "Validating: 100%|██████████| 116/116 [01:03<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3099, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.4508, Val F1 (Harmonic): 0.7273\n",
      "\n",
      "Epoch 19/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:45<00:00,  1.22it/s, loss=0.288]\n",
      "Validating: 100%|██████████| 116/116 [01:03<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2881, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.4384, Val F1 (Harmonic): 0.7586\n",
      "\n",
      "Epoch 20/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:44<00:00,  1.22it/s, loss=0.262]\n",
      "Validating: 100%|██████████| 116/116 [01:03<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2621, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.4519, Val F1 (Harmonic): 0.7497\n",
      "\n",
      "Epoch 21/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:43<00:00,  1.22it/s, loss=0.24]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2402, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.4581, Val F1 (Harmonic): 0.7385\n",
      "\n",
      "Epoch 22/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:44<00:00,  1.22it/s, loss=0.215]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2154, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.4746, Val F1 (Harmonic): 0.7482\n",
      "\n",
      "Epoch 23/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:45<00:00,  1.22it/s, loss=0.194]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1935, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.5274, Val F1 (Harmonic): 0.7506\n",
      "\n",
      "Epoch 24/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:45<00:00,  1.22it/s, loss=0.172]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1717, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.5379, Val F1 (Harmonic): 0.7561\n",
      "\n",
      "Epoch 25/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:46<00:00,  1.22it/s, loss=0.153]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1531, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.5678, Val F1 (Harmonic): 0.7530\n",
      "\n",
      "Epoch 26/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:45<00:00,  1.22it/s, loss=0.136]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1362, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.5793, Val F1 (Harmonic): 0.7727\n",
      "\n",
      "Epoch 27/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:47<00:00,  1.21it/s, loss=0.122]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1222, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.5981, Val F1 (Harmonic): 0.7692\n",
      "\n",
      "Epoch 28/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:44<00:00,  1.22it/s, loss=0.111]\n",
      "Validating: 100%|██████████| 116/116 [01:03<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1107, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.6175, Val F1 (Harmonic): 0.7698\n",
      "\n",
      "Epoch 29/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:46<00:00,  1.22it/s, loss=0.102]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1015, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.6288, Val F1 (Harmonic): 0.7672\n",
      "\n",
      "Epoch 30/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:46<00:00,  1.22it/s, loss=0.096]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0960, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.6476, Val F1 (Harmonic): 0.7565\n",
      "\n",
      "Epoch 31/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:46<00:00,  1.22it/s, loss=0.0905]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0905, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.6479, Val F1 (Harmonic): 0.7594\n",
      "\n",
      "Epoch 32/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:49<00:00,  1.21it/s, loss=0.0871]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0871, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.6565, Val F1 (Harmonic): 0.7547\n",
      "\n",
      "Epoch 33/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-4-e9a448fb9c86>:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "Training: 100%|██████████| 859/859 [11:45<00:00,  1.22it/s, loss=0.0867]\n",
      "Validating: 100%|██████████| 116/116 [01:04<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0867, Train F1 (Harmonic): 0.0000\n",
      "Val Loss: 0.6550, Val F1 (Harmonic): 0.7536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        batch_size=32,\n",
    "        num_epochs=10,\n",
    "        lr=1e-4,\n",
    "        weight_decay=0.01,\n",
    "        device='cuda',\n",
    "        wandb_logging=False\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.num_epochs = num_epochs\n",
    "        self.wandb_logging = wandb_logging\n",
    "        self.scaler = GradScaler()\n",
    "\n",
    "        \n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "        self.val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.class_weights = calculate_class_weights(datasets)\n",
    "\n",
    "        \n",
    "        self.optimizer = AdamW(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "        self.scheduler = OneCycleLR(\n",
    "            self.optimizer,\n",
    "            max_lr=lr,\n",
    "            epochs=num_epochs,\n",
    "            steps_per_epoch=len(self.train_loader)\n",
    "        )\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        task_predictions = {task: {'preds': [], 'targets': []} for task in DATASETS}\n",
    "\n",
    "        pbar = tqdm(self.train_loader, desc='Training')\n",
    "        for batch in pbar:\n",
    "            images, labels, task_ids = [x.to(self.device) for x in batch]\n",
    "\n",
    "            with autocast(enabled=True):\n",
    "                outputs = self.model(images, task_ids)\n",
    "                batch_losses = []\n",
    "\n",
    "                for i, (output, label, task_id) in enumerate(zip(outputs, labels, task_ids)):\n",
    "                    task_name = DATASETS[task_id]\n",
    "                    num_classes = self.model.task_outputs[task_name]\n",
    "                    task_output = output[:num_classes].unsqueeze(0)\n",
    "                    task_label = label.view(-1)\n",
    "\n",
    "                    \n",
    "                    class_weight = self.class_weights[task_name].to(self.device)\n",
    "\n",
    "                    \n",
    "                    loss_fn = torch.nn.CrossEntropyLoss(weight=class_weight)\n",
    "                    batch_losses.append(loss_fn(task_output, task_label))\n",
    "\n",
    "                loss = torch.stack(batch_losses).mean()\n",
    "\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "            self.scheduler.step()\n",
    "\n",
    "           \n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': total_loss / (pbar.n + 1)})\n",
    "\n",
    "        \n",
    "        task_f1_scores = {}\n",
    "        for task in DATASETS:\n",
    "            preds = task_predictions[task]['preds']\n",
    "            targets = task_predictions[task]['targets']\n",
    "            if len(preds) > 0:  \n",
    "                task_f1_scores[task] = f1_score(\n",
    "                    targets,\n",
    "                    preds,\n",
    "                    average='macro'\n",
    "                )\n",
    "            else:\n",
    "                task_f1_scores[task] = 0.0\n",
    "\n",
    "        return total_loss / len(self.train_loader), task_f1_scores\n",
    "\n",
    "\n",
    "    def forward(self, x, task_id=None):\n",
    "        \n",
    "        features = self.backbone(x)\n",
    "\n",
    "        if task_id is not None:\n",
    "            \n",
    "            outputs = []\n",
    "            for i, tid in enumerate(task_id):\n",
    "                task_name = DATASETS[tid]\n",
    "                outputs.append(self.heads[task_name](features[i:i+1]).squeeze(0))\n",
    "            return outputs\n",
    "        else:\n",
    "            \n",
    "            return {task: head(features) for task, head in self.heads.items()}\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        task_predictions = {task: {'preds': [], 'targets': []} for task in DATASETS}\n",
    "\n",
    "        for batch in tqdm(self.val_loader, desc='Validating'):\n",
    "            images, labels, task_ids = [x.to(self.device) for x in batch]\n",
    "\n",
    "           \n",
    "            labels = labels.view(-1).long()\n",
    "\n",
    "           \n",
    "            outputs = self.model(images, task_ids)\n",
    "\n",
    "            \n",
    "            batch_losses = []\n",
    "            for task_name in set(DATASETS[tid.item()] for tid in task_ids):\n",
    "                \n",
    "                task_mask = torch.tensor([DATASETS[tid.item()] == task_name for tid in task_ids], device=self.device)\n",
    "                if not task_mask.any():\n",
    "                    continue\n",
    "\n",
    "               \n",
    "                task_outputs = outputs[task_mask]\n",
    "                task_labels = labels[task_mask]\n",
    "\n",
    "                \n",
    "                n_classes = self.model.task_outputs[task_name]\n",
    "                task_loss = self.criterion(task_outputs[:, :n_classes], task_labels)\n",
    "                batch_losses.append(task_loss)\n",
    "\n",
    "            \n",
    "            loss = torch.stack(batch_losses).mean()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            \n",
    "            for i, (task_id, label) in enumerate(zip(task_ids, labels)):\n",
    "                task_name = DATASETS[task_id.item()]\n",
    "                n_classes = self.model.task_outputs[task_name]\n",
    "                pred = outputs[i, :n_classes].argmax(dim=0).cpu()\n",
    "                task_predictions[task_name]['preds'].append(pred.item())\n",
    "                task_predictions[task_name]['targets'].append(label.cpu().item())\n",
    "\n",
    "       \n",
    "        task_f1_scores = {}\n",
    "        for task in DATASETS:\n",
    "            preds = task_predictions[task]['preds']\n",
    "            targets = task_predictions[task]['targets']\n",
    "            if len(preds) > 0:  # Skip empty tasks\n",
    "                task_f1_scores[task] = f1_score(\n",
    "                    targets,\n",
    "                    preds,\n",
    "                    average='macro'\n",
    "                )\n",
    "\n",
    "        return total_loss / len(self.val_loader), task_f1_scores\n",
    "\n",
    "    def train(self):\n",
    "        best_f1 = 0\n",
    "        for epoch in range(self.num_epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{self.num_epochs}\")\n",
    "\n",
    "            \n",
    "            train_loss, train_f1_scores = self.train_epoch()\n",
    "            \n",
    "            train_f1_values = list(train_f1_scores.values())\n",
    "            train_f1_mean = len(train_f1_values) / sum(1/f1 if f1 > 0 else 1e+6 for f1 in train_f1_values)\n",
    "\n",
    "            \n",
    "            val_loss, val_f1_scores = self.validate()\n",
    "           \n",
    "            val_f1_values = list(val_f1_scores.values())\n",
    "            val_f1_mean = len(val_f1_values) / sum(1/f1 if f1 > 0 else 0 for f1 in val_f1_values)\n",
    "\n",
    "            \n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train F1 (Harmonic): {train_f1_mean:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}, Val F1 (Harmonic): {val_f1_mean:.4f}\")\n",
    "\n",
    "            \n",
    "            if val_f1_mean > best_f1:\n",
    "                best_f1 = val_f1_mean\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "                    'best_f1': best_f1,\n",
    "                }, 'best_model.pth')\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    \n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(size=28, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "\n",
    "    \n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.1),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "\n",
    "    \n",
    "    transforms.RandomApply([\n",
    "        transforms.GaussianBlur(kernel_size=3)\n",
    "    ], p=0.1),\n",
    "\n",
    "    \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = MedMNISTMultiDataset(\n",
    "    datasets,\n",
    "    split='train',\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "val_dataset = MedMNISTMultiDataset(\n",
    "    datasets,\n",
    "    split='val',\n",
    "    transform=val_transforms\n",
    ")\n",
    "\n",
    "test_dataset = MedMNISTMultiDataset(\n",
    "    datasets,\n",
    "    split='test',\n",
    "    transform=val_transforms\n",
    ")\n",
    "\n",
    "\n",
    "model = MedMNISTMultiTaskModel(backbone_name='convnext_tiny.in12k_ft_in1k', pretrained=True)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    batch_size=512,\n",
    "    num_epochs=33,\n",
    "    lr=1e-4,\n",
    "    device='cuda',\n",
    "    weight_decay=0.05\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b4d444f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T17:32:16.517991Z",
     "iopub.status.busy": "2025-01-14T17:32:16.517466Z",
     "iopub.status.idle": "2025-01-14T17:32:16.523190Z",
     "shell.execute_reply": "2025-01-14T17:32:16.522446Z"
    },
    "papermill": {
     "duration": 2.966049,
     "end_time": "2025-01-14T17:32:16.524425",
     "exception": false,
     "start_time": "2025-01-14T17:32:13.558376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_best_model(checkpoint_path, model):\n",
    "    \"\"\"\n",
    "    Load the best model from a checkpoint file.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path (str): Path to the checkpoint file.\n",
    "        model (nn.Module): Model to load the weights into.\n",
    "        \n",
    "    Returns:\n",
    "        model (nn.Module): Model with loaded weights.\n",
    "        best_f1 (float): Best F1 score achieved by this model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        \n",
    "        \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_f1 = checkpoint['best_f1']\n",
    "        \n",
    "        print(f\"Loaded checkpoint from epoch {checkpoint['epoch']} with F1: {best_f1:.4f}\")\n",
    "        \n",
    "        return model, best_f1\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"No checkpoint found at {checkpoint_path}\")\n",
    "        return model, 0.0\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {str(e)}\")\n",
    "        return model, 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21700ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T17:32:22.473913Z",
     "iopub.status.busy": "2025-01-14T17:32:22.473481Z",
     "iopub.status.idle": "2025-01-14T17:33:00.918600Z",
     "shell.execute_reply": "2025-01-14T17:33:00.917730Z"
    },
    "papermill": {
     "duration": 41.43024,
     "end_time": "2025-01-14T17:33:00.919846",
     "exception": false,
     "start_time": "2025-01-14T17:32:19.489606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "<ipython-input-6-8ac0b6618e29>:20: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n",
      "Generating predictions: 100%|██████████| 379/379 [00:38<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission saved with 96941 total predictions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>task_name</th>\n",
       "      <th>id_image_in_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>pathmnist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>pathmnist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>pathmnist</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>pathmnist</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>pathmnist</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  task_name  id_image_in_task\n",
       "0   0      8  pathmnist                 0\n",
       "1   1      4  pathmnist                 1\n",
       "2   2      4  pathmnist                 2\n",
       "3   3      3  pathmnist                 3\n",
       "4   4      4  pathmnist                 4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_submission(model, test_dataset, device='cuda', batch_size=512):\n",
    "    \"\"\"Create submission file for the MedMNIST competition.\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    \n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "    \n",
    "    \n",
    "    task_counters = {task: 0 for task in DATASETS}\n",
    "    global_id = 0\n",
    "    \n",
    "    with torch.no_grad(), torch.cuda.amp.autocast(): \n",
    "        for batch in tqdm(test_loader, desc='Generating predictions'):\n",
    "            images, _, task_ids = batch\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            task_ids = task_ids.cpu().numpy()\n",
    "            \n",
    "           \n",
    "            unique_tasks = np.unique(task_ids)\n",
    "            \n",
    "            \n",
    "            for task_idx in unique_tasks:\n",
    "                task_name = DATASETS[task_idx]\n",
    "                mask = task_ids == task_idx\n",
    "                \n",
    "                if mask.any():\n",
    "                    \n",
    "                    task_images = images[mask]\n",
    "                    \n",
    "                    \n",
    "                    features = model.backbone(task_images)\n",
    "                    outputs = model.heads[task_name](features)\n",
    "                    preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "                    \n",
    "                    \n",
    "                    n_preds = len(preds)\n",
    "                    task_start_idx = task_counters[task_name]\n",
    "                    \n",
    "                    \n",
    "                    batch_predictions = [{\n",
    "                        'id': global_id + i,\n",
    "                        'label': int(pred),\n",
    "                        'task_name': task_name,\n",
    "                        'id_image_in_task': task_start_idx + i\n",
    "                    } for i, pred in enumerate(preds)]\n",
    "                    \n",
    "                    all_predictions.extend(batch_predictions)\n",
    "                    \n",
    "                   \n",
    "                    task_counters[task_name] += n_preds\n",
    "                    global_id += n_preds\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(all_predictions)\n",
    "    df = df[['id', 'label', 'task_name', 'id_image_in_task']]\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    print(f\"\\nSubmission saved with {len(df)} total predictions\")\n",
    "    return df\n",
    "\n",
    "\n",
    "submission_df = create_submission(\n",
    "    model=model,\n",
    "    test_dataset=test_dataset,\n",
    "    device='cuda',\n",
    "    batch_size=256\n",
    ")\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9915460,
     "sourceId": 86864,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25456.534238,
   "end_time": "2025-01-14T17:33:06.583020",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-14T10:28:50.048782",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "08f755325e574b54a70d5cd4749e69f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "154682a2c3b94195a8459c25b398b834": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e2a8ef5bc7d440d3b27e1eb09ad41601",
        "IPY_MODEL_a22ad78a177545238b117f1832e62318",
        "IPY_MODEL_21df12b1803f4792af1e51dd1a8de0d7"
       ],
       "layout": "IPY_MODEL_bc1a7a3cd6ff4f7a8fdeb62cee8c834a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1a73a4701d9f4c7b8556ed0105857a46": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "21df12b1803f4792af1e51dd1a8de0d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cda5f47c9c6a44b1bb199ed6e8f0e544",
       "placeholder": "​",
       "style": "IPY_MODEL_ce6a7561bc5d4dc1a8113e2355070bb7",
       "tabbable": null,
       "tooltip": null,
       "value": " 114M/114M [00:00&lt;00:00, 243MB/s]"
      }
     },
     "5d10d4916cec4288842a74cc3fd5de63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5fd7f1ad768b4183ad8c1b11f06a4a2e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a22ad78a177545238b117f1832e62318": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5fd7f1ad768b4183ad8c1b11f06a4a2e",
       "max": 114374272.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5d10d4916cec4288842a74cc3fd5de63",
       "tabbable": null,
       "tooltip": null,
       "value": 114374272.0
      }
     },
     "bc1a7a3cd6ff4f7a8fdeb62cee8c834a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cda5f47c9c6a44b1bb199ed6e8f0e544": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce6a7561bc5d4dc1a8113e2355070bb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e2a8ef5bc7d440d3b27e1eb09ad41601": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1a73a4701d9f4c7b8556ed0105857a46",
       "placeholder": "​",
       "style": "IPY_MODEL_08f755325e574b54a70d5cd4749e69f2",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
