{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "460541b7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-26T09:24:20.161279Z",
     "iopub.status.busy": "2025-01-26T09:24:20.161019Z",
     "iopub.status.idle": "2025-01-26T09:24:20.777756Z",
     "shell.execute_reply": "2025-01-26T09:24:20.776960Z"
    },
    "papermill": {
     "duration": 0.623265,
     "end_time": "2025-01-26T09:24:20.779144",
     "exception": false,
     "start_time": "2025-01-26T09:24:20.155879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import os\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "'''import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))'''\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b3c765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T09:24:20.786929Z",
     "iopub.status.busy": "2025-01-26T09:24:20.786582Z",
     "iopub.status.idle": "2025-01-26T09:24:28.637343Z",
     "shell.execute_reply": "2025-01-26T09:24:28.636605Z"
    },
    "papermill": {
     "duration": 7.8563,
     "end_time": "2025-01-26T09:24:28.639100",
     "exception": false,
     "start_time": "2025-01-26T09:24:20.782800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f903ddaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T09:24:28.647005Z",
     "iopub.status.busy": "2025-01-26T09:24:28.646664Z",
     "iopub.status.idle": "2025-01-26T09:24:28.651557Z",
     "shell.execute_reply": "2025-01-26T09:24:28.650913Z"
    },
    "papermill": {
     "duration": 0.009976,
     "end_time": "2025-01-26T09:24:28.652709",
     "exception": false,
     "start_time": "2025-01-26T09:24:28.642733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class data (Dataset):\n",
    "    def __init__(self,csv,root_dir='', transform=None):\n",
    "        self.data = pd.read_csv(csv)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.data.iloc[index]['file_name'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = int(self.data.iloc[index]['label'])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ca3379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T09:24:28.660041Z",
     "iopub.status.busy": "2025-01-26T09:24:28.659841Z",
     "iopub.status.idle": "2025-01-26T09:24:28.663681Z",
     "shell.execute_reply": "2025-01-26T09:24:28.663105Z"
    },
    "papermill": {
     "duration": 0.008812,
     "end_time": "2025-01-26T09:24:28.664915",
     "exception": false,
     "start_time": "2025-01-26T09:24:28.656103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((518,518)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],  \n",
    "                         [0.229, 0.224, 0.225])\n",
    "    \n",
    "])\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((518,518)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],  \n",
    "                         [0.229, 0.224, 0.225])\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313db283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T09:24:28.672004Z",
     "iopub.status.busy": "2025-01-26T09:24:28.671803Z",
     "iopub.status.idle": "2025-01-26T09:24:29.019394Z",
     "shell.execute_reply": "2025-01-26T09:24:29.018673Z"
    },
    "papermill": {
     "duration": 0.352749,
     "end_time": "2025-01-26T09:24:29.020928",
     "exception": false,
     "start_time": "2025-01-26T09:24:28.668179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_path = '/kaggle/input/detect-ai-vs-human-generated-images/train.csv'\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "train_df, val_df = train_test_split(df, test_size=0.4, random_state=42, stratify=df['label'])\n",
    "\n",
    "train_df.to_csv('train_split.csv', index=False)\n",
    "val_df.to_csv('val_split.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ae65551",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T09:24:29.028775Z",
     "iopub.status.busy": "2025-01-26T09:24:29.028478Z",
     "iopub.status.idle": "2025-01-26T09:24:29.107361Z",
     "shell.execute_reply": "2025-01-26T09:24:29.106562Z"
    },
    "papermill": {
     "duration": 0.084198,
     "end_time": "2025-01-26T09:24:29.108768",
     "exception": false,
     "start_time": "2025-01-26T09:24:29.024570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = data(\n",
    "    csv = 'train_split.csv',\n",
    "    root_dir = '/kaggle/input/ai-vs-human-generated-dataset',\n",
    "    transform = train_transforms\n",
    ")\n",
    "val_dataset = data(\n",
    "    csv = 'val_split.csv',\n",
    "    root_dir = '/kaggle/input/ai-vs-human-generated-dataset',\n",
    "    transform = val_transforms\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0103e34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T09:24:29.116610Z",
     "iopub.status.busy": "2025-01-26T09:24:29.116292Z",
     "iopub.status.idle": "2025-01-26T09:24:29.120987Z",
     "shell.execute_reply": "2025-01-26T09:24:29.120142Z"
    },
    "papermill": {
     "duration": 0.009956,
     "end_time": "2025-01-26T09:24:29.122149",
     "exception": false,
     "start_time": "2025-01-26T09:24:29.112193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 47970\n",
      "Number of validation samples: 31980\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0300f446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T09:24:29.129472Z",
     "iopub.status.busy": "2025-01-26T09:24:29.129248Z",
     "iopub.status.idle": "2025-01-26T09:24:29.132846Z",
     "shell.execute_reply": "2025-01-26T09:24:29.132252Z"
    },
    "papermill": {
     "duration": 0.008646,
     "end_time": "2025-01-26T09:24:29.134000",
     "exception": false,
     "start_time": "2025-01-26T09:24:29.125354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 4\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    num_workers = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5712a13c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T09:24:29.141050Z",
     "iopub.status.busy": "2025-01-26T09:24:29.140851Z",
     "iopub.status.idle": "2025-01-26T09:24:29.198597Z",
     "shell.execute_reply": "2025-01-26T09:24:29.197715Z"
    },
    "papermill": {
     "duration": 0.062674,
     "end_time": "2025-01-26T09:24:29.199907",
     "exception": false,
     "start_time": "2025-01-26T09:24:29.137233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69979</td>\n",
       "      <td>train_data/bc5e653109f14d778f578e09ec29dbcd.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12831</td>\n",
       "      <td>train_data/f913d2c7cb7b4c58a328c1e2024a2750.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74697</td>\n",
       "      <td>train_data/7f448ab672934fb89648f878e1fca8a1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50571</td>\n",
       "      <td>train_data/ab787e86080443819180e8d6ab10e6da.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26683</td>\n",
       "      <td>train_data/b6dfda3fb59d41a0a6d3d28d2f39c577.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47965</th>\n",
       "      <td>20179</td>\n",
       "      <td>train_data/f400ab0d6b7e4d3f85101099fda03849.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47966</th>\n",
       "      <td>47744</td>\n",
       "      <td>train_data/e1eee53fa4294c2a832edad57ccc177e.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47967</th>\n",
       "      <td>2758</td>\n",
       "      <td>train_data/ff393399af4e401eabcad9ac6a6ed7f6.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47968</th>\n",
       "      <td>62613</td>\n",
       "      <td>train_data/9dae7abd88cc4bd0b42af88c44b598e3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47969</th>\n",
       "      <td>24089</td>\n",
       "      <td>train_data/d8221f05daee4ab981458b27dba2fda5.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47970 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                        file_name  label\n",
       "0           69979  train_data/bc5e653109f14d778f578e09ec29dbcd.jpg      0\n",
       "1           12831  train_data/f913d2c7cb7b4c58a328c1e2024a2750.jpg      0\n",
       "2           74697  train_data/7f448ab672934fb89648f878e1fca8a1.jpg      0\n",
       "3           50571  train_data/ab787e86080443819180e8d6ab10e6da.jpg      0\n",
       "4           26683  train_data/b6dfda3fb59d41a0a6d3d28d2f39c577.jpg      0\n",
       "...           ...                                              ...    ...\n",
       "47965       20179  train_data/f400ab0d6b7e4d3f85101099fda03849.jpg      0\n",
       "47966       47744  train_data/e1eee53fa4294c2a832edad57ccc177e.jpg      1\n",
       "47967        2758  train_data/ff393399af4e401eabcad9ac6a6ed7f6.jpg      1\n",
       "47968       62613  train_data/9dae7abd88cc4bd0b42af88c44b598e3.jpg      0\n",
       "47969       24089  train_data/d8221f05daee4ab981458b27dba2fda5.jpg      0\n",
       "\n",
       "[47970 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv('train_split.csv')\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fefe9b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T09:24:29.207847Z",
     "iopub.status.busy": "2025-01-26T09:24:29.207608Z",
     "iopub.status.idle": "2025-01-26T09:24:34.942555Z",
     "shell.execute_reply": "2025-01-26T09:24:34.941566Z"
    },
    "papermill": {
     "duration": 5.741117,
     "end_time": "2025-01-26T09:24:34.944672",
     "exception": false,
     "start_time": "2025-01-26T09:24:29.203555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305d8c8b468d4b3bb0cd27ee4ce47d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/88.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs\n",
      "DataParallel(\n",
      "  (module): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))\n",
      "      (norm): Identity()\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (patch_drop): Identity()\n",
      "    (norm_pre): Identity()\n",
      "    (blocks): Sequential(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "    (fc_norm): Identity()\n",
      "    (head_drop): Dropout(p=0.0, inplace=False)\n",
      "    (head): Linear(in_features=384, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from timm import create_model\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "model = create_model('vit_small_patch14_dinov2.lvd142m', pretrained=True, num_classes=2)\n",
    "\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-2)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4acf4a16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T09:24:34.953889Z",
     "iopub.status.busy": "2025-01-26T09:24:34.953654Z",
     "iopub.status.idle": "2025-01-26T09:24:34.959949Z",
     "shell.execute_reply": "2025-01-26T09:24:34.959341Z"
    },
    "papermill": {
     "duration": 0.012089,
     "end_time": "2025-01-26T09:24:34.961004",
     "exception": false,
     "start_time": "2025-01-26T09:24:34.948915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, criterion, optimizer, dataloader, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs,labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs,1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_accuracy = correct / total\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "\n",
    "def validate_one_epoch(model, criterion, optimizer, dataloader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "         for inputs, labels in dataloader:\n",
    "                   inputs,labels = inputs.to(device), labels.to(device)\n",
    "                   outputs = model(inputs)\n",
    "                   loss = criterion(outputs, labels)\n",
    "                   running_loss += loss.item() * inputs.size(0)\n",
    "                   _, preds = torch.max(outputs,1)\n",
    "                   correct += (preds == labels).sum().item()\n",
    "                   total += labels.size(0)\n",
    "        \n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_accuracy = correct / total\n",
    "    return epoch_loss, epoch_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "938b2985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T09:24:34.969467Z",
     "iopub.status.busy": "2025-01-26T09:24:34.969257Z",
     "iopub.status.idle": "2025-01-26T10:26:55.263857Z",
     "shell.execute_reply": "2025-01-26T10:26:55.262846Z"
    },
    "papermill": {
     "duration": 3740.304393,
     "end_time": "2025-01-26T10:26:55.269315",
     "exception": false,
     "start_time": "2025-01-26T09:24:34.964922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Train Loss: 0.0410, Train Accuracy: 0.9842 Validation Loss: 0.0090, Validation Accuracy: 0.9969\n",
      "Saving best model with Validation Accuracy: 0.9969\n",
      "Best Validation Accuracy: 0.9969\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "best_val_accuracy = 0.0\n",
    "save_path = \"best_model.pth\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train_one_epoch(model, criterion, optimizer, train_loader, device)\n",
    "    val_loss, val_accuracy = validate_one_epoch(model, criterion, optimizer, val_loader, device)\n",
    "    print(f\"Epoch [{epoch+1}]\"\n",
    "          f\" Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\"\n",
    "          f\" Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        print(f\"Saving best model with Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc442724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T10:26:55.278567Z",
     "iopub.status.busy": "2025-01-26T10:26:55.278244Z",
     "iopub.status.idle": "2025-01-26T10:26:55.283011Z",
     "shell.execute_reply": "2025-01-26T10:26:55.282169Z"
    },
    "papermill": {
     "duration": 0.01075,
     "end_time": "2025-01-26T10:26:55.284291",
     "exception": false,
     "start_time": "2025-01-26T10:26:55.273541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class data (Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, index):\n",
    "        img_path = '/kaggle/input/ai-vs-human-generated-dataset/' + self.df.iloc[index]['id']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef4da149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T10:26:55.293072Z",
     "iopub.status.busy": "2025-01-26T10:26:55.292851Z",
     "iopub.status.idle": "2025-01-26T10:26:55.295883Z",
     "shell.execute_reply": "2025-01-26T10:26:55.295224Z"
    },
    "papermill": {
     "duration": 0.008605,
     "end_time": "2025-01-26T10:26:55.296944",
     "exception": false,
     "start_time": "2025-01-26T10:26:55.288339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# /kaggle/input/ai-vs-human-generated-dataset/test_data_v2/0016e1d72d404fe68074cc87cb30aa37.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb970e6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T10:26:55.305401Z",
     "iopub.status.busy": "2025-01-26T10:26:55.305202Z",
     "iopub.status.idle": "2025-01-26T10:26:55.326384Z",
     "shell.execute_reply": "2025-01-26T10:26:55.325574Z"
    },
    "papermill": {
     "duration": 0.026809,
     "end_time": "2025-01-26T10:26:55.327690",
     "exception": false,
     "start_time": "2025-01-26T10:26:55.300881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/detect-ai-vs-human-generated-images/test.csv')\n",
    "test_dataset = data(\n",
    "    test,\n",
    "    transform = val_transforms\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4b0231a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T10:26:55.336455Z",
     "iopub.status.busy": "2025-01-26T10:26:55.336216Z",
     "iopub.status.idle": "2025-01-26T10:26:55.340505Z",
     "shell.execute_reply": "2025-01-26T10:26:55.339614Z"
    },
    "papermill": {
     "duration": 0.009896,
     "end_time": "2025-01-26T10:26:55.341691",
     "exception": false,
     "start_time": "2025-01-26T10:26:55.331795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 5540\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64bd8470",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T10:26:55.350258Z",
     "iopub.status.busy": "2025-01-26T10:26:55.350001Z",
     "iopub.status.idle": "2025-01-26T10:33:25.064212Z",
     "shell.execute_reply": "2025-01-26T10:33:25.063333Z"
    },
    "papermill": {
     "duration": 389.723816,
     "end_time": "2025-01-26T10:33:25.069430",
     "exception": false,
     "start_time": "2025-01-26T10:26:55.345614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-16872eb5bbba>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed predictions saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "best_model_path = \"best_model.pth\"\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        reversed_pred = 1 - pred  \n",
    "        preds.extend(reversed_pred.cpu().numpy().tolist())\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'label': preds\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Reversed predictions saved to submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10884264,
     "sourceId": 91198,
     "sourceType": "competition"
    },
    {
     "datasetId": 6412205,
     "sourceId": 10550636,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4150.440123,
   "end_time": "2025-01-26T10:33:28.087073",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-26T09:24:17.646950",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00f59b4f90744aeda8917a1ea1866d86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "07d7eb3fe02b43ef8f940750e3e1e790": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3fc9138826ec42a28c29e0872d1a5d3f",
       "placeholder": "​",
       "style": "IPY_MODEL_a436753f26854cfe91d21d45337a451c",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "305d8c8b468d4b3bb0cd27ee4ce47d46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_07d7eb3fe02b43ef8f940750e3e1e790",
        "IPY_MODEL_9bb0b75570d74f0f8ece58bb57ae39d3",
        "IPY_MODEL_6bcdb488836c451dba28c7d8fcb53ec8"
       ],
       "layout": "IPY_MODEL_9152ccbfbd7b40fcae59525f581cf720",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3fc9138826ec42a28c29e0872d1a5d3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6bcdb488836c451dba28c7d8fcb53ec8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8b04797d17ff4ecab018c95f18968be4",
       "placeholder": "​",
       "style": "IPY_MODEL_e696d7939d004e079b3d4eeb638867ee",
       "tabbable": null,
       "tooltip": null,
       "value": " 88.2M/88.2M [00:01&lt;00:00, 63.8MB/s]"
      }
     },
     "8b04797d17ff4ecab018c95f18968be4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9152ccbfbd7b40fcae59525f581cf720": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "99adcea618de4fa29add0782d252c170": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9bb0b75570d74f0f8ece58bb57ae39d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_99adcea618de4fa29add0782d252c170",
       "max": 88240510.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_00f59b4f90744aeda8917a1ea1866d86",
       "tabbable": null,
       "tooltip": null,
       "value": 88240510.0
      }
     },
     "a436753f26854cfe91d21d45337a451c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e696d7939d004e079b3d4eeb638867ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
